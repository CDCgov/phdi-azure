{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### analyzeLinkageAlgorithms\n",
        "This notebook performs a comparative analysis of three record linkage algorithms: a python implementation of LAC's current algorithm (without post-processing heuristics), the DIBBs Basic algorithm, and the DIBBs Log-Odds enhanced algorithm. The notebook is divided into several parts.\n",
        "\n",
        "Part 1 accesses the MPI database associated with the running environment and reads all records there into memory using spark. From this parallel read, smaller subsets to use as the ground-truth \"sub MPI\" and the testing evaluation set are generated.\n",
        "\n",
        "Part 2 performs labeling of the ground-truth subset. In order to accurately compare linkage algorithms, we need to have a set of match and non-match labels for our dataset, even if the labels aren't perfect. This part of the notebook uses a variety of heuristics, as well as the Expectation Maximization algorithm, to assign labels to candidate pairs based on iterative training of the sub-sampled MPI.\n",
        "\n",
        "Part 3 performs parallelized record linkage on the evaluation set. For each of the three algorithms being compared, the notebook generates fresh labels from the algorithms and compares them to the labels generated in the ground-truth assignment of Part 2. These comparisons allow us to make comparative assessments about the performance of each algorithm.\n",
        "\n",
        "Part 4 generates the final result statistics of the performance of each algorithm on the testing set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "pip install psycopg2-binary azure-identity phdi recordlinkage azure-keyvault-secrets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# IMPORTS AND CONSTANTS\n",
        "\n",
        "from azure.identity import DefaultAzureCredential\n",
        "\n",
        "# Ground-truth labeling imports\n",
        "import time\n",
        "import copy\n",
        "import pandas as pd\n",
        "import recordlinkage as rl\n",
        "from recordlinkage.base import BaseCompareFeature\n",
        "import numpy as np\n",
        "from phdi.harmonization import compare_strings\n",
        "\n",
        "# Set your Key Vault information\n",
        "vault_name = \"$KEY_VAULT\"\n",
        "KEY_VAULT_URL = f\"https://{vault_name}.vault.azure.net\"\n",
        "vault_linked_service = \"$KEY_VAULT_LINKED_SERVICE\"\n",
        "\n",
        "# Set up db_client\n",
        "DB_NAME = \"DibbsMpiDB\"\n",
        "DB_USER = \"postgres\"\n",
        "DB_HOST = \"$MPI_DB_HOST\"\n",
        "DB_PORT = \"5432\"\n",
        "\n",
        "# MPI table names\n",
        "DB_TABLE_PATIENT = \"patient\"\n",
        "DB_TABLE_PERSON = \"person\"\n",
        "DB_TABLE_NAME = \"name\"\n",
        "DB_TABLE_GIVEN_NAME = \"given_name\"\n",
        "DB_TABLE_ADDRESS = \"address\"\n",
        "DB_TABLE_IDENTIFIER = \"identifier\"\n",
        "\n",
        "# Adjust data volume for scaling\n",
        "# Make sure evaluation size is less than labeling size!\n",
        "LABELING_SIZE = 150000\n",
        "EVALUATION_SIZE = 150000\n",
        "\n",
        "# Ground-truth labeling parameters\n",
        "WINDOW_INDEX_SIZE = 5\n",
        "JARO_THRESHOLD = 0.9\n",
        "BIRTHDAY_THRESHOLD = 0.95"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# OPEN PARALLEL CONNECTION TO MPI, READ DB INTO COMPRESSED MEMORY\n",
        "\n",
        "from pyspark.sql import SparkSession, Row\n",
        "import json\n",
        "\n",
        "# Access the MPI Database\n",
        "credential = DefaultAzureCredential()\n",
        "db_password =  TokenLibrary.getSecret(vault_name,\"mpi-db-password\",vault_linked_service)\n",
        "\n",
        "url = f\"jdbc:postgresql://{DB_HOST}:{DB_PORT}/{DB_NAME}\"\n",
        "db_props = {\n",
        "    \"user\": DB_USER,\n",
        "    \"password\": db_password,\n",
        "    \"driver\": \"org.postgresql.Driver\"\n",
        "}\n",
        "\n",
        "spark = (\n",
        "    SparkSession.builder.master(\"local[*]\")\n",
        "    .appName(\"Build sub-sampled MPI\")\n",
        "    .getOrCreate()\n",
        ")\n",
        "\n",
        "# Create views into all tables in the MPI so we can extract them in parallel\n",
        "patient_view = \"patient_view\"\n",
        "mpi_patient_data = spark.read.jdbc(url, DB_TABLE_PATIENT, properties=db_props)\n",
        "mpi_patient_data.createOrReplaceTempView(patient_view)\n",
        "\n",
        "name_view = \"name_view\"\n",
        "mpi_name_data = spark.read.jdbc(url, DB_TABLE_NAME, properties=db_props)\n",
        "mpi_name_data.createOrReplaceTempView(name_view)\n",
        "\n",
        "given_name_view = \"given_name_view\"\n",
        "mpi_given_name_data = spark.read.jdbc(url, DB_TABLE_GIVEN_NAME, properties=db_props)\n",
        "mpi_given_name_data.createOrReplaceTempView(given_name_view)\n",
        "\n",
        "address_view = \"address_view\"\n",
        "mpi_address_data = spark.read.jdbc(url, DB_TABLE_ADDRESS, properties=db_props)\n",
        "mpi_address_data.createOrReplaceTempView(address_view)\n",
        "\n",
        "identifier_view = \"identifier_view\"\n",
        "mpi_identifier_data = spark.read.jdbc(url, DB_TABLE_IDENTIFIER, properties=db_props)\n",
        "mpi_identifier_data.createOrReplaceTempView(identifier_view)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# MOUNT THE FILE SYSTEM SO WE CAN WRITE THE OUTPUTS TO FILES\n",
        "\n",
        "# Set paths\n",
        "STORAGE_ACCOUNT = \"$STORAGE_ACCOUNT\"\n",
        "LINKAGE_OUTPUTS_FILESYSTEM = f\"abfss://linkage-notebook-outputs@{STORAGE_ACCOUNT}.dfs.core.windows.net/\"\n",
        "BLOB_STORAGE_LINKED_SERVICE = \"$BLOB_STORAGE_LINKED_SERVICE\"\n",
        "\n",
        "from notebookutils import mssparkutils\n",
        "\n",
        "# Functions for writing and reading results\n",
        "\"\"\"\n",
        "Function that writes the output of a linkage algorithm to a json file.\n",
        "\"\"\"\n",
        "def write_linkage_results(fname, results):\n",
        "    # Results come in as a dict of ints to sets, so just json dumps it\n",
        "    res_to_write = {str(k):[str(x) for x in list(v)] for (k,v) in results.items()}\n",
        "    res_to_write = json.dumps(res_to_write)\n",
        "    mssparkutils.fs.put(LINKAGE_OUTPUTS_FILESYSTEM + fname + \".json\", res_to_write, True)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Function that loads the output of a linkage algorithm from a json file using spark.read\n",
        "and converts it into the same format as the results dict (ints to sets).\n",
        "\"\"\"\n",
        "def load_linkage_results(fname):\n",
        "    try:\n",
        "        res = spark.read.json(LINKAGE_OUTPUTS_FILESYSTEM + fname + \".json\")\n",
        "    except:\n",
        "        print(\"Existing results not found.\")\n",
        "        return None\n",
        "    \n",
        "    print(\"Existing results found!\")\n",
        "    res = res.toPandas()\n",
        "    res = res.to_dict()\n",
        "    res = {int(k):set([int(x) for x in v[0]]) for (k,v) in res.items()}\n",
        "    return res\n",
        "    \n",
        "\n",
        "# Set up for writing to blob storage\n",
        "linkage_bucket_name = \"linkage-notebook-outputs\"\n",
        "blob_sas_token = mssparkutils.credentials.getConnectionStringOrCreds(BLOB_STORAGE_LINKED_SERVICE)\n",
        "wasb_path = 'wasbs://%s@%s.blob.core.windows.net/' % (linkage_bucket_name, STORAGE_ACCOUNT)\n",
        "spark.conf.set('fs.azure.sas.%s.%s.blob.core.windows.net' % (linkage_bucket_name, STORAGE_ACCOUNT), blob_sas_token)\n",
        "# Try mounting the remote storage directory at the mount point\n",
        "try:\n",
        "    mssparkutils.fs.mount(\n",
        "        wasb_path,\n",
        "        \"/\",\n",
        "        {\"LinkedService\": f\"${BLOB_STORAGE_LINKED_SERVICE}\"}\n",
        "    )\n",
        "except:\n",
        "    print(\"Already mounted\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# MPI EXTRACTION\n",
        "# Pull all the various sources of patient information out of the MPI and\n",
        "# massage them into a single table. This allows us to format the data for\n",
        "# training and testing easily off the same spark DF.\n",
        "\n",
        "import pyspark.sql.functions as F\n",
        "from pyspark.sql.functions import struct\n",
        "\n",
        "'''\n",
        "Helper function to construct a complete string representation of a patient's given \n",
        "name from the various fields of a row struct in a pyspark dataframe pulled from\n",
        "the MPI.\n",
        "'''\n",
        "def construct_full_given_name(row):\n",
        "    gn = \"\"\n",
        "    if row[\"given_name_list\"] is not None:\n",
        "        sorted_structs = sorted(row[\"given_name_list\"], key=lambda x: x.given_name_index)\n",
        "        gn = [x.given_name for x in sorted_structs]\n",
        "        gn = \" \".join(gn)\n",
        "    return row[\"name_id\"], row[\"patient_id\"], row[\"last_name\"], gn\n",
        "\n",
        "\n",
        "# Start with table with 1 row per patient so that when we left join, we preserve that\n",
        "extracted_patient_data = spark.sql(f\"SELECT * from {DB_TABLE_PATIENT}_view\")\n",
        "\n",
        "# Given names don't have a patient_id field, so compile the given names\n",
        "# associated with each name_id entry in preparation to join to last names\n",
        "extracted_given_names = spark.sql(f\"SELECT * from {DB_TABLE_GIVEN_NAME}_view\")\n",
        "extracted_given_names = extracted_given_names.withColumn(\n",
        "    \"name_structs\",\n",
        "    struct(extracted_given_names.given_name, extracted_given_names.given_name_index)\n",
        ")\n",
        "extracted_given_names = extracted_given_names.groupBy(\"name_id\").agg(F.collect_list(\"name_structs\").alias(\"given_name_list\"))\n",
        "extracted_given_names.cache()\n",
        "\n",
        "# Last names are 1:1 with a name_id representing all associated given names\n",
        "# Last names also map back to patient_ids in the patient_table, so use left\n",
        "# joins to preserve all present info and the 1 row per patient structure\n",
        "extracted_name_data = spark.sql(f\"SELECT * from {DB_TABLE_NAME}_view\")\n",
        "full_name_table = extracted_name_data.join(extracted_given_names, \"name_id\", \"left\")\n",
        "full_name_table = full_name_table.rdd.map(construct_full_given_name).toDF([\"name_id\", \"patient_id\", \"last_name\", \"given_name\"])\n",
        "full_name_table = full_name_table.withColumn(\"full_name_structs\", struct(full_name_table.given_name, full_name_table.last_name))\n",
        "full_name_table = full_name_table.groupBy(\"patient_id\").agg(F.collect_list(\"full_name_structs\").alias(\"full_name_list\"))\n",
        "extracted_patient_data = extracted_patient_data.join(full_name_table, \"patient_id\", \"left\")\n",
        "extracted_patient_data.cache()\n",
        "\n",
        "# Identifier table needs compiled and can left join back to patients\n",
        "extracted_identifier_data = spark.sql(f\"SELECT * from {DB_TABLE_IDENTIFIER}_view\")\n",
        "extracted_identifier_data = extracted_identifier_data.withColumn(\"id_structs\", struct(\n",
        "    extracted_identifier_data.patient_identifier, extracted_identifier_data.type_code\n",
        "))\n",
        "extracted_identifier_data = extracted_identifier_data.groupBy(\"patient_id\").agg(F.collect_list(\"id_structs\").alias(\"ids_list\"))\n",
        "extracted_patient_data = extracted_patient_data.join(extracted_identifier_data, \"patient_id\", \"left\")\n",
        "\n",
        "# Address fields can be massively collapsed into the traditional string representation\n",
        "# Then we join this back on patient table\n",
        "extracted_address_data = spark.sql(f\"SELECT * from {DB_TABLE_ADDRESS}_view\")\n",
        "extracted_address_data = extracted_address_data.withColumn(\"address_structs\", struct(\n",
        "    extracted_address_data.line_1,\n",
        "    extracted_address_data.line_2,\n",
        "    extracted_address_data.city,\n",
        "    extracted_address_data.state,\n",
        "    extracted_address_data.zip_code\n",
        "))\n",
        "extracted_address_data = extracted_address_data.groupBy(\"patient_id\").agg(F.collect_list(\"address_structs\").alias(\"address_list\"))\n",
        "extracted_patient_data = extracted_patient_data.join(extracted_address_data, \"patient_id\", \"left\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TRAIN/TEST CREATION\n",
        "# Use the extracted information from the MPI to create two sets of data, one\n",
        "# in flattened array form in a pandas DF for labeling (training) and one as a \n",
        "# list of FHIR bundles for evaluation (testing).\n",
        "\n",
        "from phdi.linkage.link import _flatten_patient_resource\n",
        "from pyspark.sql.types import StructType, StructField, StringType\n",
        "\n",
        "\n",
        "def create_patient_resource_from_spark_row(row):\n",
        "    # Pull out the various fields from the passed-in row\n",
        "    extracted_pid = row[\"patient_id\"]\n",
        "    extracted_birthdate = row[\"dob\"] if row[\"dob\"] is not None else \"\"\n",
        "    extracted_gender = row[\"sex\"] if row[\"sex\"] is not None else \"\"\n",
        "    extracted_names = row[\"full_name_list\"]\n",
        "    extracted_identifiers = row[\"ids_list\"]\n",
        "    extracted_addresses = row[\"address_list\"]\n",
        "\n",
        "    # Initialize a patient resource to append fields into\n",
        "    patient_resource = {\n",
        "        \"resourceType\": \"Patient\",\n",
        "        \"id\": f\"{extracted_pid}\",\n",
        "        \"identifier\": [],\n",
        "        \"name\": [],\n",
        "        \"gender\": f\"{extracted_gender}\",\n",
        "        \"birthDate\": f\"{extracted_birthdate}\",\n",
        "        \"address\": [],\n",
        "    }\n",
        "\n",
        "    for en in extracted_names:\n",
        "        givens = en.given_name if en.given_name is not None else \"\"\n",
        "        givens = str(givens).split()\n",
        "        last = en.last_name if en.last_name is not None else \"\"\n",
        "        patient_resource[\"name\"].append({\n",
        "            \"family\": f\"{last}\",\n",
        "            \"given\": givens\n",
        "        })\n",
        "    \n",
        "    for ident in extracted_identifiers:\n",
        "        patient_resource[\"identifier\"].append({\n",
        "            \"type\": {\n",
        "                \"coding\": [\n",
        "                    {\n",
        "                        \"system\": \"http://terminology.hl7.org/CodeSystem/v2-0203\",\n",
        "                        \"code\": ident.type_code\n",
        "                    }\n",
        "                ]\n",
        "            },\n",
        "            \"value\": ident.patient_identifier\n",
        "        })\n",
        "    \n",
        "    for addr in extracted_addresses:\n",
        "        l1 = addr.line_1 if addr.line_1 is not None else \"\"\n",
        "        l2 = addr.line_2 if addr.line_2 is not None else \"\"\n",
        "        lines = [x for x in [l1, l2] if x != \"\"]\n",
        "        city = addr.city if addr.city is not None else \"\"\n",
        "        state = addr.state if addr.state is not None else \"\"\n",
        "        zipcode = addr.zip_code if addr.zip_code is not None else \"\"\n",
        "        patient_resource[\"address\"].append({\n",
        "            \"line\": lines if len(lines) > 0 else [\"\"],\n",
        "            \"city\": f\"{city}\",\n",
        "            \"state\": f\"{state}\",\n",
        "            \"postalCode\": f\"{zipcode}\"\n",
        "        })\n",
        "    \n",
        "    return (row[\"person_id\"], patient_resource)\n",
        "\n",
        "\n",
        "def yield_patient_resource(row):\n",
        "    return row[1]\n",
        "\n",
        "\n",
        "def yield_flattened_patient_with_person_id(row):\n",
        "    pid = row[0]\n",
        "    fp = _flatten_patient_resource(row[1])\n",
        "    fp[1] = pid\n",
        "    return fp\n",
        "\n",
        "\n",
        "# Build the base FHIR and flattened row groups of data\n",
        "fhir_mapped_data = extracted_patient_data.rdd.map(create_patient_resource_from_spark_row)\n",
        "fhir_mapped_data.cache()\n",
        "flattened_patient_data = fhir_mapped_data.map(yield_flattened_patient_with_person_id)\n",
        "fhir_mapped_data = fhir_mapped_data.map(yield_patient_resource)\n",
        "\n",
        "# Construct the labeling set\n",
        "formatted_cols = [\"patient_id\", \"person_id\", \"address\", \"birthdate\", \"city\", \"first_name\", \"last_name\", \"mrn\", \"sex\", \"state\", \"zip\"]\n",
        "pyspark_schema = StructType([\n",
        "    StructField(x, StringType(), True) for x in formatted_cols\n",
        "])\n",
        "flattened_patient_data = flattened_patient_data.toDF(pyspark_schema)\n",
        "labeling_set = [list(x) for x in flattened_patient_data.collect()]\n",
        "if LABELING_SIZE is not None and LABELING_SIZE < len(labeling_set):\n",
        "    labeling_set = labeling_set[:LABELING_SIZE]\n",
        "labeling_set = pd.DataFrame(labeling_set, columns=formatted_cols)\n",
        "del flattened_patient_data\n",
        "\n",
        "# Construct the evaluation set\n",
        "evaluation_set = [x for x in fhir_mapped_data.collect()]\n",
        "if EVALUATION_SIZE is not None and EVALUATION_SIZE < len(evaluation_set):\n",
        "    evaluation_set = evaluation_set[:EVALUATION_SIZE]\n",
        "evaluation_set = spark.sparkContext.parallelize(evaluation_set, numSlices=512)\n",
        "del fhir_mapped_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CANDIDATE INDEXING\n",
        "# Generates tuples of all possible candidate pairs that the labeler will compute\n",
        "# match likelihoods for.\n",
        "\n",
        "from recordlinkage.index import SortedNeighbourhood, BaseIndexAlgorithm\n",
        "from recordlinkage.utils import listify\n",
        "\n",
        "'''\n",
        "A custom Indexing function built to operate compatibly on the first_name column\n",
        "returned from the MPI. Since that's a list of strings (because someone could have\n",
        "multiple given names), we need a way to cross-conjoin these entries and apply\n",
        "the same fuzzy blocking filter window that a regular column of strings would get.\n",
        "This performs joint name concatenation on copies of that column in the data, and\n",
        "then uses an edit distance neighborhood to find fuzzy blocking candidates.\n",
        "'''\n",
        "class FirstNameSortedNeighborhood(BaseIndexAlgorithm):\n",
        "    def __init__(\n",
        "        self,\n",
        "        left_on=None,\n",
        "        right_on=None,\n",
        "        window=3,\n",
        "        sorting_key_values=None,\n",
        "        block_on=[],\n",
        "        block_left_on=[],\n",
        "        block_right_on=[],\n",
        "        **kwargs\n",
        "    ):\n",
        "        super(FirstNameSortedNeighborhood, self).__init__(**kwargs)\n",
        "\n",
        "        # variables to block on\n",
        "        self.left_on = left_on\n",
        "        self.right_on = right_on\n",
        "        self.window = window\n",
        "        self.sorting_key_values = sorting_key_values\n",
        "        self.block_on = block_on\n",
        "        self.block_left_on = block_left_on\n",
        "        self.block_right_on = block_right_on\n",
        "\n",
        "    def _get_left_and_right_on(self):\n",
        "        \"\"\"\n",
        "        We only care about the de-dupe case which involves no self.right, but this\n",
        "        still needs to be implemented for super compatibility.\n",
        "        \"\"\"\n",
        "        if self.right_on is None:\n",
        "            return (self.left_on, self.left_on)\n",
        "        else:\n",
        "            return (self.left_on, self.right_on)\n",
        "\n",
        "    def _get_sorting_key_values(self, array1, array2):\n",
        "        \"\"\"\n",
        "        Return the sorting key values as a series. This function is required by the\"\n",
        "        package for multi-index neighborhood filtering according to some papers it's\"\n",
        "        built on.\n",
        "        \"\"\"\n",
        "\n",
        "        concat_arrays = np.concatenate([array1, array2])\n",
        "        return np.unique(concat_arrays)\n",
        "\n",
        "    def _link_index(self, df_a, df_b):\n",
        "        df_a = df_a.copy()\n",
        "        df_b = df_b.copy()\n",
        "        df_a[\"first_name\"] = df_a[\"first_name\"].str.join(\" \")\n",
        "        df_b[\"first_name\"] = df_a[\"first_name\"].str.join(\" \")\n",
        "        left_on, right_on = self._get_left_and_right_on()\n",
        "        left_on = listify(left_on)\n",
        "        right_on = listify(right_on)\n",
        "\n",
        "        window = self.window\n",
        "\n",
        "        # Correctly generate blocking keys\n",
        "        block_left_on = listify(self.block_left_on)\n",
        "        block_right_on = listify(self.block_right_on)\n",
        "\n",
        "        if self.block_on:\n",
        "            block_left_on = listify(self.block_on)\n",
        "            block_right_on = listify(self.block_on)\n",
        "\n",
        "        blocking_keys = [\"sorting_key\"] + [\n",
        "            \"blocking_key_%d\" % i for i, v in enumerate(block_left_on)\n",
        "        ]\n",
        "\n",
        "        # Format the data to thread with index pairs\n",
        "        data_left = pd.DataFrame(df_a[listify(left_on) + block_left_on], copy=False)\n",
        "        data_left.columns = blocking_keys\n",
        "        data_left[\"index_x\"] = np.arange(len(df_a))\n",
        "        data_left.dropna(axis=0, how=\"any\", subset=blocking_keys, inplace=True)\n",
        "\n",
        "        data_right = pd.DataFrame(df_b[listify(right_on) + block_right_on], copy=False)\n",
        "        data_right.columns = blocking_keys\n",
        "        data_right[\"index_y\"] = np.arange(len(df_b))\n",
        "        data_right.dropna(axis=0, how=\"any\", subset=blocking_keys, inplace=True)\n",
        "\n",
        "        # sorting_key_values is the terminology in Data Matching [Christen,\n",
        "        # 2012]\n",
        "        if self.sorting_key_values is None:\n",
        "            self.sorting_key_values = self._get_sorting_key_values(\n",
        "                data_left[\"sorting_key\"].values, data_right[\"sorting_key\"].values\n",
        "            )\n",
        "\n",
        "        sorting_key_factors = pd.Series(\n",
        "            np.arange(len(self.sorting_key_values)), index=self.sorting_key_values\n",
        "        )\n",
        "\n",
        "        data_left[\"sorting_key\"] = data_left[\"sorting_key\"].map(sorting_key_factors)\n",
        "        data_right[\"sorting_key\"] = data_right[\"sorting_key\"].map(sorting_key_factors)\n",
        "\n",
        "        # Internal window size\n",
        "        _window = int((window - 1) / 2)\n",
        "\n",
        "        def merge_lagged(x, y, w):\n",
        "            \"\"\"Merge two dataframes with a lag on in the sorting key.\"\"\"\n",
        "\n",
        "            y = y.copy()\n",
        "            y[\"sorting_key\"] = y[\"sorting_key\"] + w\n",
        "\n",
        "            return x.merge(y, how=\"inner\")\n",
        "\n",
        "        pairs_concat = [\n",
        "            merge_lagged(data_left, data_right, w) for w in range(-_window, _window + 1)\n",
        "        ]\n",
        "\n",
        "        pairs_df = pd.concat(pairs_concat, axis=0)\n",
        "\n",
        "        return pd.MultiIndex(\n",
        "            levels=[df_a.index.values, df_b.index.values],\n",
        "            codes=[pairs_df[\"index_x\"].values, pairs_df[\"index_y\"].values],\n",
        "            verify_integrity=False,\n",
        "        )\n",
        "\n",
        "\n",
        "def find_candidate_links(data):\n",
        "    start = time.time()\n",
        "    # Create a windowed neighborhood index on patient table because full is \n",
        "    # too expensive\n",
        "    indexer = rl.Index()\n",
        "    # Adding multiple different neighborhoods takes their union so we don't over-block\n",
        "    indexer.add(SortedNeighbourhood('last_name', window=WINDOW_INDEX_SIZE))\n",
        "    indexer.add(SortedNeighbourhood('birthdate', window=WINDOW_INDEX_SIZE))\n",
        "    indexer.add(SortedNeighbourhood('mrn', window=WINDOW_INDEX_SIZE))\n",
        "    indexer.add(FirstNameSortedNeighborhood('first_name', window=WINDOW_INDEX_SIZE))\n",
        "    candidate_links = indexer.index(data)\n",
        "    print(len(candidate_links), \"candidate pairs identified\")\n",
        "\n",
        "    # Note: using a multi-indexer treats the row number as the index, so\n",
        "    # results will automatically be in acceptable eval format\n",
        "    end = time.time()\n",
        "    print(\"Identifying possible candidate pairs took \", str(round(end - start, 2)), \"seconds\")\n",
        "    return candidate_links\n",
        "\n",
        "\n",
        "# Transform a recordlinkage toolkit multi-index into a set of candidate tuples\n",
        "def get_pred_match_dict_from_multi_idx(mltidx, n_rows):\n",
        "    candidate_tuples = mltidx.to_list()\n",
        "    pred_matches = {k: set() for k in range(n_rows)}\n",
        "    for pair in candidate_tuples:\n",
        "        reference_record = min(pair)\n",
        "        linked_record = max(pair)\n",
        "        pred_matches[reference_record].add(linked_record)\n",
        "    return pred_matches\n",
        "\n",
        "# Convert mrn col into actual Nones rather than string Nones\n",
        "# We'll need to reverse this in the later spark-block stages to parallel mask\n",
        "labeling_set = labeling_set.replace({\"None\": None})\n",
        "\n",
        "candidate_links = find_candidate_links(labeling_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# GROUND TRUTH LABELING: VIRGINIA FUNCTIONS\n",
        "\n",
        "# Special class for comparing LoL concatenated elements\n",
        "# Use the full concatenation of all values to account for multiple entries like given names\n",
        "class CompareNestedString(BaseCompareFeature):\n",
        "    def _compute_vectorized(self, s1, s2):\n",
        "        strrep1 = s1.str.lstrip('[').str.rstrip(']').str.split(',')\n",
        "        strrep2 = s2.str.lstrip('[').str.rstrip(']').str.split(',')\n",
        "        return (strrep1.str[0] == strrep2.str[0]).astype(float)\n",
        "\n",
        "\n",
        "def get_va_labels(data, candidate_links):\n",
        "    start = time.time()\n",
        "\n",
        "    # Apply feature comparisons on each supported field from the MPI\n",
        "    comp = rl.Compare()\n",
        "    comp.add(CompareNestedString(\"first_name\", \"first_name\",label=\"first_name\"))\n",
        "    comp.exact(\"last_name\", \"last_name\", label=\"last_name\")\n",
        "    comp.exact(\"birthdate\", \"birthdate\", label=\"birthdate\")\n",
        "    comp.add(CompareNestedString(\"address\", \"address\", label=\"address\"))\n",
        "    features = comp.compute(candidate_links, data)\n",
        "    matches = features[features.sum(axis=1) == 4]\n",
        "\n",
        "    end = time.time()\n",
        "    print(\"Comparing candidates took\", str(round(end - start, 2)), \"seconds\")\n",
        "\n",
        "    matches = get_pred_match_dict_from_multi_idx(matches.index, len(data))\n",
        "    return matches\n",
        "\n",
        "\n",
        "va_labels = get_va_labels(labeling_set, candidate_links)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FEATURE COMPARATOR\n",
        "# Generate string similarity scores for all features in all candidate pairs.\n",
        "\n",
        "# Special class for comparing LoL first name elements\n",
        "# Use the full concatenation of all names to account for multiple given names\n",
        "class CompareFirstName(BaseCompareFeature):\n",
        "    def _compute_vectorized(self, s1, s2):\n",
        "        strrep1 = s1.str.lstrip('[').str.rstrip(']').str.split(',')\n",
        "        strrep2 = s2.str.lstrip('[').str.rstrip(']').str.split(',')\n",
        "        jarowinklers = np.vectorize(compare_strings)(strrep1.str.join(\" \"), strrep2.str.join(\" \"))\n",
        "        return jarowinklers\n",
        "\n",
        "\n",
        "# Special class for comparing LoL address line elements\n",
        "# Check each address line against each other address line to account for moving\n",
        "class CompareAddress(BaseCompareFeature):\n",
        "    def _compute_vectorized(self, s1, s2):\n",
        "\n",
        "        def comp_address_fields(a1_list, a2_list):\n",
        "            best_score = 0.0\n",
        "            for a1 in a1_list:\n",
        "                for a2 in a2_list:\n",
        "                    score = compare_strings(a1, a2)\n",
        "                    if score >= best_score:\n",
        "                        best_score = score\n",
        "            return best_score\n",
        "\n",
        "        strrep1 = s1.str.lstrip('[').str.rstrip(']').str.split(',')\n",
        "        strrep2 = s2.str.lstrip('[').str.rstrip(']').str.split(',')\n",
        "        jarowinklers = np.vectorize(comp_address_fields)(strrep1, strrep2)\n",
        "        return jarowinklers\n",
        "\n",
        "'''\n",
        "Produces a dataframe with a multi-index, in which each tuple of row indices\n",
        "denotes one potential candidate match. The value in each column of the DF\n",
        "is the fuzzy match similarity score between the two records given by the \n",
        "multi-index.\n",
        "'''\n",
        "def compute_comparator_matrix(data, candidate_links):\n",
        "    start = time.time()\n",
        "\n",
        "    # Apply feature comparisons on each supported field from the MPI\n",
        "    comp = rl.Compare()\n",
        "    comp.add(CompareFirstName(\"first_name\", \"first_name\",label=\"first_name\"))\n",
        "    comp.string(\n",
        "        \"last_name\", \"last_name\", method=\"jarowinkler\", label=\"last_name\"\n",
        "    )\n",
        "    comp.string(\"mrn\", \"mrn\", method=\"jarowinkler\", label=\"mrn\")\n",
        "    comp.string(\n",
        "        \"birthdate\", \"birthdate\", method=\"jarowinkler\", label=\"birthdate\"\n",
        "    )\n",
        "    comp.add(CompareAddress(\"address\", \"address\", label=\"address\"))\n",
        "    comp.string(\"city\", \"city\", method=\"jarowinkler\", label=\"city\")\n",
        "    comp.string(\"zip\", \"zip\", method=\"jarowinkler\", label=\"zip\")\n",
        "    comp.string(\"sex\", \"sex\", method=\"jarowinkler\", label=\"sex\")\n",
        "    features = comp.compute(candidate_links, data)\n",
        "\n",
        "    end = time.time()\n",
        "    print(\"Computation took\", str(round(end - start, 2)), \"seconds\")\n",
        "    return features\n",
        "\n",
        "features = compute_comparator_matrix(labeling_set, candidate_links)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# GROUND-TRUTH LABELING: INTELLIGENT EXTERNAL SYSTEMS\n",
        "# Leverages the published heuristic rules of both the NCI SEER labaling algorithm\n",
        "# and the UK's National Health Services deterministic labeler to generate labels\n",
        "# that we can treat as true for comparative match purposes.\n",
        "\n",
        "'''\n",
        "Helper function that combines two dictionaries, each of which has already been\n",
        "formatted in the requisite stats indexing fashion.\n",
        "'''\n",
        "def combine_match_dicts(m1, m2):\n",
        "    m3 = {}\n",
        "    for k in m1:\n",
        "        union_set = set()\n",
        "        union_set = union_set.union(m1[k])\n",
        "        union_set = union_set.union(m2[k])\n",
        "        m3[k] = union_set\n",
        "    return m3\n",
        "\n",
        "\n",
        "'''\n",
        "Generate the NCI's SEER Labels using two types of matches, based on whether or not\n",
        "the candidate pair has a perfectly agreeing MRN.\n",
        "'''\n",
        "def get_seer_labels(data, features):\n",
        "    mrn_matches = features.loc[features['mrn'] == 1.0]\n",
        "    matches_type_1 = mrn_matches.loc[\n",
        "        ((mrn_matches['first_name'] >= JARO_THRESHOLD) & (mrn_matches['last_name'] >= JARO_THRESHOLD)) |\n",
        "        ((mrn_matches['first_name'] >= JARO_THRESHOLD) & (mrn_matches['birthdate'] >= JARO_THRESHOLD)) |\n",
        "        ((mrn_matches['birthdate'] >= BIRTHDAY_THRESHOLD) & (mrn_matches['last_name'] >= JARO_THRESHOLD))\n",
        "    ]\n",
        "\n",
        "    matches_type_2 = features.loc[\n",
        "        (features['first_name'] >= JARO_THRESHOLD) &\n",
        "        (features['last_name'] >= JARO_THRESHOLD) & \n",
        "        (features['sex'] >= JARO_THRESHOLD) &\n",
        "        (\n",
        "            (features['mrn'] >= JARO_THRESHOLD) |\n",
        "            (features['birthdate'] >= BIRTHDAY_THRESHOLD)\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    m1_dict = get_pred_match_dict_from_multi_idx(matches_type_1.index, len(data))\n",
        "    m2_dict = get_pred_match_dict_from_multi_idx(matches_type_2.index, len(data))\n",
        "    pred_matches = combine_match_dicts(m1_dict, m2_dict)\n",
        "\n",
        "    return pred_matches\n",
        "\n",
        "\n",
        "'''\n",
        "Generate the UK's National Health Service labels using three match conditions, \n",
        "depending on the available field information and whether constraints are\n",
        "progressively relaxed.\n",
        "'''\n",
        "def get_uk_nhs_labels(data, features):\n",
        "    matches_type_1 = features.loc[\n",
        "        (features['birthdate'] == 1.0) &\n",
        "        (features['sex'] == 1.0) &\n",
        "        (features['mrn'] == 1.0)\n",
        "    ]\n",
        "\n",
        "    matches_type_2 = features.loc[\n",
        "        (features['birthdate'] >= BIRTHDAY_THRESHOLD) & \n",
        "        (features['sex'] == 1.0) &\n",
        "        (features['zip'] == 1.0) &\n",
        "        (features['mrn'] >= JARO_THRESHOLD)\n",
        "    ]\n",
        "\n",
        "    matches_type_3 = features.loc[\n",
        "        (features['birthdate'] == 1.0) &\n",
        "        (features['sex'] == 1.0) &\n",
        "        (features['zip'] == 1.0)\n",
        "    ]\n",
        "\n",
        "    m1_dict = get_pred_match_dict_from_multi_idx(matches_type_1.index, len(data))\n",
        "    m2_dict = get_pred_match_dict_from_multi_idx(matches_type_2.index, len(data))\n",
        "    m3_dict = get_pred_match_dict_from_multi_idx(matches_type_3.index, len(data))\n",
        "    pred_matches = combine_match_dicts(m1_dict, m2_dict)\n",
        "    pred_matches = combine_match_dicts(pred_matches, m3_dict)\n",
        "    \n",
        "    return pred_matches\n",
        "\n",
        "seer_labels = get_seer_labels(labeling_set, features)\n",
        "uk_labels = get_uk_nhs_labels(labeling_set, features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# LINKAGE DRIVER FUNCTIONS\n",
        "\n",
        "from phdi.linkage.link import _flatten_patient_resource, extract_blocking_values_from_record\n",
        "from typing import List\n",
        "import re\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Function that uses a pandas DataFrame construct of an extracted MPI to efficiently\n",
        "filter down candidates into appropriate blocks. While the filtering itself is not\n",
        "parallelized, since it occurs on the worker nodes, each executor is performing\n",
        "linkage for one or more test records simultaneously. As a result, a pandas DF\n",
        "provides an appropriate level of speed to use .loc retrieval.\n",
        "\"\"\"\n",
        "def spark_block(block_vals: dict, labeling_set: pd.DataFrame):\n",
        "\n",
        "    # We'll sequentially apply each blocking filter, since that's equivalent to finding\n",
        "    # their intersection all at once\n",
        "    result = labeling_set\n",
        "    for blocking_criterion in block_vals:\n",
        "        props = block_vals[blocking_criterion]\n",
        "\n",
        "        # Special case if we're blocking on first_name or address: pyspark can serialize these\n",
        "        # as JSON strings, but that means they actually get stored as strings, so we need to \n",
        "        # account for the brackets '[' and ']'\n",
        "        if blocking_criterion == \"first_name\" or blocking_criterion == \"address\":\n",
        "            if \"transformation\" in props:\n",
        "                if props[\"transformation\"] == \"first4\":\n",
        "                    result = result.loc[result[blocking_criterion].str.startswith(\"[\" + props[\"value\"])]\n",
        "                elif props[\"transformation\"] == \"last4\":\n",
        "                    result = result.loc[result[blocking_criterion].str.endswith(props[\"value\"] + \"]\")]\n",
        "            else:\n",
        "                result = result.loc[result[blocking_criterion] == \"[\" + props[\"value\"] + \"]\"]\n",
        "\n",
        "        # Regular case is just a straight string comparison since we've already stripped the \n",
        "        # de-serialization quotes\n",
        "        else:\n",
        "            if \"transformation\" in props:\n",
        "                if props[\"transformation\"] == \"first4\":\n",
        "                    result = result.loc[result[blocking_criterion].str.startswith(props[\"value\"])]\n",
        "                elif props[\"transformation\"] == \"last4\":\n",
        "                    result = result.loc[result[blocking_criterion].str.endswith(props[\"value\"])]\n",
        "            else:\n",
        "                result = result.loc[result[blocking_criterion] == props[\"value\"]]\n",
        "    return result\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Function that compares a single blocked candidate from the MPI with the\n",
        "incoming, now flattened, record. Comparison functions for evaluating the linkage\n",
        "match are applied iteratively, and a net score is accumulated giving the\n",
        "total strength of the linkage match. This function is applied sequentially to\n",
        "each of the candidate records returned in the block.\n",
        "\"\"\"\n",
        "def spark_compare_df_helper(row, flattened_record, funcs, col_to_idx, matching_rule, **kwargs):\n",
        "\n",
        "    # Iteratively accumulate results of each feature-wise comparison\n",
        "    match_score = 0.0\n",
        "    for col in funcs:\n",
        "        func = funcs[col]\n",
        "        feature_idx_in_record = col_to_idx[col]\n",
        "        feature_in_record = flattened_record[feature_idx_in_record]\n",
        "\n",
        "        if \"fuzzy\" in func:\n",
        "            similarity_measure, fuzzy_threshold = _get_fuzzy_comp_params(col, **kwargs)\n",
        "\n",
        "            # Given name is a list (possibly including middle name), so our logic says\n",
        "            # concatenate all the values together and then fuzzy compare\n",
        "            if col == \"first_name\":\n",
        "                feature_in_record = \" \".join(feature_in_record)\n",
        "                feature_in_mpi = re.sub(r'\\[|\\]', \"\", row[col])\n",
        "                feature_in_mpi = feature_in_mpi.split(\", \")\n",
        "                feature_in_mpi = \" \".join(feature_in_mpi)\n",
        "                feature_score = compare_strings(feature_in_mpi, feature_in_record, similarity_measure)\n",
        "                match_score = _apply_score_contribution(\n",
        "                    feature_score, col, fuzzy_threshold, match_score, matching_rule, **kwargs\n",
        "                )\n",
        "\n",
        "            # Address is also a list, but rather than concatenate them all, we check if each\n",
        "            # line of an incoming address matches any line of an MPI address; this accounts for\n",
        "            # a patient's change of residence history\n",
        "            elif col == \"address\":\n",
        "                feature_in_mpi = re.sub(r'\\[|\\]', \"\", row[col])\n",
        "                feature_in_mpi = feature_in_mpi.split(\", \")\n",
        "                best_score = 0.0\n",
        "                for r in feature_in_record:\n",
        "                    for m in feature_in_mpi:\n",
        "                        feature_comp = compare_strings(r, m, similarity_measure)\n",
        "                        if feature_comp > best_score:\n",
        "                            best_score = feature_comp\n",
        "                match_score = _apply_score_contribution(\n",
        "                    best_score, col, fuzzy_threshold, match_score, matching_rule, **kwargs\n",
        "                )\n",
        "            \n",
        "            # Regular case: straight string comparison on the fields\n",
        "            else:\n",
        "                feature_in_mpi = row[col]\n",
        "                feature_score = compare_strings(feature_in_mpi, feature_in_record, similarity_measure)\n",
        "                match_score = _apply_score_contribution(\n",
        "                    feature_score, col, fuzzy_threshold, match_score, matching_rule, **kwargs\n",
        "                )\n",
        "        else:\n",
        "            pass\n",
        "\n",
        "    return pd.Series([row['patient_id'], match_score])\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Quick helper to extract the threshold and metric used in fuzzy string comparisons.\n",
        "We have this to not clutter the main analytic function.\n",
        "\"\"\"\n",
        "def _get_fuzzy_comp_params(col, **kwargs):\n",
        "    similarity_measure = \"JaroWinkler\"\n",
        "    if \"similarity_measure\" in kwargs:\n",
        "        similarity_measure = kwargs[\"similarity_measure\"]\n",
        "    threshold = 0.7\n",
        "    \n",
        "    # Optional unique threshold per column in the data\n",
        "    if \"thresholds\" in kwargs:\n",
        "        if col in kwargs[\"thresholds\"]:\n",
        "            threshold = kwargs[\"thresholds\"][col]\n",
        "    \n",
        "    # Single universal threshold for all fields\n",
        "    elif \"threshold\" in kwargs:\n",
        "        threshold = kwargs[\"threshold\"]\n",
        "        \n",
        "    return similarity_measure, threshold\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Helper to apply the result of a feature-wise comparison between an incoming record and a \n",
        "candidate from the MPI to the accumulated 'match score' of the two. In a 'normal' case\n",
        "where we're not using log-odds, this is just a count of the number of feature comparisons\n",
        "that satisfy the fuzzy string threshold. In the log-odds case, this is an accumulation of\n",
        "the weighted probability score that the two records are a match.\n",
        "\"\"\"\n",
        "def _apply_score_contribution(feature_score, col, fuzzy_threshold, match_score, match_rule, **kwargs):\n",
        "    if \"log\" in match_rule:\n",
        "        col_odds = kwargs[\"log_odds\"][col]\n",
        "        match_score += (feature_score * col_odds)\n",
        "    else:\n",
        "        if feature_score >= fuzzy_threshold:\n",
        "            match_score += 1.0\n",
        "    return match_score\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Orchestrator function that provisions the RDD-mapping of the parallel candidate evaluation.\n",
        "Once we've parallel-processed the candidates, we apply RDD filtering to identify only those\n",
        "candidates who satisfy the provided matching rule. (be that \"all feature-wise comparisons are\n",
        "true\" or \"total probability score exceeds log-odds cutoff\").\n",
        "\"\"\"\n",
        "def spark_compare(data_block: pd.DataFrame, record: List, funcs: dict, col_to_idx: dict, matching_rule, **kwargs):\n",
        "    res = data_block.apply(lambda x: spark_compare_df_helper(x, record, funcs, col_to_idx, matching_rule, **kwargs), axis=1)\n",
        "    if \"log\" in matching_rule:\n",
        "        match_cutoff = kwargs[\"true_match_threshold\"]\n",
        "    else:\n",
        "        match_cutoff = len(funcs)\n",
        "    match_list = res.loc[res[1] >= match_cutoff]\n",
        "    match_list = list(match_list[0])\n",
        "    return match_list\n",
        "\n",
        "\n",
        "'''\n",
        "Main driver function that's applied in parallel to each record of the incoming\n",
        "evaluation set. The procedure is much the same as if the record were being\n",
        "processed in real time, except that a pandas dataframe (rather than a networked\n",
        "DB) is used to retrieve the candidate block for speed purposes.\n",
        "'''\n",
        "def parallel_eval(record, algo_config: List[dict], labeling_set: pd.DataFrame, testing_field=None, testing_vals=None):\n",
        "\n",
        "    # Flatten incoming resource and remove any lurking None's\n",
        "    flattened_record = _flatten_patient_resource(record)\n",
        "    if flattened_record[2] is None:\n",
        "        flattened_record[2] = [\"\"]\n",
        "    if flattened_record[5] is None:\n",
        "        flattened_record[5] = [\"\"]\n",
        "\n",
        "    if testing_field:\n",
        "        matches = {str(x): [] for x in testing_vals}\n",
        "    else:\n",
        "        matches = []\n",
        "\n",
        "    for linkage_pass in algo_config:\n",
        "        blocking_fields = linkage_pass[\"blocks\"]\n",
        "        field_blocks = extract_blocking_values_from_record(record, blocking_fields)\n",
        "        if len(field_blocks) == 0:\n",
        "            continue\n",
        "        \n",
        "        # Use the extract of the MPI to quickly filter down a block of candidates\n",
        "        data_block = spark_block(field_blocks, labeling_set)\n",
        "        col_to_idx = {v: k for k, v in enumerate(formatted_cols)}\n",
        "\n",
        "        # Parallel process the candidates to find any matches\n",
        "        kwargs = linkage_pass.get(\"kwargs\", {})\n",
        "\n",
        "        if testing_field:\n",
        "            for tv in testing_vals:\n",
        "                vkwargs = copy.deepcopy(kwargs)\n",
        "                vkwargs[\"thresholds\"][testing_field] = tv\n",
        "                matching_records = spark_compare(\n",
        "                    data_block, flattened_record, linkage_pass[\"funcs\"], col_to_idx, linkage_pass[\"matching_rule\"], **vkwargs\n",
        "                )\n",
        "                matches[str(tv)] += matching_records\n",
        "        else:\n",
        "            matching_records = spark_compare(\n",
        "                data_block, flattened_record, linkage_pass[\"funcs\"], col_to_idx, linkage_pass[\"matching_rule\"], **kwargs\n",
        "            )\n",
        "            matches += matching_records\n",
        "\n",
        "    if testing_field:\n",
        "        return flattened_record[0], [matches[str(tv)] for tv in testing_vals]\n",
        "    else:\n",
        "        return flattened_record[0], matches\n",
        "\n",
        "\n",
        "'''\n",
        "Turn the patient_ids of identified \"found matches\" into the threaded multi-row-indices\n",
        "that the ground truth labeler can understand. This way, all indices are expressed in\n",
        "the same scheme for statistical comparison.\n",
        "'''\n",
        "def map_patient_ids_to_idxs(pids: List, data: pd.DataFrame):\n",
        "    record_idxs = []\n",
        "    for pid in pids:\n",
        "        row_idx = data[data['patient_id'] == pid].index.values\n",
        "        if len(row_idx) > 0:\n",
        "            record_idxs.append(row_idx[0])\n",
        "    return record_idxs\n",
        "\n",
        "\n",
        "'''\n",
        "Find existing patient records in a dataset that map to each incoming record in a block \n",
        "of FHIR data. Since the FHIR data itself is pulled from the MPI, we can freely use it\n",
        "for querying for blocks without risk of finding unrecognized data.\n",
        "'''\n",
        "def link_all_fhir_records_block_dataset(records, algo_config: List[dict], label_set: pd.DataFrame, formatted_cols, testing_field=None, testing_vals=None):\n",
        "    if testing_field:\n",
        "        if not testing_vals or len(testing_vals) == 0:\n",
        "            print(\"Must supply list of threshold values to test\")\n",
        "            return\n",
        "        found_matches = { str(x): {} for x in testing_vals }\n",
        "    else:\n",
        "        found_matches = {}\n",
        "    start = time.time()\n",
        "    res = records.map(lambda x: parallel_eval(x, algo_config, label_set, testing_field, testing_vals))\n",
        "    res.cache()\n",
        "\n",
        "    if testing_field:\n",
        "        for x in res.collect():\n",
        "            ridx = map_patient_ids_to_idxs([x[0]], label_set)[0]\n",
        "            for tv in range(len(x[1])):\n",
        "                linked_rs_at_threshold = x[1][tv]\n",
        "                lidx = set(linked_rs_at_threshold)\n",
        "                lidx = map_patient_ids_to_idxs(lidx, label_set)\n",
        "                found_matches[str(testing_vals[tv])][ridx] = set(lidx)\n",
        "            \n",
        "        print(\"finished linking \", str(time.time() - start))\n",
        "        return found_matches\n",
        "\n",
        "    else:\n",
        "        for x in res.collect():\n",
        "            ridx = map_patient_ids_to_idxs([x[0]], label_set)[0]\n",
        "            lidx = set(x[1])\n",
        "            lidx = map_patient_ids_to_idxs(lidx, label_set)\n",
        "            found_matches[ridx] = set(lidx)\n",
        "\n",
        "        print(\"finished linking \", str(time.time() - start))\n",
        "        return found_matches\n",
        "\n",
        "'''\n",
        "Due to transforming patient_ids back into indices, multiple tuples get inserted for each\n",
        "match, i.e. we record the link (i,j) and the link (j,i), which would skew our stats.\n",
        "This function eliminates these redundancies and makes sure each link is counted once.\n",
        "'''\n",
        "def dedupe_match_double_counts(match_dict, is_fuzzy_test=False):\n",
        "    if is_fuzzy_test:\n",
        "        for tv in match_dict:\n",
        "            sub_dict = match_dict[tv]\n",
        "            for k in sub_dict:\n",
        "                if k > 0:\n",
        "                    lower_set = set(list(range(k)))\n",
        "                    sub_dict[k] = sub_dict[k].difference(lower_set)\n",
        "                if k in sub_dict[k]:\n",
        "                    sub_dict[k].remove(k)\n",
        "        return match_dict\n",
        "    \n",
        "    for k in match_dict:\n",
        "        if k > 0:\n",
        "            lower_set = set(list(range(k)))\n",
        "            match_dict[k] = match_dict[k].difference(lower_set)\n",
        "        if k in match_dict[k]:\n",
        "            match_dict[k].remove(k)\n",
        "    return match_dict\n",
        "\n",
        "\n",
        "# Change the real None-type values back into their placeholders so we can mass-boolean filter\n",
        "labeling_set = labeling_set.replace({None: \"None\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# EXPERIMENTAL THRESHOLD ANALYSIS\n",
        "# Supplemental code used for experimentally determining the best fuzzy\n",
        "# matching threshold for a given field\n",
        "\n",
        "from phdi.linkage import DIBBS_BASIC\n",
        "import copy\n",
        "\n",
        "TESTING_FIELD = \"first_name\"\n",
        "TESTING_VALS = [0.85, 0.88, 0.90, 0.92, 0.95]\n",
        "\n",
        "\n",
        "def score_fuzzy_test(found_matches, true_matches, records_in_dataset, testing_vals):\n",
        "\n",
        "    # Need division by 2 because ordering is irrelevant, matches are symmetric\n",
        "    total_possible_matches = (records_in_dataset * (records_in_dataset - 1)) / 2.0\n",
        "    scores = {}\n",
        "    for tv in testing_vals:\n",
        "        true_positives = 0.0\n",
        "        false_positives = 0.0\n",
        "        false_negatives = 0.0\n",
        "        matches_at_threshold = found_matches[str(tv)]\n",
        "\n",
        "        for root_record in true_matches:\n",
        "            if root_record in matches_at_threshold:\n",
        "                true_positives += len(\n",
        "                    true_matches[root_record].intersection(matches_at_threshold[root_record])\n",
        "                )\n",
        "                false_positives += len(\n",
        "                    matches_at_threshold[root_record].difference(true_matches[root_record])\n",
        "                )\n",
        "                false_negatives += len(\n",
        "                    true_matches[root_record].difference(matches_at_threshold[root_record])\n",
        "                )\n",
        "            else:\n",
        "                false_negatives += len(true_matches[root_record])\n",
        "        for record in set(set(matches_at_threshold.keys()).difference(true_matches.keys())):\n",
        "            false_positives += len(matches_at_threshold[record])\n",
        "\n",
        "        sensitivity = round(true_positives / (true_positives + false_negatives), 3)\n",
        "        ppv = round(true_positives / (true_positives + false_positives), 3)\n",
        "        f1 = round(\n",
        "            (2 * true_positives) / (2 * true_positives + false_negatives + false_positives),\n",
        "            3,\n",
        "        )\n",
        "        f_half_num = (1.0 + 0.5**2) * true_positives\n",
        "        f_half_denom_new = (0.5**2) * false_negatives + false_positives\n",
        "        f_half = round(f_half_num / (f_half_num + f_half_denom_new), 3)\n",
        "        scores[str(tv)] = {\n",
        "            \"tp\": true_positives,\n",
        "            \"fp\": false_positives,\n",
        "            \"fn\": false_negatives,\n",
        "            \"sens\": sensitivity,\n",
        "            \"ppv\": ppv,\n",
        "            \"f1\": f1,\n",
        "            \"f_half\": f_half\n",
        "        }\n",
        "    \n",
        "    return scores\n",
        "\n",
        "\n",
        "new_algo = copy.deepcopy(DIBBS_BASIC)\n",
        "col_thresholds = {\n",
        "    \"address\": 0.85,\n",
        "    \"birthdate\": 0.85,\n",
        "    \"city\": 0.85,\n",
        "    \"first_name\": 0.85,\n",
        "    \"last_name\": 0.85,\n",
        "    \"mrn\": 0.85,\n",
        "    \"sex\": 0.85,\n",
        "    \"state\": 0.85,\n",
        "    \"zip\": 0.85\n",
        "}\n",
        "new_algo[0][\"kwargs\"] = { \"thresholds\": col_thresholds }\n",
        "new_algo[1][\"kwargs\"] = { \"thresholds\": col_thresholds }\n",
        "\n",
        "found_matches_dibbs_basic = link_all_fhir_records_block_dataset(evaluation_set, new_algo, labeling_set, formatted_cols, TESTING_FIELD, TESTING_VALS)\n",
        "found_matches_dibbs_basic = dedupe_match_double_counts(found_matches_dibbs_basic, True)\n",
        "eval_scores = score_fuzzy_test(found_matches_dibbs_basic, seer_labels, EVALUATION_SIZE, TESTING_VALS)\n",
        "for t in eval_scores:\n",
        "    print(t, eval_scores[t])\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ALGORITHM EVALUATION: LAC EXISTING\n",
        "\n",
        "LAC_ALGO = [\n",
        "    {\n",
        "        \"funcs\": {\n",
        "            \"first_name\": \"feature_match_fuzzy_string\",\n",
        "            \"last_name\": \"feature_match_fuzzy_string\",\n",
        "            \"address\": \"feature_match_fuzzy_string\",\n",
        "            \"mrn\": \"feature_match_fuzzy_string\",\n",
        "        },\n",
        "        \"blocks\": [\n",
        "            {\"value\": \"first_name\", \"transformation\": \"first4\"},\n",
        "            {\"value\": \"last_name\", \"transformation\": \"first4\"},\n",
        "            {\"value\": \"birthdate\"},\n",
        "        ],\n",
        "        \"matching_rule\": \"eval_perfect_match\",\n",
        "        \"cluster_ratio\": 0.9,\n",
        "    },\n",
        "    {\n",
        "        \"funcs\": {\n",
        "            \"first_name\": \"feature_match_fuzzy_string\",\n",
        "            \"last_name\": \"feature_match_fuzzy_string\",\n",
        "            \"address\": \"feature_match_fuzzy_string\",\n",
        "            \"mrn\": \"feature_match_fuzzy_string\",\n",
        "        },\n",
        "        \"blocks\": [\n",
        "            {\"value\": \"first_name\", \"transformation\": \"first4\"},\n",
        "            {\"value\": \"last_name\", \"transformation\": \"first4\"},\n",
        "            {\"value\": \"address\", \"transformation\": \"first4\"},\n",
        "        ],\n",
        "        \"matching_rule\": \"eval_perfect_match\",\n",
        "        \"cluster_ratio\": 0.9,\n",
        "    },\n",
        "    {\n",
        "        \"funcs\": {\n",
        "            \"first_name\": \"feature_match_fuzzy_string\",\n",
        "            \"last_name\": \"feature_match_fuzzy_string\",\n",
        "            \"address\": \"feature_match_fuzzy_string\",\n",
        "            \"mrn\": \"feature_match_fuzzy_string\",\n",
        "        },\n",
        "        \"blocks\": [\n",
        "            {\"value\": \"birthdate\"},\n",
        "        ],\n",
        "        \"matching_rule\": \"eval_perfect_match\",\n",
        "        \"cluster_ratio\": 0.9,\n",
        "    },\n",
        "]\n",
        "\n",
        "found_matches_lac = load_linkage_results(\"lac_algorithm_results\")\n",
        "if found_matches_lac is None:\n",
        "    found_matches_lac = link_all_fhir_records_block_dataset(evaluation_set, LAC_ALGO, labeling_set, formatted_cols)\n",
        "    found_matches_lac = dedupe_match_double_counts(found_matches_lac)\n",
        "    write_linkage_results(\"lac_algorithm_results\", found_matches_lac)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ALGORITHM EVALUATION: DIBBs BASIC\n",
        "from phdi.linkage import DIBBS_BASIC\n",
        "import copy\n",
        "\n",
        "new_algo = copy.deepcopy(DIBBS_BASIC)\n",
        "col_thresholds = {\n",
        "    \"address\": 0.85,\n",
        "    \"birthdate\": 0.85,\n",
        "    \"city\": 0.85,\n",
        "    \"first_name\": 0.85,\n",
        "    \"last_name\": 0.85,\n",
        "    \"mrn\": 0.85,\n",
        "    \"sex\": 0.85,\n",
        "    \"state\": 0.85,\n",
        "    \"zip\": 0.85\n",
        "}\n",
        "new_algo[0][\"kwargs\"] = { \"thresholds\": col_thresholds }\n",
        "new_algo[1][\"kwargs\"] = { \"thresholds\": col_thresholds }\n",
        "\n",
        "found_matches_dibbs_basic = load_linkage_results(\"dibbs_basic_algorithm_results\")\n",
        "if found_matches_dibbs_basic is None:\n",
        "    found_matches_dibbs_basic = link_all_fhir_records_block_dataset(evaluation_set, new_algo, labeling_set, formatted_cols)\n",
        "    found_matches_dibbs_basic = dedupe_match_double_counts(found_matches_dibbs_basic)\n",
        "    write_linkage_results(\"dibbs_basic_algorithm_results\", found_matches_dibbs_basic)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ALGORITHM EVALUATION: DIBBs ENHANCED\n",
        "from phdi.linkage import DIBBS_ENHANCED\n",
        "\n",
        "new_algo = copy.deepcopy(DIBBS_ENHANCED)\n",
        "col_thresholds = {\n",
        "    \"address\": 0.85,\n",
        "    \"birthdate\": 0.85,\n",
        "    \"city\": 0.85,\n",
        "    \"first_name\": 0.85,\n",
        "    \"last_name\": 0.85,\n",
        "    \"mrn\": 0.85,\n",
        "    \"sex\": 0.85,\n",
        "    \"state\": 0.85,\n",
        "    \"zip\": 0.85\n",
        "}\n",
        "del new_algo[0][\"kwargs\"][\"threshold\"]\n",
        "del new_algo[1][\"kwargs\"][\"threshold\"]\n",
        "new_algo[0][\"kwargs\"][\"thresholds\"] = col_thresholds\n",
        "new_algo[1][\"kwargs\"][\"thresholds\"] = col_thresholds\n",
        "\n",
        "found_matches_dibbs_enhanced = load_linkage_results(\"dibbs_enhanced_algorithm_results\")\n",
        "if found_matches_dibbs_enhanced is None:\n",
        "    found_matches_dibbs_enhanced = link_all_fhir_records_block_dataset(evaluation_set, new_algo, labeling_set, formatted_cols)\n",
        "    found_matches_dibbs_enhanced = dedupe_match_double_counts(found_matches_dibbs_enhanced)\n",
        "    write_linkage_results(\"dibbs_enhanced_algorithm_results\", found_matches_dibbs_enhanced)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RECOMPUTE AND EXPORT LOG-ODDS\n",
        "\n",
        "from phdi.linkage import calculate_m_probs, calculate_log_odds\n",
        "import json\n",
        "from random import randint\n",
        "\n",
        "def calculate_u_probs(\n",
        "    data: pd.DataFrame,\n",
        "    true_matches: dict,\n",
        "    n_samples: int,\n",
        "):\n",
        "\n",
        "    # Quick heuristic check to make sure we can generate enough\n",
        "    # negative samples to satisfy the parameter request\n",
        "    max_combos = (len(data.index) * (len(data.index) - 1)) / 2.0\n",
        "    # Based on bernoulli limits for deterministic runtimes, don't worry about the ln(2)\n",
        "    # This is how many neg pairs you can expect to generate in reasonable time\n",
        "    runtime_sample_neg_ceiling = np.log(2) * 0.10 * max_combos\n",
        "    if n_samples >= runtime_sample_neg_ceiling:\n",
        "        print(\"Too many samples requested for data size. Lower n_samples parameter.\")\n",
        "        return\n",
        "\n",
        "    u_probs = {c: 1.0 for c in data.columns}\n",
        "    neg_pairs = set()\n",
        "\n",
        "    # Use speed of RNGers to take a sample out of all possible non-match pairs\n",
        "    # without explicitly constructing the list\n",
        "    while len(neg_pairs) < n_samples:\n",
        "        idx1 = randint(0, len(data.index)-1)\n",
        "        idx2 = randint(0, len(data.index)-1)\n",
        "        root = min(idx1, idx2)\n",
        "        ref = max(idx1, idx2)\n",
        "        if root not in true_matches or ref not in true_matches[root]:\n",
        "            neg_pairs.add((root, ref))\n",
        "\n",
        "    neg_pairs = list(neg_pairs)\n",
        "\n",
        "    # Count up the number of candidate pairs that have a field that matches,\n",
        "    # then normalize per field\n",
        "    for root, ref in neg_pairs:\n",
        "        for c in data.columns:\n",
        "            if data[c].iloc[root] == data[c].iloc[ref]:\n",
        "                u_probs[c] += 1.0\n",
        "    for c in data.columns:\n",
        "            u_probs[c] = u_probs[c] / (n_samples + 1.0)\n",
        "\n",
        "    return u_probs\n",
        "\n",
        "m_probs = calculate_m_probs(labeling_set, seer_labels)\n",
        "\n",
        "# For small data sets (< 10k records), use 50k sample size.\n",
        "# For mid sized (10k - 25k records), use 75k samples\n",
        "# Any larger, don't go above 100k samples\n",
        "u_probs = calculate_u_probs(labeling_set, seer_labels, n_samples=50000)\n",
        "\n",
        "log_odds = calculate_log_odds(m_probs, u_probs)\n",
        "log_odds.pop(\"patient_id\")\n",
        "log_odds.pop(\"person_id\")\n",
        "mssparkutils.fs.put(LINKAGE_OUTPUTS_FILESYSTEM + \"updated_log_odds.json\", json.dumps(log_odds), True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# PROFILE LOG-ODDS WEIGHTS FOR CUTOFF DETERMINATION\n",
        "# Run computations on the log-odds cutoff scores for both matches and non-matches\n",
        "# for later graphical evaluation\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def profiling_df_helper(data, idx_i, idx_j, fuzzy_cols, log_odds, col_to_idx):\n",
        "\n",
        "    # Iteratively accumulate results of each feature-wise comparison\n",
        "    match_score = 0.0\n",
        "    ri = data[idx_i]\n",
        "    rj = data[idx_j]\n",
        "\n",
        "    for col in fuzzy_cols:\n",
        "        col_odds = log_odds[col]\n",
        "        cidx = col_to_idx[col]\n",
        "        similarity_measure=\"JaroWinkler\"\n",
        "        min_sim_threshold = 0.85\n",
        "\n",
        "        # Given name is a list (possibly including middle name), so our logic says\n",
        "        # concatenate all the values together and then fuzzy compare\n",
        "        if col == \"first_name\":\n",
        "            feature_in_record = re.sub(r'\\[|\\]', \"\", ri[cidx])\n",
        "            feature_in_record = feature_in_record.split(\", \")\n",
        "            feature_in_record = \" \".join(feature_in_record)\n",
        "            feature_in_mpi = re.sub(r'\\[|\\]', \"\", rj[cidx])\n",
        "            feature_in_mpi = feature_in_mpi.split(\", \")\n",
        "            feature_in_mpi = \" \".join(feature_in_mpi)\n",
        "            feature_score = compare_strings(feature_in_mpi, feature_in_record, similarity_measure)\n",
        "\n",
        "        # Address is also a list, but rather than concatenate them all, we check if each\n",
        "        # line of an incoming address matches any line of an MPI address; this accounts for\n",
        "        # a patient's change of residence history\n",
        "        elif col == \"address\":\n",
        "            feature_in_record = re.sub(r'\\[|\\]', \"\", ri[cidx])\n",
        "            feature_in_record = feature_in_record.split(\", \")\n",
        "            feature_in_mpi = re.sub(r'\\[|\\]', \"\", rj[cidx])\n",
        "            feature_in_mpi = feature_in_mpi.split(\", \")\n",
        "            feature_score = 0.0\n",
        "            for r in feature_in_record:\n",
        "                for m in feature_in_mpi:\n",
        "                    feature_comp = compare_strings(r, m, similarity_measure)\n",
        "                    if feature_comp > feature_score:\n",
        "                        feature_score = feature_comp\n",
        "        \n",
        "        # Regular case: straight string comparison on the fields\n",
        "        else:\n",
        "            feature_in_record = ri[cidx]\n",
        "            feature_in_mpi = rj[cidx]\n",
        "            feature_score = compare_strings(feature_in_mpi, feature_in_record, similarity_measure)\n",
        "        \n",
        "        # Potential match gets no points if strings are too dissimilar\n",
        "        # Prevents accumulations of minimal points from every field swaying the results\n",
        "        if feature_score < min_sim_threshold:\n",
        "            feature_score = 0.0\n",
        "        match_score += feature_score * col_odds\n",
        "\n",
        "    return match_score\n",
        "\n",
        "\n",
        "def profile_log_odds_computation(\n",
        "    data: pd.DataFrame,\n",
        "    true_matches: dict,\n",
        "    log_odds: dict,\n",
        "    fuzzy_cols,\n",
        "    neg_samples: int = 50000,\n",
        "):\n",
        "    neg_pairs = set()\n",
        "    while len(neg_pairs) < neg_samples:\n",
        "        idx1 = randint(0, len(data.index)-1)\n",
        "        idx2 = randint(0, len(data.index)-1)\n",
        "        root = min(idx1, idx2)\n",
        "        ref = max(idx1, idx2)\n",
        "        if root not in true_matches or ref not in true_matches[root]:\n",
        "            neg_pairs.add((root, ref))\n",
        "\n",
        "    neg_pairs = list(neg_pairs)\n",
        "\n",
        "    data_cols = list(data.columns)\n",
        "    col_to_idx = dict(zip(data_cols, range(len(data_cols))))\n",
        "    data = data.values.tolist()\n",
        "\n",
        "    true_match_scores = []\n",
        "    for root_record, paired_records in true_matches.items():\n",
        "        for pr in paired_records:\n",
        "            score = profiling_df_helper(data, root_record, pr, fuzzy_cols, log_odds, col_to_idx)\n",
        "            true_match_scores.append(score)\n",
        "\n",
        "    non_match_scores = []\n",
        "    for record_1, record_2 in neg_pairs:\n",
        "        score = profiling_df_helper(data, record_1, record_2, fuzzy_cols, log_odds, col_to_idx)\n",
        "        non_match_scores.append(score)\n",
        "    \n",
        "    return true_match_scores, non_match_scores\n",
        "\n",
        "match_scores, non_match_scores = profile_log_odds_computation(labeling_set, seer_labels, log_odds, [\"address\", \"city\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# VISUALIZE LOG-ODDS GRAPH\n",
        "# Graphically displays elbow curves of the log-odds total match scores for both\n",
        "# true matches and true non-matches (as determined by SEER labels) so that the\n",
        "# separating hyperplane can be determined.\n",
        "\n",
        "def show_profiling_graph(match_scores, non_match_scores):\n",
        "\n",
        "    # TODO: Verify non-min-length works on larger prod data set; if it doesn't,\n",
        "    # uncomment this block\n",
        "\n",
        "    # min_length = min(len(true_match_scores), len(non_match_scores))\n",
        "    # true_match_scores = true_match_scores[:min_length]\n",
        "    # non_match_scores = non_match_scores[:min_length]\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    fig.set_size_inches(12,6)\n",
        "    _, bins, _ = plt.hist(match_scores, bins=75, range=[0, 25])\n",
        "    _ = plt.hist(non_match_scores, bins=bins, alpha=0.5)\n",
        "\n",
        "    # Adjust the density of tick marks here to find the best separation boundary\n",
        "    ax.xaxis.set_major_locator(plt.MaxNLocator(20))\n",
        "\n",
        "    # Use this min and max of the x axis to effectively zoom in\n",
        "    # ax.set_xlim([6,8])\n",
        "    plt.show()\n",
        "\n",
        "show_profiling_graph(match_scores, non_match_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RUN THE NUMBERS AND GET THE STATS FUNCTIONS\n",
        "\n",
        "'''\n",
        "To ensure accurate statistics, the matches and the true matches dictionaries\n",
        "in the statistical evaluation function should have the following form:\n",
        "\n",
        "{\n",
        "    row_num_of_record_in_data: set(row_nums_of_linked_records)\n",
        "}\n",
        "\n",
        "Each row in the data should be represented as a key in both dictionaries.\n",
        "The value for each of these keys should be a set that contains all other\n",
        "row numbers for records in the data set that link to the key record.\n",
        "'''\n",
        "\n",
        "def score_linkage_vs_truth(found_matches, true_matches, records_in_dataset):\n",
        "\n",
        "    # Need division by 2 because ordering is irrelevant, matches are symmetric\n",
        "    total_possible_matches = (records_in_dataset * (records_in_dataset - 1)) / 2.0\n",
        "    true_positives = 0.0\n",
        "    false_positives = 0.0\n",
        "    false_negatives = 0.0\n",
        "\n",
        "    for root_record in true_matches:\n",
        "        if root_record in found_matches:\n",
        "            true_positives += len(\n",
        "                true_matches[root_record].intersection(found_matches[root_record])\n",
        "            )\n",
        "            false_positives += len(\n",
        "                found_matches[root_record].difference(true_matches[root_record])\n",
        "            )\n",
        "            false_negatives += len(\n",
        "                true_matches[root_record].difference(found_matches[root_record])\n",
        "            )\n",
        "        else:\n",
        "            false_negatives += len(true_matches[root_record])\n",
        "    for record in set(set(found_matches.keys()).difference(true_matches.keys())):\n",
        "        false_positives += len(found_matches[record])\n",
        "\n",
        "    true_negatives = (\n",
        "        total_possible_matches - true_positives - false_positives - false_negatives\n",
        "    )\n",
        "    npv = round((true_negatives / (true_negatives + false_negatives)), 3)\n",
        "    sensitivity = round(true_positives / (true_positives + false_negatives), 3)\n",
        "    specificity = round(true_negatives / (true_negatives + false_positives), 3)\n",
        "    ppv = round(true_positives / (true_positives + false_positives), 3)\n",
        "    f1 = round(\n",
        "        (2 * true_positives) / (2 * true_positives + false_negatives + false_positives),\n",
        "        3,\n",
        "    )\n",
        "    return {\n",
        "        \"tp\": true_positives,\n",
        "        \"fp\": false_positives,\n",
        "        \"fn\": false_negatives,\n",
        "        \"sens\": sensitivity,\n",
        "        \"spec\": specificity,\n",
        "        \"ppv\": ppv,\n",
        "        \"npv\": npv,\n",
        "        \"f1\": f1\n",
        "    }\n",
        "\n",
        "display_str = \"\"\n",
        "n_records = EVALUATION_SIZE\n",
        "\n",
        "for lbl_type in [\"va\", \"uk-nhs\", \"nci-seer\"]:\n",
        "    if lbl_type == \"va\":\n",
        "        labels = va_labels\n",
        "    elif lbl_type == \"nci-seer\":\n",
        "        labels = seer_labels\n",
        "    else:\n",
        "        labels = uk_labels\n",
        "    \n",
        "    stats_dict_lac = score_linkage_vs_truth(found_matches_lac, labels, n_records)\n",
        "    stats_dict_dibbs_b = score_linkage_vs_truth(found_matches_dibbs_basic, labels, n_records)\n",
        "    stats_dict_dibbs_e = score_linkage_vs_truth(found_matches_dibbs_enhanced, labels, n_records)\n",
        "\n",
        "    display_str += \"DISPLAYING EVALUATION ON \" + lbl_type.upper() + \" LABELS:\\n\"\n",
        "    display_str += \"\\n\"\n",
        "\n",
        "    for algo in [\"lac\", \"basic\", \"enhanced\"]:\n",
        "        if algo == \"lac\":\n",
        "            display_str += \"LAC Existing Algorithm:\\n\"\n",
        "            scores = stats_dict_lac\n",
        "        elif algo == \"basic\":\n",
        "            display_str += \"DIBBs Basic Algorithm:\\n\"\n",
        "            scores = stats_dict_dibbs_b\n",
        "        else:\n",
        "            display_str += \"DIBBs Log-Odds Algorithm:\\n\"\n",
        "            scores = stats_dict_dibbs_e\n",
        "\n",
        "        display_str += \"True Positives: \" + str(scores[\"tp\"]) + \"\\n\"\n",
        "        display_str += \"False Positives: \" + str(scores[\"fp\"]) + \"\\n\"\n",
        "        display_str += \"False Negatives: \" + str(scores[\"fn\"]) + \"\\n\"\n",
        "        display_str += \"Sensitivity: \" + str(scores[\"sens\"]) + \"\\n\"\n",
        "        display_str += \"Specificity: \" + str(scores[\"spec\"]) + \"\\n\"\n",
        "        display_str += \"PPV: \" + str(scores[\"ppv\"]) + \"\\n\"\n",
        "        display_str += \"NPV: \" + str(scores[\"npv\"]) + \"\\n\"\n",
        "        display_str += \"F1: \" + str(scores[\"f1\"]) + \"\\n\"\n",
        "        display_str += \"\\n\"\n",
        "    \n",
        "    display_str += \"\\n\"\n",
        "\n",
        "print(display_str)\n",
        "\n",
        "mssparkutils.fs.put(LINKAGE_OUTPUTS_FILESYSTEM + \"results.txt\", display_str, True)"
      ]
    }
  ],
  "metadata": {
    "description": null,
    "kernel_info": {
      "name": "synapse_pyspark"
    },
    "kernelspec": {
      "display_name": "Synapse PySpark",
      "language": "Python",
      "name": "synapse_pyspark"
    },
    "language_info": {
      "name": "python"
    },
    "save_output": true,
    "synapse_widget": {
      "state": {},
      "version": "0.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
