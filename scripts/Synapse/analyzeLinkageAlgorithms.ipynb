{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# analyzeLinkageAlgorithms\n",
        "This notebook serves as a one-stop shop for record linkage analysis, experimentation, and evaluation. By adjusting the parameter settings and runtime mode below, a user can perform the following:\n",
        "\n",
        "* Run a comparative analysis of three record linkage algorithms: a python implementation of LAC's current algorithm (without post-processing heuristics and in general form), the DIBBs Basic algorithm, and the DIBBs Log-Odds enhanced algorithm.\n",
        "* Train an updated set of DIBBs Enhanced Algorithm log-odds weights to suit a specific suite of production data. Then, visually profile and identify cutoff thresholds for each pass of the DIBBs Enhanced Algorithm using previously trained or newly trained log-odds weights.\n",
        "* Simultaneously test a suite of different fuzzy matching thresholds for one or more fields of patient data.\n",
        "\n",
        "Much of the code used in these tasks overlaps, but to help facilitate easy use, the notebook is divided into many smaller sections with called-out settings and explanations specific to the desired tasks.\n",
        "\n",
        "To begin, run the line below to install the notebook's dependencies; then, select which mode you'd like to run the notebook in."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install --upgrade pip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "pip install psycopg2-binary azure-identity recordlinkage azure-keyvault-secrets rapidfuzz numpy pandas matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Mode Selection\n",
        "In the cell below, enter the string corresponding to the mode you'd like to run the notebook in:\n",
        "\n",
        "* `\"compare_algorithms\"`: this mode performs a computational comparison in the performance of the three algorithms of interest (a Python port of LAC's current algorithm, DIBBs Basic, and DIBBs Enhanced). Individual algorithm results are saved along the way, and final results are both displayed in the notebook as well as exported to a file for saving.\n",
        "* `\"train_weights\"`: this mode computes population-appropriate weights for each field of patient data in the extract loaded from the MPI. These new weights serve as the log-odds scores in the DIBBs Enhanced algorithm. Generating these weights does not require any running of a record linkage algorithm and is a fairly quick process; however, graphically profiling the impact of the trained weights does. Once the weights are computed, the notebook runs each pass of the DIBBs enhanced algorithm in isolation, accumulating the scores each record _would have earned_ if linkage were being run in full. The distributions of these scores are used in concert with the labels the notebook generates to visually separate the true matches from the non-matches, so that a user can identify a cutoff line to use as a new parameter setting in the Enhanced algorithm.\n",
        "* `\"test_thresholds\"`: this mode evaluates a list of different fuzzy matching thresholds for a single field of patient data (e.g. `birthdate` or `first_name`). Each provided possible threshold has a subset of performance statistics computed for it, and when the testing framework completes, these values are reported for each tested threshold so that a user can determine which threshold performed the best.\n",
        "\n",
        "These modes are mutually exclusive with one another--e.g., running `train_weights` will preclude running `test_thresholds`. Each of these modes has different mode-specific parameter settings, which can be configured in the sections below.\n",
        "\n",
        "Once the MPI has been seeded, any of these three modes can be run before any others, but if all functionality is desired from all parts, the most logical sequence would be the following:\n",
        "\n",
        "* for each field of interest, run the notebook in `test_thresholds` mode to identify the best fuzzy matching-threshold for each field to-be-used in the desired algorithm; `test_thresholds` mode relies only on the DIBBs Basic Algorithm, meaning it needs no additional inputs or functions from weight training or the enhanced algorithm\n",
        "* modify the settings for `train_weights` mode by adding these experimentally determined per-field thresholds to the `COLS_TO_THRESHOLDS` parameter in the form of key-value pairs (i.e. `\"first_name_\": 0.92`)\n",
        "* run the notebook in `train_weights` mode once for each pass of the algorithm to adjust (for the DIBBs algorithm, this will be twice), passing in the appropriate `cols_to_profile` values for the pass of interest; for each such run, use the profiling graph to determine the best cutoff threshold for each pass\n",
        "* modify the settings for `compare_algorithms` mode by updaing the final cutoff threshold parameters and the new, updated log-odds weights with these experimentally determined values\n",
        "* run the notebook in `compare_algorithms` mode to see the performance impacts of the tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# MODE SELECTION\n",
        "# Options are: \"compare_algorithms\", \"train_weights\", and \"test_thresholds\"\n",
        "NOTEBOOK_MODE = \"compare_algorithms\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## MPI Access Configuration\n",
        "The cell below contains the settings to-be configured to ensure the notebook can access the MPI in which production data is stored. Configure the db_client information and table names to reflect the structure of the MPI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set your Key Vault information\n",
        "vault_name = \"$KEY_VAULT\"\n",
        "KEY_VAULT_URL = f\"https://{vault_name}.vault.azure.net\"\n",
        "vault_linked_service = \"$KEY_VAULT_LINKED_SERVICE\"\n",
        "\n",
        "# Set up db_client\n",
        "DB_NAME = \"DibbsMpiDB\"\n",
        "DB_USER = \"postgres\"\n",
        "DB_HOST = \"$MPI_DB_HOST\"\n",
        "DB_PORT = \"5432\"\n",
        "\n",
        "# MPI table names\n",
        "DB_TABLE_PATIENT = \"patient\"\n",
        "DB_TABLE_PERSON = \"person\"\n",
        "DB_TABLE_NAME = \"name\"\n",
        "DB_TABLE_GIVEN_NAME = \"given_name\"\n",
        "DB_TABLE_ADDRESS = \"address\"\n",
        "DB_TABLE_IDENTIFIER = \"identifier\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## General Notebook Settings\n",
        "The cell below contains a selection of imports and configuration options which are used across all modes. These settings include configuration of the size of the dataset to use, tuning thresholds for ground-truth labeling, and the window size of the neighborhood to search around each field when building the indexer (see below)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imports for secure access and ground-truth labeling\n",
        "from azure.identity import DefaultAzureCredential\n",
        "import time\n",
        "import copy\n",
        "import pandas as pd\n",
        "import recordlinkage as rl\n",
        "from recordlinkage.base import BaseCompareFeature\n",
        "import numpy as np\n",
        "\n",
        "# Adjust data volume for scaling\n",
        "# Make sure evaluation size is less than or equal to labeling size!\n",
        "# If running in `compare_algorithms` mode or `train_weights` mode, we recommend both sizes be set to 150000.\n",
        "# If running in `test_thresholds` mode, we recommend any value between 50000 and 150000.\n",
        "LABELING_SIZE = 200000\n",
        "EVALUATION_SIZE = 200000\n",
        "\n",
        "# Adjust the parameteres for ground truth labeling.\n",
        "# Window size is the number of nearest neighbors that will be chosen as possible candidates\n",
        "# during the indexing of each field. We recommend a value no larger than 7.\n",
        "# Jaro Threshold and Birthday threshold are \"fuzzy match\" thresholds used by the true-match\n",
        "# labelers to decide if two candidates are indeed a match. Birthday should not be set below 0.95.\n",
        "# Jaro can be set anywhere above 0.85, but we recommend at least 0.9.\n",
        "WINDOW_INDEX_SIZE = 5\n",
        "JARO_THRESHOLD = 0.9\n",
        "BIRTHDAY_THRESHOLD = 0.95"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# DEFAULT DIBBS ALGORITHMS\n",
        "\n",
        "# UPDATED DIBBs ALGORITHMS\n",
        "# These algorithms and log odds scores are the updated values developed after\n",
        "# substantial statistical tuning. Older algorithms can be found below.\n",
        "DIBBS_ENHANCED_LOG_ODDS_SCORES = {\n",
        "    'address': 8.438284928858774,\n",
        "    'birthdate': 10.126641103800338,\n",
        "    'city': 2.438553006137189,\n",
        "    'first_name': 6.849475906891162,\n",
        "    'last_name': 6.350720397426025,\n",
        "    'mrn': 0.3051262572525359,\n",
        "    'sex': 0.7510419059643679,\n",
        "    'state': 0.022376768992488694,\n",
        "    'zip': 4.975031471124867\n",
        "}\n",
        "FUZZY_THRESHOLDS = {\n",
        "    \"first_name\": 0.9,\n",
        "    \"last_name\": 0.9,\n",
        "    \"birthdate\": 0.95,\n",
        "    \"address\": 0.9,\n",
        "    \"city\": 0.92,\n",
        "    \"zip\": 0.95\n",
        "}\n",
        "\n",
        "DIBBS_BASIC = [\n",
        "    {\n",
        "        \"funcs\": {\n",
        "            \"first_name\": \"feature_match_fuzzy_string\",\n",
        "            \"last_name\": \"feature_match_exact\",\n",
        "        },\n",
        "        \"blocks\": [\n",
        "            {\"value\": \"birthdate\"},\n",
        "            {\"value\": \"mrn\", \"transformation\": \"last4\"},\n",
        "            {\"value\": \"sex\"}\n",
        "        ],\n",
        "        \"matching_rule\": \"eval_perfect_match\",\n",
        "        \"cluster_ratio\": 0.9,\n",
        "        \"kwargs\": {\n",
        "            \"thresholds\": FUZZY_THRESHOLDS\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"funcs\": {\n",
        "            \"address\": \"feature_match_fuzzy_string\",\n",
        "            \"birthdate\": \"feature_match_exact\",\n",
        "        },\n",
        "        \"blocks\": [\n",
        "            {\"value\": \"zip\"},\n",
        "            {\"value\": \"first_name\", \"transformation\": \"first4\"},\n",
        "            {\"value\": \"last_name\", \"transformation\": \"first4\"},\n",
        "            {\"value\": \"sex\"},\n",
        "        ],\n",
        "        \"matching_rule\": \"eval_perfect_match\",\n",
        "        \"cluster_ratio\": 0.9,\n",
        "        \"kwargs\": {\n",
        "            \"thresholds\": FUZZY_THRESHOLDS\n",
        "        }\n",
        "    }\n",
        "]\n",
        "\n",
        "DIBBS_ENHANCED = [\n",
        "    {\n",
        "        \"funcs\": {\n",
        "            \"first_name\": \"feature_match_log_odds_fuzzy_compare\",\n",
        "            \"last_name\": \"feature_match_log_odds_fuzzy_compare\",\n",
        "        },\n",
        "        \"blocks\": [\n",
        "            {\"value\": \"birthdate\"},\n",
        "            {\"value\": \"mrn\", \"transformation\": \"last4\"},\n",
        "            {\"value\": \"sex\"}\n",
        "        ],\n",
        "        \"matching_rule\": \"eval_log_odds_cutoff\",\n",
        "        \"cluster_ratio\": 0.9,\n",
        "        \"kwargs\": {\n",
        "            \"similarity_measure\": \"JaroWinkler\",\n",
        "            \"thresholds\": FUZZY_THRESHOLDS,\n",
        "            \"true_match_threshold\": 12.2,\n",
        "            \"log_odds\": DIBBS_ENHANCED_LOG_ODDS_SCORES,\n",
        "        },\n",
        "    },\n",
        "    {\n",
        "        \"funcs\": {\n",
        "            \"address\": \"feature_match_log_odds_fuzzy_compare\",\n",
        "            \"birthdate\": \"feature_match_log_odds_fuzzy_compare\",\n",
        "        },\n",
        "        \"blocks\": [\n",
        "            {\"value\": \"zip\"},\n",
        "            {\"value\": \"first_name\", \"transformation\": \"first4\"},\n",
        "            {\"value\": \"last_name\", \"transformation\": \"first4\"},\n",
        "            {\"value\": \"sex\"},\n",
        "        ],\n",
        "        \"matching_rule\": \"eval_log_odds_cutoff\",\n",
        "        \"cluster_ratio\": 0.9,\n",
        "        \"kwargs\": {\n",
        "            \"similarity_measure\": \"JaroWinkler\",\n",
        "            \"thresholds\": FUZZY_THRESHOLDS,\n",
        "            \"true_match_threshold\": 17.0,\n",
        "            \"log_odds\": DIBBS_ENHANCED_LOG_ODDS_SCORES,\n",
        "        },\n",
        "    }\n",
        "]\n",
        "\n",
        "# OLD DIBBs ALGORITHMS\n",
        "# The algorithms and information listed below represents the preliminary\n",
        "# algorithms DIBBs developed, prior to tuning and experimentation. They \n",
        "# are included here mostly for posterity.\n",
        "\n",
        "# DIBBS_ENHANCED_LOG_ODDS_SCORES = {\n",
        "#     \"birthdate\": 9.944142836217619,\n",
        "#     \"first_name\": 8.009121400325398,\n",
        "#     \"last_name\": 5.327681398982514,\n",
        "#     \"sex\": 0.6964525713514773,\n",
        "#     \"address\": 5.769942276960749,\n",
        "#     \"city\": 1.8002552875091014,\n",
        "#     \"state\": 0.0,\n",
        "#     \"zip\": 4.909466232098861,\n",
        "#     \"mrn\": 1.464232660081324,\n",
        "# }\n",
        "\n",
        "# DIBBS_BASIC = [\n",
        "#     {\n",
        "#         \"funcs\": {\n",
        "#             \"first_name\": \"feature_match_fuzzy_string\",\n",
        "#             \"last_name\": \"feature_match_fuzzy_string\",\n",
        "#             \"birthdate\": \"feature_match_fuzzy_string\",\n",
        "#         },\n",
        "#         \"blocks\": [\n",
        "#             {\"value\": \"mrn\", \"transformation\": \"last4\"},\n",
        "#             {\"value\": \"address\", \"transformation\": \"first4\"},\n",
        "#         ],\n",
        "#         \"matching_rule\": \"eval_perfect_match\",\n",
        "#         \"cluster_ratio\": 0.9,\n",
        "#     },\n",
        "#     {\n",
        "#         \"funcs\": {\n",
        "#             \"address\": \"feature_match_fuzzy_string\",\n",
        "#             \"city\": \"feature_match_fuzzy_string\",\n",
        "#         },\n",
        "#         \"blocks\": [\n",
        "#             {\"value\": \"first_name\", \"transformation\": \"first4\"},\n",
        "#             {\"value\": \"last_name\", \"transformation\": \"first4\"},\n",
        "#         ],\n",
        "#         \"matching_rule\": \"eval_perfect_match\",\n",
        "#         \"cluster_ratio\": 0.9,\n",
        "#     },\n",
        "# ]\n",
        "\n",
        "# DIBBS_ENHANCED = [\n",
        "#     {\n",
        "#         \"funcs\": {\n",
        "#             \"birthdate\": \"feature_match_log_odds_fuzzy_compare\",\n",
        "#             \"first_name\": \"feature_match_log_odds_fuzzy_compare\",\n",
        "#             \"last_name\": \"feature_match_log_odds_fuzzy_compare\",\n",
        "#         },\n",
        "#         \"blocks\": [\n",
        "#             {\"value\": \"mrn\", \"transformation\": \"last4\"},\n",
        "#             {\"value\": \"address\", \"transformation\": \"first4\"},\n",
        "#         ],\n",
        "#         \"matching_rule\": \"eval_log_odds_cutoff\",\n",
        "#         \"cluster_ratio\": 0.9,\n",
        "        # \"kwargs\": {\n",
        "        #     \"similarity_measure\": \"JaroWinkler\",\n",
        "        #     \"threshold\": 0.7,\n",
        "        #     \"true_match_threshold\": 16.5,\n",
        "        #     \"log_odds\": DIBBS_ENHANCED_LOG_ODDS_SCORES,\n",
        "        # },\n",
        "#     },\n",
        "#     {\n",
        "#         \"funcs\": {\n",
        "#             \"zip\": \"feature_match_log_odds_fuzzy_compare\",\n",
        "#             \"city\": \"feature_match_log_odds_fuzzy_compare\",\n",
        "#         },\n",
        "#         \"blocks\": [\n",
        "#             {\"value\": \"first_name\", \"transformation\": \"first4\"},\n",
        "#             {\"value\": \"last_name\", \"transformation\": \"first4\"},\n",
        "#         ],\n",
        "#         \"matching_rule\": \"eval_log_odds_cutoff\",\n",
        "#         \"cluster_ratio\": 0.9,\n",
        "#         \"kwargs\": {\n",
        "#             \"similarity_measure\": \"JaroWinkler\",\n",
        "#             \"threshold\": 0.7,\n",
        "#             \"true_match_threshold\": 7.0,\n",
        "#             \"log_odds\": DIBBS_ENHANCED_LOG_ODDS_SCORES,\n",
        "#         },\n",
        "#     },\n",
        "# ]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Mode-Specific Settings\n",
        "The cell below contains additional parameter settings that can be tuned "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SETTINGS FOR `test_thresholds` MODE\n",
        "# Testing field can be any supported field name in a patient resource\n",
        "# We recommend testing no more than 7 values at once\n",
        "TESTING_FIELD = \"first_name\"\n",
        "TESTING_VALS = [0.85, 0.88, 0.90, 0.92, 0.95]\n",
        "\n",
        "# SETTINGS FOR `train_weights` MODE\n",
        "# For small data sets (< 10k records), use 50k neg samples.\n",
        "# For mid sized (10k - 25k records), use 75k samples.\n",
        "# Any larger, don't go above 100k samples.\n",
        "NEG_SAMPLES = 100000\n",
        "# Cols_to_profile should be an array of field names corresponding to one pass\n",
        "# of a linkage algorithm. This means to run profiling for DIBBs,\n",
        "# two separate runs will have to be made (since each pass has its own cutoff).\n",
        "# Pass 1 should be [\"first_name\", \"last_name\", \"birthdate\"]\n",
        "# Pass 2 should be [\"address\", \"city\"]\n",
        "COLS_TO_PROFILE = [\"first_name\", \"last_name\", \"birthdate\"]\n",
        "# Cols_to_thresholds should be a dictionary mapping field name strings (e.g.\n",
        "# \"first_name\") to floats giving the minimum fuzzy matching threshold permissible\n",
        "# to count for enhaned weight scoring. These numbers can be experimentally\n",
        "# determined using the `test_thresholds` mode.\n",
        "COLS_TO_THRESHOLDS = {\n",
        "    \"first_name\": 0.9,\n",
        "    \"last_name\": 0.9,\n",
        "    \"birthdate\": 0.95,\n",
        "    \"address\": 0.9,\n",
        "    \"city\": 0.92,\n",
        "    \"zip\": 0.95\n",
        "}\n",
        "\n",
        "# SETTINGS FOR `compare_algorithms` MODE\n",
        "# Before running any algorithm, check the `linkage-notebook-outputs` container of the \n",
        "# storage account for the environment this notebook is running in. We might have a \n",
        "# previously saved linkage result there for this algorithm. If so, load that\n",
        "# instead of rerunning the algorithm now. Safe to use in any situation where the order\n",
        "# of data in the MPI doesn't change. If you want to leave this setting as True\n",
        "# for some algorithms but still force others to re-run, simply manually delete\n",
        "# that algorithm's output file in the Azure container associated with linkage results.\n",
        "LOAD_PREVIOUS_RUNS = True\n",
        "# Final_cols_to_thresholds should be a dictionary with the same structure and K-V\n",
        "# pairs as COLS_TO_THRESHOLDS determined above; this parameter simply uses those\n",
        "# values in the algorithm comparison evaluation\n",
        "FINAL_COLS_TO_THRESHOLDS = COLS_TO_THRESHOLDS\n",
        "# Each of these parameters should be the cutoff threshold value determined with \n",
        "# experimental profiling in `train_weights` mode. To use the default DIBBs enhanced\n",
        "# cutoffs, set them to None.\n",
        "# The experimentally determined values for the updated log-odds weights, calculated\n",
        "# using the `train_weights` mode\n",
        "FINAL_LOG_ODDS = {\n",
        "    'address': 8.438284928858774,\n",
        "    'birthdate': 10.126641103800338,\n",
        "    'city': 2.438553006137189,\n",
        "    'first_name': 6.849475906891162,\n",
        "    'last_name': 6.350720397426025,\n",
        "    'mrn': 0.3051262572525359,\n",
        "    'sex': 0.7510419059643679,\n",
        "    'state': 0.022376768992488694,\n",
        "    'zip': 4.975031471124867\n",
        "}\n",
        "\n",
        "# Each of these parameters should be the cutoff threshold value determined with \n",
        "# experimental profiling in `train_weights` mode. To use the default DIBBs enhanced\n",
        "# cutoffs, set them to None.\n",
        "FINAL_PASS_1_THRESHOLD = 12.2\n",
        "FINAL_PASS_2_THRESHOLD = 17.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## File System Mounting\n",
        "The cell below creates a spark session for use in the remainder of the notebook. It also mounts this session to the file system holding the Azure storage containers via secure connection. This lets us save the results we accumulate so that if the connection is disrupted, the notebook times out, or we simply wish to view previous information, we can do so with ease."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "from notebookutils import mssparkutils\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Set paths\n",
        "STORAGE_ACCOUNT = \"$STORAGE_ACCOUNT\"\n",
        "LINKAGE_OUTPUTS_FILESYSTEM = f\"abfss://linkage-notebook-outputs@{STORAGE_ACCOUNT}.dfs.core.windows.net/\"\n",
        "BLOB_STORAGE_LINKED_SERVICE = \"$BLOB_STORAGE_LINKED_SERVICE\"\n",
        "\n",
        "\"\"\"\n",
        "Function that writes the output of a linkage algorithm to a json file.\n",
        "\"\"\"\n",
        "def write_linkage_results(fname, results):\n",
        "    # Results come in as a dict of ints to sets, so just json dumps it\n",
        "    res_to_write = {str(k):[str(x) for x in list(v)] for (k,v) in results.items()}\n",
        "    res_to_write = json.dumps(res_to_write)\n",
        "    mssparkutils.fs.put(LINKAGE_OUTPUTS_FILESYSTEM + fname + \".json\", res_to_write, True)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Function that loads the output of a linkage algorithm from a json file using spark.read\n",
        "and converts it into the same format as the results dict (ints to sets).\n",
        "\"\"\"\n",
        "def load_linkage_results(spark_session, fname):\n",
        "    try:\n",
        "        res = spark_session.read.json(LINKAGE_OUTPUTS_FILESYSTEM + fname + \".json\")\n",
        "    except:\n",
        "        print(\"Existing results not found.\")\n",
        "        return None\n",
        "    \n",
        "    print(\"Existing results found!\")\n",
        "    res = res.toPandas()\n",
        "    res = res.to_dict()\n",
        "    res = {int(k):set([int(x) for x in v[0]]) for (k,v) in res.items()}\n",
        "    return res\n",
        "\n",
        "\n",
        "# Instantiate a spark session for use with the rest of the notebook\n",
        "credential = DefaultAzureCredential()\n",
        "db_password =  TokenLibrary.getSecret(vault_name,\"mpi-db-password\",vault_linked_service)\n",
        "url = f\"jdbc:postgresql://{DB_HOST}:{DB_PORT}/{DB_NAME}\"\n",
        "db_props = {\n",
        "    \"user\": DB_USER,\n",
        "    \"password\": db_password,\n",
        "    \"driver\": \"org.postgresql.Driver\"\n",
        "}\n",
        "spark = (\n",
        "    SparkSession.builder.master(\"local[*]\")\n",
        "    .appName(\"Build sub-sampled MPI\")\n",
        "    .getOrCreate()\n",
        ")\n",
        "\n",
        "# Set up for writing to blob storage\n",
        "linkage_bucket_name = \"linkage-notebook-outputs\"\n",
        "blob_sas_token = mssparkutils.credentials.getConnectionStringOrCreds(BLOB_STORAGE_LINKED_SERVICE)\n",
        "wasb_path = 'wasbs://%s@%s.blob.core.windows.net/' % (linkage_bucket_name, STORAGE_ACCOUNT)\n",
        "spark.conf.set('fs.azure.sas.%s.%s.blob.core.windows.net' % (linkage_bucket_name, STORAGE_ACCOUNT), blob_sas_token)\n",
        "\n",
        "# Try mounting the remote storage directory at the mount point\n",
        "try:\n",
        "    mssparkutils.fs.mount(\n",
        "        wasb_path,\n",
        "        \"/\",\n",
        "        {\"LinkedService\": f\"${BLOB_STORAGE_LINKED_SERVICE}\"}\n",
        "    )\n",
        "except:\n",
        "    print(\"Already mounted\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extracting the MPI\n",
        "Now we get into the meat of the notebook, in which we read and analyze data from the MPI. The following cells open a connection to the MPI specified by the configuration options above, extract patient data from it, and format it into an appropriately sized sample for use with the remainder of this notebook. All 3 notebook modes rely on clean, properly formatted patient data pulled from the MPI. This is accomplished with `pyspark` using access patterns called \"temporary database views\". We can read a dataset distributed across multiple tables into memory in parallel, and by constructing specific views for each of the tables we want to access, `pyspark` provides us a window to run queries or perform joins against that table without disrupting the underlying information actually stored in the MPI. Once we have these views, we can begin with the default `patient` table and iteratively join each other table to the assorted patient records there, ensuring that their information is properly grouped and collated along the way, so that our result is a single massaged table consisting of one patient row per re-constructed health care record."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# MPI ACCESS\n",
        "# Create views into all tables in the MPI so we can extract them in parallel\n",
        "# Each of these views represents a safe \"copy\" of one table in the MPI that we\n",
        "# can query and/or manipulate without worrying about affecting the actual data\n",
        "# stored in the database. We need one view for each table we want to access.\n",
        "patient_view = \"patient_view\"\n",
        "mpi_patient_data = spark.read.jdbc(url, DB_TABLE_PATIENT, properties=db_props)\n",
        "mpi_patient_data.createOrReplaceTempView(patient_view)\n",
        "\n",
        "name_view = \"name_view\"\n",
        "mpi_name_data = spark.read.jdbc(url, DB_TABLE_NAME, properties=db_props)\n",
        "mpi_name_data.createOrReplaceTempView(name_view)\n",
        "\n",
        "given_name_view = \"given_name_view\"\n",
        "mpi_given_name_data = spark.read.jdbc(url, DB_TABLE_GIVEN_NAME, properties=db_props)\n",
        "mpi_given_name_data.createOrReplaceTempView(given_name_view)\n",
        "\n",
        "address_view = \"address_view\"\n",
        "mpi_address_data = spark.read.jdbc(url, DB_TABLE_ADDRESS, properties=db_props)\n",
        "mpi_address_data.createOrReplaceTempView(address_view)\n",
        "\n",
        "identifier_view = \"identifier_view\"\n",
        "mpi_identifier_data = spark.read.jdbc(url, DB_TABLE_IDENTIFIER, properties=db_props)\n",
        "mpi_identifier_data.createOrReplaceTempView(identifier_view)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# MPI EXTRACTION\n",
        "# Pull all the various sources of patient information out of the MPI and\n",
        "# massage them into a single table. This allows us to format the data for\n",
        "# training and testing easily off the same spark DF.\n",
        "\n",
        "import pyspark.sql.functions as F\n",
        "from pyspark.sql.functions import struct\n",
        "\n",
        "'''\n",
        "Helper function to construct a complete string representation of a patient's given \n",
        "name from the various fields of a row struct in a pyspark dataframe pulled from\n",
        "the MPI.\n",
        "'''\n",
        "def construct_full_given_name(row):\n",
        "    gn = \"\"\n",
        "    if row[\"given_name_list\"] is not None:\n",
        "        sorted_structs = sorted(row[\"given_name_list\"], key=lambda x: x.given_name_index)\n",
        "        gn = [x.given_name for x in sorted_structs]\n",
        "        gn = [x for x in gn if x is not None]\n",
        "        gn = \" \".join(gn) if len(gn) > 0 else \"\"\n",
        "    return row[\"name_id\"], row[\"patient_id\"], row[\"last_name\"], gn\n",
        "\n",
        "\n",
        "# Start with table with 1 row per patient so that when we left join, we preserve that\n",
        "extracted_patient_data = spark.sql(f\"SELECT * from {DB_TABLE_PATIENT}_view\")\n",
        "\n",
        "# Given names don't have a patient_id field, so compile the given names\n",
        "# associated with each name_id entry in preparation to join to last names\n",
        "extracted_given_names = spark.sql(f\"SELECT * from {DB_TABLE_GIVEN_NAME}_view\")\n",
        "extracted_given_names = extracted_given_names.withColumn(\n",
        "    \"name_structs\",\n",
        "    struct(extracted_given_names.given_name, extracted_given_names.given_name_index)\n",
        ")\n",
        "extracted_given_names = extracted_given_names.groupBy(\"name_id\").agg(F.collect_list(\"name_structs\").alias(\"given_name_list\"))\n",
        "extracted_given_names.cache()\n",
        "\n",
        "# Last names are 1:1 with a name_id representing all associated given names\n",
        "# Last names also map back to patient_ids in the patient_table, so use left\n",
        "# joins to preserve all present info and the 1 row per patient structure\n",
        "extracted_name_data = spark.sql(f\"SELECT * from {DB_TABLE_NAME}_view\")\n",
        "full_name_table = extracted_name_data.join(extracted_given_names, \"name_id\", \"left\")\n",
        "full_name_table = full_name_table.rdd.map(construct_full_given_name).toDF([\"name_id\", \"patient_id\", \"last_name\", \"given_name\"])\n",
        "full_name_table = full_name_table.withColumn(\"full_name_structs\", struct(full_name_table.given_name, full_name_table.last_name))\n",
        "full_name_table = full_name_table.groupBy(\"patient_id\").agg(F.collect_list(\"full_name_structs\").alias(\"full_name_list\"))\n",
        "extracted_patient_data = extracted_patient_data.join(full_name_table, \"patient_id\", \"left\")\n",
        "extracted_patient_data.cache()\n",
        "\n",
        "# Identifier table needs compiled (patients can have multiple IDs, such as MRN and\n",
        "# SS) and can left join back to patients\n",
        "extracted_identifier_data = spark.sql(f\"SELECT * from {DB_TABLE_IDENTIFIER}_view\")\n",
        "extracted_identifier_data = extracted_identifier_data.withColumn(\"id_structs\", struct(\n",
        "    extracted_identifier_data.patient_identifier, extracted_identifier_data.type_code\n",
        "))\n",
        "extracted_identifier_data = extracted_identifier_data.groupBy(\"patient_id\").agg(F.collect_list(\"id_structs\").alias(\"ids_list\"))\n",
        "extracted_patient_data = extracted_patient_data.join(extracted_identifier_data, \"patient_id\", \"left\")\n",
        "\n",
        "# Address fields can be massively collapsed into the traditional string representation\n",
        "# Then we join this back on patient table\n",
        "extracted_address_data = spark.sql(f\"SELECT * from {DB_TABLE_ADDRESS}_view\")\n",
        "extracted_address_data = extracted_address_data.withColumn(\"address_structs\", struct(\n",
        "    extracted_address_data.line_1,\n",
        "    extracted_address_data.line_2,\n",
        "    extracted_address_data.city,\n",
        "    extracted_address_data.state,\n",
        "    extracted_address_data.zip_code\n",
        "))\n",
        "extracted_address_data = extracted_address_data.groupBy(\"patient_id\").agg(F.collect_list(\"address_structs\").alias(\"address_list\"))\n",
        "extracted_patient_data = extracted_patient_data.join(extracted_address_data, \"patient_id\", \"left\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Formatting And Set Creation\n",
        "With the data extracted and properly joined out of the MPI, the next cell transforms the pyspark DataFrames currently holding the scattered patient information into the FHIR- and pandas-based formats the remainder of the notebook expects. `None` typed data and empty strings are handled, then data is converted to a FHIR format for any downstream flattening. The cell generates two different formats of the same set of data:\n",
        "\n",
        "* a list of FHIR-formatted data consisting of `EVALUATION_SIZE` records on which the notebook will perform record linkage (this can be considered the \"testing set\" version of the data)\n",
        "* a pandas DataFrame of flattened list-structured data consisting of `LABELING_SIZE` records, on which the notebook will perform ground-truth labeling (so that we can assess algorithm performance relative to a \"known\" baseline)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TRAIN/TEST CREATION\n",
        "# Use the extracted information from the MPI to create two sets of data, one\n",
        "# in flattened array form in a pandas DF for labeling (training) and one as a \n",
        "# list of FHIR bundles for evaluation (testing).\n",
        "\n",
        "from pyspark.sql.types import StructType, StructField, StringType\n",
        "import fhirpathpy\n",
        "from typing import Any, Callable, List, Literal, Union\n",
        "\n",
        "\n",
        "selection_criteria_types = Literal[\"first\", \"last\", \"all\"]\n",
        "\n",
        "FIELD_COLS = [\"address\", \"birthdate\", \"city\", \"first_name\", \"last_name\", \"mrn\", \"sex\", \"state\", \"zip\"]\n",
        "FIELD_COLS_TO_IDX = dict(zip(FIELD_COLS, range(len(FIELD_COLS))))\n",
        "LINKING_FIELDS_TO_FHIRPATHS = {\n",
        "    \"first_name\": \"Patient.name.given\",\n",
        "    \"last_name\": \"Patient.name.family\",\n",
        "    \"birthdate\": \"Patient.birthDate\",\n",
        "    \"address\": \"Patient.address.line\",\n",
        "    \"zip\": \"Patient.address.postalCode\",\n",
        "    \"city\": \"Patient.address.city\",\n",
        "    \"state\": \"Patient.address.state\",\n",
        "    \"sex\": \"Patient.gender\",\n",
        "    \"mrn\": \"Patient.identifier.where(type.coding.code='MR').value\",\n",
        "}\n",
        "\n",
        "\"\"\"\n",
        "Returns value(s), according to the selection criteria, from a given list of values\n",
        "parsed from a FHIR resource. A single string value is returned - if the selected\n",
        "value is a complex structure (list or dict), it is converted to a string.\n",
        "\"\"\"\n",
        "def apply_selection_criteria(\n",
        "    value: List[Any],\n",
        "    selection_criteria: selection_criteria_types,\n",
        ") -> str | List:\n",
        "    if selection_criteria == \"first\":\n",
        "        value = value[0]\n",
        "    elif selection_criteria == \"last\":\n",
        "        value = value[-1]\n",
        "    elif selection_criteria == \"all\":\n",
        "        return value\n",
        "    else:\n",
        "        raise ValueError(\n",
        "            f'Selection criteria {selection_criteria} is not a valid option. Must be one of \"first\", \"last\", \"random\", or \"all\".'  # noqa\n",
        "        )\n",
        "\n",
        "    if type(value) is dict:\n",
        "        value = json.dumps(value)\n",
        "    elif type(value) is list:\n",
        "        value = \",\".join(value)\n",
        "    return value\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Yields a single value from a resource based on a provided `fhir_path`.\n",
        "If the path doesn't map to an extant value in the first, returns\n",
        "`None` instead.\n",
        "\"\"\"\n",
        "def extract_value_with_resource_path(\n",
        "    resource: dict,\n",
        "    path: str,\n",
        "    selection_criteria: Literal[\"first\", \"last\", \"random\", \"all\"] = \"first\",\n",
        ") -> Union[Any, None]:\n",
        "    \n",
        "    parse_function = get_fhirpathpy_parser(path)\n",
        "    value = parse_function(resource)\n",
        "    if len(value) == 0:\n",
        "        return None\n",
        "    else:\n",
        "        value = apply_selection_criteria(value, selection_criteria)\n",
        "        return value\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Accepts a FHIRPath expression, and returns a callable function\n",
        "which returns the evaluated value at fhirpath_expression for\n",
        "a specified FHIR resource.\n",
        "\"\"\"\n",
        "def get_fhirpathpy_parser(fhirpath_expression: str) -> Callable:\n",
        "    return fhirpathpy.compile(fhirpath_expression)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Formatting function to account for patient resources that have multiple\n",
        "associated addresses. Each address is a self-contained object, replete\n",
        "with its own `line` property that can hold a list of strings. This\n",
        "function condenses that `line` into a single concatenated string, for\n",
        "each address object, and returns the result in a properly formatted\n",
        "list.\n",
        "\"\"\"\n",
        "def _condense_extract_address_from_resource(resource: dict, field: str):\n",
        "    expanded_address_fhirpath = LINKING_FIELDS_TO_FHIRPATHS[field]\n",
        "    expanded_address_fhirpath = \".\".join(expanded_address_fhirpath.split(\".\")[:-1])\n",
        "    list_of_address_objects = extract_value_with_resource_path(\n",
        "        resource, expanded_address_fhirpath, \"all\"\n",
        "    )\n",
        "    list_of_usable_address_elements = []\n",
        "    if field == \"address\":\n",
        "        if list_of_address_objects is not None:\n",
        "            list_of_address_lists = [\n",
        "                ao.get(LINKING_FIELDS_TO_FHIRPATHS[field].split(\".\")[-1], [])\n",
        "                for ao in list_of_address_objects\n",
        "            ]\n",
        "            list_of_usable_address_elements = [\n",
        "                \" \".join(obj) for obj in list_of_address_lists\n",
        "            ]\n",
        "    else:\n",
        "        if list_of_address_objects is not None:\n",
        "            for address_object in list_of_address_objects:\n",
        "                list_of_usable_address_elements.append(\n",
        "                    address_object.get(LINKING_FIELDS_TO_FHIRPATHS[field].split(\".\")[-1])\n",
        "                )\n",
        "    return list_of_usable_address_elements\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Helper method that flattens an incoming patient resource into a list whose\n",
        "elements are the keys of the FHIR dictionary, reformatted and ordered\n",
        "according to our \"blocking fields extractor\" dictionary.\n",
        "\"\"\"\n",
        "def flatten_patient_resource(resource: dict, col_to_idx: dict) -> List:\n",
        "    flattened_record = [\n",
        "        flatten_patient_field_helper(resource, f) for f in col_to_idx.keys()\n",
        "    ]\n",
        "    flattened_record = [resource[\"id\"], None] + flattened_record\n",
        "    return flattened_record\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Helper function that determines the correct way to flatten a patient's\n",
        "FHIR field based on the specific field in question. Names and Addresses,\n",
        "because their lists can hold multiple objects, are fetched completely,\n",
        "whereas other fields just have their first element used (since historical\n",
        "information doesn't matter there).\n",
        "\n",
        "For any field for which the value would be `None`, instead use an empty string\n",
        "(if the field isn't first_name or address) or a list with one element, the\n",
        "empty string (if the field is first_name or address). This ensures that\n",
        "future loops over the elements don't disrupt the flow of the matching\n",
        "algorithm.\n",
        "\"\"\"\n",
        "def flatten_patient_field_helper(resource: dict, field: str) -> any:\n",
        "    if field == \"first_name\":\n",
        "        vals = extract_value_with_resource_path(\n",
        "            resource, LINKING_FIELDS_TO_FHIRPATHS[field], selection_criteria=\"all\"\n",
        "        )\n",
        "        return vals if vals is not None else [\"\"]\n",
        "    elif field in [\"address\", \"city\", \"zip\", \"state\"]:\n",
        "        vals = _condense_extract_address_from_resource(resource, field)\n",
        "        if field == \"address\":\n",
        "            return vals if (vals is not None and len(vals) > 0) else [\"\"]\n",
        "        else:\n",
        "            return vals[0] if (vals is not None and len(vals) > 0) else \"\"\n",
        "    else:\n",
        "        val = extract_value_with_resource_path(\n",
        "            resource, LINKING_FIELDS_TO_FHIRPATHS[field], selection_criteria=\"first\"\n",
        "        )\n",
        "        return val if val is not None else \"\"\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Function that transforms an aggregated row of patient information from joins of\n",
        "MPI tables into a single FHIR Patient resource, with all information present\n",
        "in the table loaded into appropriate fields and sub-fields.\n",
        "\"\"\"\n",
        "def create_patient_resource_from_spark_row(row):\n",
        "    # Pull out the various fields from the passed-in row\n",
        "    extracted_pid = row[\"patient_id\"]\n",
        "    extracted_birthdate = row[\"dob\"] if row[\"dob\"] is not None else \"\"\n",
        "    extracted_gender = row[\"sex\"] if row[\"sex\"] is not None else \"\"\n",
        "    extracted_names = row[\"full_name_list\"] if row[\"full_name_list\"] is not None else []\n",
        "    extracted_identifiers = row[\"ids_list\"] if row[\"ids_list\"] is not None else []\n",
        "    extracted_addresses = row[\"address_list\"] if row[\"address_list\"] is not None else []\n",
        "\n",
        "    # Initialize a patient resource to append fields into\n",
        "    patient_resource = {\n",
        "        \"resourceType\": \"Patient\",\n",
        "        \"id\": f\"{extracted_pid}\",\n",
        "        \"identifier\": [],\n",
        "        \"name\": [],\n",
        "        \"gender\": f\"{extracted_gender}\",\n",
        "        \"birthDate\": f\"{extracted_birthdate}\",\n",
        "        \"address\": [],\n",
        "    }\n",
        "\n",
        "    # Append the appropriate list construct for each name present\n",
        "    for en in extracted_names:\n",
        "        givens = en.given_name if en.given_name is not None else \"\"\n",
        "        givens = str(givens).split()\n",
        "        last = en.last_name if en.last_name is not None else \"\"\n",
        "        patient_resource[\"name\"].append({\n",
        "            \"family\": f\"{last}\",\n",
        "            \"given\": givens\n",
        "        })\n",
        "    \n",
        "    # Do the same for identifiers, following the correct coding scheme\n",
        "    for ident in extracted_identifiers:\n",
        "        patient_resource[\"identifier\"].append({\n",
        "            \"type\": {\n",
        "                \"coding\": [\n",
        "                    {\n",
        "                        \"system\": \"http://terminology.hl7.org/CodeSystem/v2-0203\",\n",
        "                        \"code\": ident.type_code\n",
        "                    }\n",
        "                ]\n",
        "            },\n",
        "            \"value\": ident.patient_identifier\n",
        "        })\n",
        "    \n",
        "    # Finally, repeat for each address present in the patient row, making\n",
        "    # sure to capture `line` elements appropriately\n",
        "    for addr in extracted_addresses:\n",
        "        l1 = addr.line_1 if addr.line_1 is not None else \"\"\n",
        "        l2 = addr.line_2 if addr.line_2 is not None else \"\"\n",
        "        lines = [x for x in [l1, l2] if x != \"\" and x != \"None\"]\n",
        "        city = addr.city if addr.city is not None else \"\"\n",
        "        state = addr.state if addr.state is not None else \"\"\n",
        "        zipcode = addr.zip_code if addr.zip_code is not None else \"\"\n",
        "        patient_resource[\"address\"].append({\n",
        "            \"line\": lines if len(lines) > 0 else [\"\"],\n",
        "            \"city\": f\"{city}\",\n",
        "            \"state\": f\"{state}\",\n",
        "            \"postalCode\": f\"{zipcode}\"\n",
        "        })\n",
        "    \n",
        "    return (row[\"person_id\"], patient_resource)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Simple helper used for iteratively returning a single patient during parallel\n",
        "processing.\n",
        "\"\"\"\n",
        "def yield_patient_resource(row):\n",
        "    return row[1]\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Simple helper used for iteratively building a flattened representation of a \n",
        "FHIR patient resource, augmented with the person_id of the person to which\n",
        "this patient is assigned in the MPI.\n",
        "\"\"\"\n",
        "def yield_flattened_patient_with_person_id(row):\n",
        "    pid = row[0]\n",
        "    fp = flatten_patient_resource(row[1], FIELD_COLS_TO_IDX)\n",
        "    fp[1] = pid\n",
        "    return fp\n",
        "\n",
        "\n",
        "# Build the base FHIR and flattened row groups of data\n",
        "fhir_mapped_data = extracted_patient_data.rdd.map(create_patient_resource_from_spark_row)\n",
        "fhir_mapped_data.cache()\n",
        "flattened_patient_data = fhir_mapped_data.map(yield_flattened_patient_with_person_id)\n",
        "fhir_mapped_data = fhir_mapped_data.map(yield_patient_resource)\n",
        "\n",
        "# Construct the labeling set--need an explicit schema since the \n",
        "# conversion to rdd for mapping removed that information, so \n",
        "# just have to cast it back\n",
        "formatted_cols = [\"patient_id\", \"person_id\"] + FIELD_COLS\n",
        "pyspark_schema = StructType([\n",
        "    StructField(x, StringType(), True) for x in formatted_cols\n",
        "])\n",
        "flattened_patient_data = flattened_patient_data.toDF(pyspark_schema)\n",
        "labeling_set = [list(x) for x in flattened_patient_data.collect()]\n",
        "if LABELING_SIZE is not None and LABELING_SIZE < len(labeling_set):\n",
        "    labeling_set = labeling_set[:LABELING_SIZE]\n",
        "labeling_set = pd.DataFrame(labeling_set, columns=formatted_cols)\n",
        "del flattened_patient_data\n",
        "\n",
        "# Construct the evaluation set\n",
        "evaluation_set = [x for x in fhir_mapped_data.collect()]\n",
        "if EVALUATION_SIZE is not None and EVALUATION_SIZE < len(evaluation_set):\n",
        "    evaluation_set = evaluation_set[:EVALUATION_SIZE]\n",
        "evaluation_set = spark.sparkContext.parallelize(evaluation_set, numSlices=512)\n",
        "del fhir_mapped_data\n",
        "\n",
        "# Force cleanup of DB connections\n",
        "del extracted_patient_data\n",
        "del extracted_address_data\n",
        "del extracted_identifier_data\n",
        "del extracted_name_data\n",
        "del full_name_table\n",
        "del extracted_given_names\n",
        "del mpi_patient_data\n",
        "del mpi_name_data\n",
        "del mpi_given_name_data\n",
        "del mpi_address_data\n",
        "del mpi_identifier_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ground-Truth Labeling\n",
        "This large section of the notebook is responsible for creating the ground-truth labels that the notebook uses for evaluation purposes. While the labels (which represent matches between candidate pairs of records in the Labeling Set) aren't guaranteed to be matches in reality, for purposes of algorithm comparison, that isn't a problem, since all algorithms are measured back to the same standard of comparison. Labeling uses the following outline of a procedure:\n",
        "\n",
        "* build an index of possible candidate matches, which are the pairs of records in the Labeling Set there are \"worth\" considering for full match status (this is done by building a sliding window around a sorted list of patients and checking each record with respect to some number of its neighbors)\n",
        "* generate numerical comparisons of fuzzy match scores across different fields for each candidate pair in the index\n",
        "* apply a variety of filtering rules to find candidate pairs with matching scores sufficiently high\n",
        "* label these subsets as \"true\" matches for the purpose of the notebook\n",
        "\n",
        "The code in the cells of this section will need to run regardless of the selected notebook mode, but importantly, the values here should generally **not** require any user input or changing. All Labeling tuning should be done using the settings at the top of the notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CANDIDATE INDEXING\n",
        "# Generates tuples of all possible candidate pairs that the labeler will compute\n",
        "# match likelihoods for.\n",
        "\n",
        "from recordlinkage.index import SortedNeighbourhood, BaseIndexAlgorithm\n",
        "from recordlinkage.utils import listify\n",
        "\n",
        "'''\n",
        "A custom Indexing function built to operate compatibly on the first_name column\n",
        "returned from the MPI. Since that's a list of strings (because someone could have\n",
        "multiple given names), we need a way to cross-conjoin these entries and apply\n",
        "the same fuzzy blocking filter window that a regular column of strings would get.\n",
        "This performs joint name concatenation on copies of that column in the data, and\n",
        "then uses an edit distance neighborhood to find fuzzy blocking candidates.\n",
        "'''\n",
        "class FirstNameSortedNeighborhood(BaseIndexAlgorithm):\n",
        "    def __init__(\n",
        "        self,\n",
        "        left_on=None,\n",
        "        right_on=None,\n",
        "        window=3,\n",
        "        sorting_key_values=None,\n",
        "        block_on=[],\n",
        "        block_left_on=[],\n",
        "        block_right_on=[],\n",
        "        **kwargs\n",
        "    ):\n",
        "        super(FirstNameSortedNeighborhood, self).__init__(**kwargs)\n",
        "\n",
        "        # variables to block on\n",
        "        self.left_on = left_on\n",
        "        self.right_on = right_on\n",
        "        self.window = window\n",
        "        self.sorting_key_values = sorting_key_values\n",
        "        self.block_on = block_on\n",
        "        self.block_left_on = block_left_on\n",
        "        self.block_right_on = block_right_on\n",
        "\n",
        "    def _get_left_and_right_on(self):\n",
        "        \"\"\"\n",
        "        We only care about the de-dupe case which involves no self.right, but this\n",
        "        still needs to be implemented for super compatibility.\n",
        "        \"\"\"\n",
        "        if self.right_on is None:\n",
        "            return (self.left_on, self.left_on)\n",
        "        else:\n",
        "            return (self.left_on, self.right_on)\n",
        "\n",
        "    def _get_sorting_key_values(self, array1, array2):\n",
        "        \"\"\"\n",
        "        Return the sorting key values as a series. This function is required by the\"\n",
        "        package for multi-index neighborhood filtering according to some papers it's\"\n",
        "        built on.\n",
        "        \"\"\"\n",
        "\n",
        "        concat_arrays = np.concatenate([array1, array2])\n",
        "        return np.unique(concat_arrays)\n",
        "\n",
        "    def _link_index(self, df_a, df_b):\n",
        "        df_a = df_a.copy()\n",
        "        df_b = df_b.copy()\n",
        "        df_a[\"first_name\"] = df_a[\"first_name\"].str.join(\" \")\n",
        "        df_b[\"first_name\"] = df_a[\"first_name\"].str.join(\" \")\n",
        "        left_on, right_on = self._get_left_and_right_on()\n",
        "        left_on = listify(left_on)\n",
        "        right_on = listify(right_on)\n",
        "\n",
        "        window = self.window\n",
        "\n",
        "        # Correctly generate blocking keys\n",
        "        block_left_on = listify(self.block_left_on)\n",
        "        block_right_on = listify(self.block_right_on)\n",
        "\n",
        "        if self.block_on:\n",
        "            block_left_on = listify(self.block_on)\n",
        "            block_right_on = listify(self.block_on)\n",
        "\n",
        "        blocking_keys = [\"sorting_key\"] + [\n",
        "            \"blocking_key_%d\" % i for i, v in enumerate(block_left_on)\n",
        "        ]\n",
        "\n",
        "        # Format the data to thread with index pairs\n",
        "        data_left = pd.DataFrame(df_a[listify(left_on) + block_left_on], copy=False)\n",
        "        data_left.columns = blocking_keys\n",
        "        data_left[\"index_x\"] = np.arange(len(df_a))\n",
        "        data_left.dropna(axis=0, how=\"any\", subset=blocking_keys, inplace=True)\n",
        "\n",
        "        data_right = pd.DataFrame(df_b[listify(right_on) + block_right_on], copy=False)\n",
        "        data_right.columns = blocking_keys\n",
        "        data_right[\"index_y\"] = np.arange(len(df_b))\n",
        "        data_right.dropna(axis=0, how=\"any\", subset=blocking_keys, inplace=True)\n",
        "\n",
        "        # sorting_key_values is the terminology in Data Matching [Christen,\n",
        "        # 2012]\n",
        "        if self.sorting_key_values is None:\n",
        "            self.sorting_key_values = self._get_sorting_key_values(\n",
        "                data_left[\"sorting_key\"].values, data_right[\"sorting_key\"].values\n",
        "            )\n",
        "\n",
        "        sorting_key_factors = pd.Series(\n",
        "            np.arange(len(self.sorting_key_values)), index=self.sorting_key_values\n",
        "        )\n",
        "\n",
        "        data_left[\"sorting_key\"] = data_left[\"sorting_key\"].map(sorting_key_factors)\n",
        "        data_right[\"sorting_key\"] = data_right[\"sorting_key\"].map(sorting_key_factors)\n",
        "\n",
        "        # Internal window size\n",
        "        _window = int((window - 1) / 2)\n",
        "\n",
        "        def merge_lagged(x, y, w):\n",
        "            \"\"\"Merge two dataframes with a lag on in the sorting key.\"\"\"\n",
        "\n",
        "            y = y.copy()\n",
        "            y[\"sorting_key\"] = y[\"sorting_key\"] + w\n",
        "\n",
        "            return x.merge(y, how=\"inner\")\n",
        "\n",
        "        pairs_concat = [\n",
        "            merge_lagged(data_left, data_right, w) for w in range(-_window, _window + 1)\n",
        "        ]\n",
        "\n",
        "        pairs_df = pd.concat(pairs_concat, axis=0)\n",
        "\n",
        "        return pd.MultiIndex(\n",
        "            levels=[df_a.index.values, df_b.index.values],\n",
        "            codes=[pairs_df[\"index_x\"].values, pairs_df[\"index_y\"].values],\n",
        "            verify_integrity=False,\n",
        "        )\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Function that builds an indexed list of the possible matches between candidate\n",
        "pairs of records that we should consider for full match evaluation.\n",
        "\"\"\"\n",
        "def find_candidate_links(data):\n",
        "    start = time.time()\n",
        "    # Create a windowed neighborhood index on patient table because full is \n",
        "    # too expensive\n",
        "    indexer = rl.Index()\n",
        "    # Adding multiple different neighborhoods takes their union so we don't over-block\n",
        "    indexer.add(SortedNeighbourhood('last_name', window=WINDOW_INDEX_SIZE))\n",
        "    indexer.add(SortedNeighbourhood('birthdate', window=WINDOW_INDEX_SIZE))\n",
        "    indexer.add(SortedNeighbourhood('mrn', window=WINDOW_INDEX_SIZE))\n",
        "    indexer.add(FirstNameSortedNeighborhood('first_name', window=WINDOW_INDEX_SIZE))\n",
        "    candidate_links = indexer.index(data)\n",
        "    print(len(candidate_links), \"candidate pairs identified\")\n",
        "\n",
        "    # Note: using a multi-indexer treats the row number as the index, so\n",
        "    # results will automatically be in acceptable eval format\n",
        "    end = time.time()\n",
        "    print(\"Identifying possible candidate pairs took \", str(round(end - start, 2)), \"seconds\")\n",
        "    return candidate_links\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Function that transforms a recordlinkage toolkit multi-index into a set of\n",
        "candidate tuples, and constructs a dictionary mapping the \"lower indexed\" record \n",
        "of each pair to all \"higher indexed\" records that are linked to it. This structure\n",
        "allows us to perform efficient scoring later by taking set differences.\n",
        "\"\"\"\n",
        "def get_pred_match_dict_from_multi_idx(mltidx, n_rows):\n",
        "    candidate_tuples = mltidx.to_list()\n",
        "    pred_matches = {k: set() for k in range(n_rows)}\n",
        "    for pair in candidate_tuples:\n",
        "        reference_record = min(pair)\n",
        "        linked_record = max(pair)\n",
        "        pred_matches[reference_record].add(linked_record)\n",
        "    return pred_matches\n",
        "\n",
        "# Convert mrn col into actual Nones rather than string Nones\n",
        "# We'll need to reverse this in the later spark-block stages to parallel mask\n",
        "labeling_set = labeling_set.replace({\"\": None})\n",
        "\n",
        "candidate_links = find_candidate_links(labeling_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FEATURE COMPARATOR\n",
        "# Generate string similarity scores for all features in all candidate pairs.\n",
        "\n",
        "import rapidfuzz\n",
        "\n",
        "\"\"\"\n",
        "Returns the normalized similarity measure between string1 and string2, as\n",
        "determined by the similarlity measure. The higher the normalized similarity measure\n",
        "(up to 1.0), the more similar string1 and string2 are. A normalized similarity\n",
        "measure of 0.0 means string1 and string 2 are not at all similar. This function\n",
        "expects basic text cleaning (e.g. removal of numeric characters, trimming of spaces,\n",
        "etc.) to already have been performed on the input strings.\n",
        "\"\"\"\n",
        "def compare_strings(\n",
        "    string1: str,\n",
        "    string2: str,\n",
        "    similarity_measure: Literal[\n",
        "        \"JaroWinkler\", \"Levenshtein\", \"DamerauLevenshtein\"\n",
        "    ] = \"JaroWinkler\",\n",
        ") -> float:\n",
        "    if similarity_measure == \"JaroWinkler\":\n",
        "        return rapidfuzz.distance.JaroWinkler.normalized_similarity(string1, string2)\n",
        "    elif similarity_measure == \"Levenshtein\":\n",
        "        return rapidfuzz.distance.Levenshtein.normalized_similarity(string1, string2)\n",
        "    elif similarity_measure == \"DamerauLevenshtein\":\n",
        "        return rapidfuzz.distance.DamerauLevenshtein.normalized_similarity(\n",
        "            string1, string2\n",
        "        )\n",
        "\n",
        "\"\"\"\n",
        "A special class for comparing LoL concatenated elements. Use the full concatenation\n",
        "of all values to account for multiple entries like given names.\n",
        "\"\"\"\n",
        "class CompareNestedString(BaseCompareFeature):\n",
        "    def _compute_vectorized(self, s1, s2):\n",
        "        strrep1 = s1.str.lstrip('[').str.rstrip(']').str.split(',')\n",
        "        strrep2 = s2.str.lstrip('[').str.rstrip(']').str.split(',')\n",
        "        return (strrep1.str[0] == strrep2.str[0]).astype(float)\n",
        "\n",
        "\n",
        "\"\"\"\"\n",
        "A special class for comparing LoL first name elements. Use the full concatenation\n",
        "of all names to account for multiple given names.\n",
        "\"\"\"\n",
        "class CompareFirstName(BaseCompareFeature):\n",
        "    def _compute_vectorized(self, s1, s2):\n",
        "        strrep1 = s1.str.lstrip('[').str.rstrip(']').str.split(',')\n",
        "        strrep2 = s2.str.lstrip('[').str.rstrip(']').str.split(',')\n",
        "        jarowinklers = np.vectorize(compare_strings)(strrep1.str.join(\" \"), strrep2.str.join(\" \"))\n",
        "        return jarowinklers\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "A special class for comparing LoL address line elements. Check each address\n",
        "line against each other address line to account for patients who have changed\n",
        "residence.\n",
        "\"\"\"\n",
        "class CompareAddress(BaseCompareFeature):\n",
        "    def _compute_vectorized(self, s1, s2):\n",
        "        def comp_address_fields(a1_list, a2_list):\n",
        "            best_score = 0.0\n",
        "            for a1 in a1_list:\n",
        "                for a2 in a2_list:\n",
        "                    score = compare_strings(a1, a2)\n",
        "                    if score >= best_score:\n",
        "                        best_score = score\n",
        "            return best_score\n",
        "\n",
        "        strrep1 = s1.str.lstrip('[').str.rstrip(']').str.split(',')\n",
        "        strrep2 = s2.str.lstrip('[').str.rstrip(']').str.split(',')\n",
        "        jarowinklers = np.vectorize(comp_address_fields)(strrep1, strrep2)\n",
        "        return jarowinklers\n",
        "\n",
        "\n",
        "'''\n",
        "Produces a dataframe with a multi-index, in which each tuple of row indices\n",
        "denotes one potential candidate match. The value in each column of the DF\n",
        "is the fuzzy match similarity score between the two records given by the \n",
        "multi-index.\n",
        "'''\n",
        "def compute_comparator_matrix(data, candidate_links):\n",
        "    start = time.time()\n",
        "\n",
        "    # Apply feature comparisons on each supported field from the MPI\n",
        "    comp = rl.Compare()\n",
        "    comp.add(CompareFirstName(\"first_name\", \"first_name\",label=\"first_name\"))\n",
        "    comp.string(\n",
        "        \"last_name\", \"last_name\", method=\"jarowinkler\", label=\"last_name\"\n",
        "    )\n",
        "    comp.string(\"mrn\", \"mrn\", method=\"jarowinkler\", label=\"mrn\")\n",
        "    comp.string(\n",
        "        \"birthdate\", \"birthdate\", method=\"jarowinkler\", label=\"birthdate\"\n",
        "    )\n",
        "    comp.add(CompareAddress(\"address\", \"address\", label=\"address\"))\n",
        "    comp.string(\"city\", \"city\", method=\"jarowinkler\", label=\"city\")\n",
        "    comp.string(\"zip\", \"zip\", method=\"jarowinkler\", label=\"zip\")\n",
        "    comp.string(\"sex\", \"sex\", method=\"jarowinkler\", label=\"sex\")\n",
        "    features = comp.compute(candidate_links, data)\n",
        "\n",
        "    end = time.time()\n",
        "    print(\"Computation took\", str(round(end - start, 2)), \"seconds\")\n",
        "    return features\n",
        "\n",
        "features = compute_comparator_matrix(labeling_set, candidate_links)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Labeling Method 1: Virginia Labels\n",
        "The VA Labels are a result of DIBBs' early work with a very simple record linkage system. Under the VA Labeling Scheme, two records match if and only if they exactly agree on: first name, last name, date of birth, and address. The VA Labels aren't intended to reflect \"real\" match criteria, but rather illustrate performance for data \"in the best case.\" Record pairs that are linked by VA labels are the super easy cases that any other record linkage algorithm should readily pick up. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_va_labels(data, candidate_links):\n",
        "    start = time.time()\n",
        "\n",
        "    # Apply feature comparisons on each supported field from the MPI\n",
        "    comp = rl.Compare()\n",
        "    comp.add(CompareNestedString(\"first_name\", \"first_name\",label=\"first_name\"))\n",
        "    comp.exact(\"last_name\", \"last_name\", label=\"last_name\")\n",
        "    comp.exact(\"birthdate\", \"birthdate\", label=\"birthdate\")\n",
        "    comp.add(CompareNestedString(\"address\", \"address\", label=\"address\"))\n",
        "    features = comp.compute(candidate_links, data)\n",
        "    matches = features[features.sum(axis=1) == 4]\n",
        "\n",
        "    end = time.time()\n",
        "    print(\"Comparing candidates took\", str(round(end - start, 2)), \"seconds\")\n",
        "\n",
        "    matches = get_pred_match_dict_from_multi_idx(matches.index, len(data))\n",
        "    return matches\n",
        "\n",
        "\n",
        "va_labels = get_va_labels(labeling_set, candidate_links)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Labeling Method 2: UK NHS Labels\n",
        "The United Kingdom's National Health Services administration uses a straightforward deterministic matching procedure to classify patients as matches. Their baseline deterministic model performs linkage in three steps:\n",
        "\n",
        "1) exact match on DOB, exact match on sex, exact match on NHS number (which for our purposes is equivalent to MRN)\n",
        "2) of the unlinked records, new matches are linked using partial/fuzzy match on DOB, exact match on sex, exact match on postal code, and a partial match on MRN\n",
        "3) of the remaining unlinked records, new matches are found by exact match on DOB, exact match on sex, and exact match on post code\n",
        "\n",
        "This system's use of a variety of fields in different combinations gives a good insight to the \"average case\" performance of a linkage algorithm. Since fields can be missing or inexact in one pass and still match in another with a new combination, this labeling scheme gives a good representation of a linkage algorithm's performance on data if we otherwise knew nothing about the nature and field quality of the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "Helper function that combines two dictionaries, each of which has already been\n",
        "formatted in the requisite stats indexing fashion.\n",
        "'''\n",
        "def combine_match_dicts(m1, m2):\n",
        "    m3 = {}\n",
        "    for k in m1:\n",
        "        union_set = set()\n",
        "        union_set = union_set.union(m1[k])\n",
        "        union_set = union_set.union(m2[k])\n",
        "        m3[k] = union_set\n",
        "    return m3\n",
        "\n",
        "\n",
        "'''\n",
        "Generate the UK's National Health Service labels using three match conditions, \n",
        "depending on the available field information and whether constraints are\n",
        "progressively relaxed.\n",
        "'''\n",
        "def get_uk_nhs_labels(data, features):\n",
        "    matches_type_1 = features.loc[\n",
        "        (features['birthdate'] == 1.0) &\n",
        "        (features['sex'] == 1.0) &\n",
        "        (features['mrn'] == 1.0)\n",
        "    ]\n",
        "\n",
        "    matches_type_2 = features.loc[\n",
        "        (features['birthdate'] >= BIRTHDAY_THRESHOLD) & \n",
        "        (features['sex'] == 1.0) &\n",
        "        (features['zip'] == 1.0) &\n",
        "        (features['mrn'] >= JARO_THRESHOLD)\n",
        "    ]\n",
        "\n",
        "    matches_type_3 = features.loc[\n",
        "        (features['birthdate'] == 1.0) &\n",
        "        (features['sex'] == 1.0) &\n",
        "        (features['zip'] == 1.0)\n",
        "    ]\n",
        "\n",
        "    m1_dict = get_pred_match_dict_from_multi_idx(matches_type_1.index, len(data))\n",
        "    m2_dict = get_pred_match_dict_from_multi_idx(matches_type_2.index, len(data))\n",
        "    m3_dict = get_pred_match_dict_from_multi_idx(matches_type_3.index, len(data))\n",
        "    pred_matches = combine_match_dicts(m1_dict, m2_dict)\n",
        "    pred_matches = combine_match_dicts(pred_matches, m3_dict)\n",
        "    \n",
        "    return pred_matches\n",
        "\n",
        "uk_labels = get_uk_nhs_labels(labeling_set, features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Labeling Method 3: NCI SEER Labels\n",
        "The National Cancer Institute's Surveillance, Epidemiology, and End Results program provides the third and final set of labeling criteria our notebook uses for ground-truth classification. This system employs the following rules:\n",
        "\n",
        "1) two records should be linked if they are an exact match on SSN (MRN for our purposes), as well as fuzzy match on at least 2 of first name, last name, and birthdate\n",
        "2) of the remaining unlinked records, they should be considered a match if they are a fuzzy match on first name, last name, and sex, and are additionally a fuzzy match on either MRN or birthdate.\n",
        "\n",
        "The SEER labels are what we consider our \"best\" or most accurate/representative labels. They use fields that suit production data well, and they keep a good balance of sensitivity and specificity. Performance on these labels is our benchmark of which algorithm is functioning best."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "Generate the NCI's SEER Labels using two types of matches, based on whether or not\n",
        "the candidate pair has a perfectly agreeing MRN.\n",
        "'''\n",
        "def get_seer_labels(data, features):\n",
        "    mrn_matches = features.loc[features['mrn'] == 1.0]\n",
        "    matches_type_1 = mrn_matches.loc[\n",
        "        ((mrn_matches['first_name'] >= JARO_THRESHOLD) & (mrn_matches['last_name'] >= JARO_THRESHOLD)) |\n",
        "        ((mrn_matches['first_name'] >= JARO_THRESHOLD) & (mrn_matches['birthdate'] >= BIRTHDAY_THRESHOLD)) |\n",
        "        ((mrn_matches['birthdate'] >= BIRTHDAY_THRESHOLD) & (mrn_matches['last_name'] >= JARO_THRESHOLD))\n",
        "    ]\n",
        "\n",
        "    matches_type_2 = features.loc[\n",
        "        (features['first_name'] >= JARO_THRESHOLD) &\n",
        "        (features['last_name'] >= JARO_THRESHOLD) & \n",
        "        (features['sex'] >= JARO_THRESHOLD) &\n",
        "        (\n",
        "            ((features['mrn'] >= JARO_THRESHOLD) & (features['birthdate'] >= BIRTHDAY_THRESHOLD)) | \n",
        "            (features['birthdate'] == 1.0)\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    m1_dict = get_pred_match_dict_from_multi_idx(matches_type_1.index, len(data))\n",
        "    m2_dict = get_pred_match_dict_from_multi_idx(matches_type_2.index, len(data))\n",
        "    pred_matches = combine_match_dicts(m1_dict, m2_dict)\n",
        "\n",
        "    return pred_matches\n",
        "\n",
        "seer_labels = get_seer_labels(labeling_set, features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parallel Linkage Code\n",
        "The following massive cell contains all of the code that makes our record linkage analysis work. While we follow the same general format and structure of the versions of these functions present in the SDK, for this notebook, we need the parallel processing power spark can offer to make large-scale analysis computationally tractable. The functions below are heavily documented with comments spread throughout the code, but in general, an incoming record from the Evaluation Set undergoes the following process (each such record is computed in parallel to avoid looping over the large testing list):\n",
        "\n",
        "* fetch candidate records in a block from the spark-extracted version of the MPI\n",
        "* for each candidate record in the block, use the provided comparator functions to determine if the candidate is a match to the incoming record\n",
        "* map all matched candidates from the block back to their indexed ID in the original Labeling Set\n",
        "* deduplicate any match pairs that were found in multiple passes of the algorithm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# LINKAGE DRIVER FUNCTIONS\n",
        "\n",
        "import re\n",
        "\n",
        "\"\"\"\n",
        "Extracts values from a given patient record for eventual use in database\n",
        "record linkage blocking. A list of fields to block on, as well as a mapping\n",
        "of those fields to any desired transformations of their extracted values,\n",
        "is used to fhir-path parse the value out of the incoming patient record.\n",
        "\"\"\"\n",
        "def extract_blocking_values_from_record(\n",
        "    record: dict, blocking_fields: List[dict]\n",
        ") -> dict:\n",
        "    transform_funcs = {\n",
        "        \"first4\": lambda x: x[:4] if len(x) >= 4 else x,\n",
        "        \"last4\": lambda x: x[-4:] if len(x) >= 4 else x,\n",
        "    }\n",
        "\n",
        "    block_vals = dict.fromkeys([b.get(\"value\") for b in blocking_fields], \"\")\n",
        "    transform_blocks = [b for b in blocking_fields if \"transformation\" in b]\n",
        "    transformations = dict(\n",
        "        zip(\n",
        "            [b.get(\"value\") for b in transform_blocks],\n",
        "            [b.get(\"transformation\") for b in transform_blocks],\n",
        "        )\n",
        "    )\n",
        "    for block_dict in blocking_fields:\n",
        "        block = block_dict.get(\"value\")\n",
        "\n",
        "        # Apply utility extractor for safe parsing\n",
        "        value = extract_value_with_resource_path(\n",
        "            record,\n",
        "            LINKING_FIELDS_TO_FHIRPATHS[block],\n",
        "            selection_criteria=\"first\",\n",
        "        )\n",
        "        if value:\n",
        "            if block in transformations:\n",
        "                value = transform_funcs[transformations[block]](value)\n",
        "                block_vals[block] = {\n",
        "                    \"value\": value,\n",
        "                    \"transformation\": transformations[block],\n",
        "                }\n",
        "            else:\n",
        "                block_vals[block] = {\"value\": value}\n",
        "\n",
        "    # Account for any incoming FHIR resources that return no data\n",
        "    # for a field--don't count this against records to-block\n",
        "    keys_to_pop = []\n",
        "    for field in block_vals:\n",
        "        if _is_empty_extraction_field(block_vals, field):\n",
        "            keys_to_pop.append(field)\n",
        "    for k in keys_to_pop:\n",
        "        block_vals.pop(k)\n",
        "\n",
        "    return block_vals\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Helper method that determines when a field extracted from an incoming\n",
        "record should be considered \"empty\" for the purpose of blocking.\n",
        "Fields whose values are either `None` or the empty string should not\n",
        "be used when retrieving blocked records from the MPI, since that\n",
        "would impose an artificial constraint (e.g. if an incoming record\n",
        "has no `last_name` field, we don't want to retrieve only records\n",
        "from the MPI that also have no `last_name`).\n",
        "\"\"\"\n",
        "def _is_empty_extraction_field(block_vals: dict, field: str):\n",
        "    # Means the value extractor found no data in the FHIR resource\n",
        "    if block_vals[field] == \"\":\n",
        "        return True\n",
        "    # Alternatively, there was \"data\" there, but it's empty\n",
        "    elif (\n",
        "        block_vals[field].get(\"value\") is None\n",
        "        or block_vals[field].get(\"value\") == \"\"\n",
        "        or block_vals[field].get(\"value\") == [\"\"]\n",
        "    ):\n",
        "        return True  # pragma: no cover\n",
        "    return False\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Function that uses a pandas DataFrame construct of an extracted MPI to efficiently\n",
        "filter down candidates into appropriate blocks. While the filtering itself is not\n",
        "parallelized, since it occurs on the worker nodes, each executor is performing\n",
        "linkage for one or more test records simultaneously. As a result, a pandas DF\n",
        "provides an appropriate level of speed to use .loc retrieval.\n",
        "\"\"\"\n",
        "def spark_block(block_vals: dict, labeling_set: pd.DataFrame):\n",
        "\n",
        "    # We'll sequentially apply each blocking filter, since that's equivalent to finding\n",
        "    # their intersection all at once\n",
        "    result = labeling_set\n",
        "    for blocking_criterion in block_vals:\n",
        "        props = block_vals[blocking_criterion]\n",
        "        if props[\"value\"] is None or props[\"value\"] == \"\":\n",
        "            continue\n",
        "\n",
        "        # Special case if we're blocking on first_name or address: pyspark can serialize these\n",
        "        # as JSON strings, but that means they actually get stored as strings, so we need to \n",
        "        # account for the brackets '[' and ']'\n",
        "        if blocking_criterion == \"first_name\" or blocking_criterion == \"address\":\n",
        "            if \"transformation\" in props:\n",
        "                if props[\"transformation\"] == \"first4\":\n",
        "                    result = result.loc[result[blocking_criterion].str.startswith(\"[\" + props[\"value\"])]\n",
        "                elif props[\"transformation\"] == \"last4\":\n",
        "                    result = result.loc[result[blocking_criterion].str.endswith(props[\"value\"] + \"]\")]\n",
        "            else:\n",
        "                result = result.loc[result[blocking_criterion] == \"[\" + props[\"value\"] + \"]\"]\n",
        "\n",
        "        # Regular case is just a straight string comparison since we've already stripped the \n",
        "        # de-serialization quotes\n",
        "        else:\n",
        "            if \"transformation\" in props:\n",
        "                if props[\"transformation\"] == \"first4\":\n",
        "                    result = result.loc[result[blocking_criterion].str.startswith(props[\"value\"])]\n",
        "                elif props[\"transformation\"] == \"last4\":\n",
        "                    result = result.loc[result[blocking_criterion].str.endswith(props[\"value\"])]\n",
        "            else:\n",
        "                result = result.loc[result[blocking_criterion] == props[\"value\"]]\n",
        "    return result\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Function that compares a single blocked candidate from the MPI with the\n",
        "incoming, now flattened, record. Comparison functions for evaluating the linkage\n",
        "match are applied iteratively, and a net score is accumulated giving the\n",
        "total strength of the linkage match. This function is applied sequentially to\n",
        "each of the candidate records returned in the block.\n",
        "\"\"\"\n",
        "def spark_compare_df_helper(row, flattened_record, funcs, col_to_idx, matching_rule, **kwargs):\n",
        "\n",
        "    # Iteratively accumulate results of each feature-wise comparison\n",
        "    match_score = 0.0\n",
        "    for col in funcs:\n",
        "        func = funcs[col]\n",
        "        feature_idx_in_record = col_to_idx[col]\n",
        "        feature_in_record = flattened_record[feature_idx_in_record]\n",
        "\n",
        "        if \"fuzzy\" in func:\n",
        "            similarity_measure, fuzzy_threshold = _get_fuzzy_comp_params(col, **kwargs)\n",
        "\n",
        "            # Given name is a list (possibly including middle name), so our logic says\n",
        "            # concatenate all the values together and then fuzzy compare\n",
        "            if col == \"first_name\":\n",
        "                feature_in_record = \" \".join(feature_in_record)\n",
        "                feature_in_mpi = re.sub(r'\\[|\\]', \"\", row[col])\n",
        "                feature_in_mpi = feature_in_mpi.split(\", \")\n",
        "                feature_in_mpi = \" \".join(feature_in_mpi)\n",
        "                feature_score = compare_strings(feature_in_mpi, feature_in_record, similarity_measure)\n",
        "                match_score = _apply_score_contribution(\n",
        "                    feature_score, col, fuzzy_threshold, match_score, matching_rule, **kwargs\n",
        "                )\n",
        "\n",
        "            # Address is also a list, but rather than concatenate them all, we check if each\n",
        "            # line of an incoming address matches any line of an MPI address; this accounts for\n",
        "            # a patient's change of residence history\n",
        "            elif col == \"address\":\n",
        "                feature_in_mpi = re.sub(r'\\[|\\]', \"\", row[col])\n",
        "                feature_in_mpi = feature_in_mpi.split(\", \")\n",
        "                best_score = 0.0\n",
        "                for r in feature_in_record:\n",
        "                    for m in feature_in_mpi:\n",
        "                        feature_comp = compare_strings(r, m, similarity_measure)\n",
        "                        if feature_comp > best_score:\n",
        "                            best_score = feature_comp\n",
        "                match_score = _apply_score_contribution(\n",
        "                    best_score, col, fuzzy_threshold, match_score, matching_rule, **kwargs\n",
        "                )\n",
        "            \n",
        "            # Regular case: straight string comparison on the fields\n",
        "            else:\n",
        "                feature_in_mpi = row[col]\n",
        "                feature_score = compare_strings(feature_in_mpi, feature_in_record, similarity_measure)\n",
        "                match_score = _apply_score_contribution(\n",
        "                    feature_score, col, fuzzy_threshold, match_score, matching_rule, **kwargs\n",
        "                )\n",
        "        else:\n",
        "            feature_in_mpi = row[col]\n",
        "            feature_score = compare_strings(feature_in_mpi, feature_in_record, similarity_measure)\n",
        "            match_score = _apply_score_contribution(\n",
        "                feature_score, col, 1.0, match_score, matching_rule, **kwargs\n",
        "            )\n",
        "\n",
        "    return pd.Series([row['patient_id'], match_score])\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Quick helper to extract the threshold and metric used in fuzzy string comparisons.\n",
        "We have this to not clutter the main analytic function.\n",
        "\"\"\"\n",
        "def _get_fuzzy_comp_params(col, **kwargs):\n",
        "    similarity_measure = \"JaroWinkler\"\n",
        "    if \"similarity_measure\" in kwargs:\n",
        "        similarity_measure = kwargs[\"similarity_measure\"]\n",
        "    threshold = 0.7\n",
        "    \n",
        "    # Optional unique threshold per column in the data\n",
        "    if \"thresholds\" in kwargs:\n",
        "        if col in kwargs[\"thresholds\"]:\n",
        "            threshold = kwargs[\"thresholds\"][col]\n",
        "    \n",
        "    # Single universal threshold for all fields\n",
        "    elif \"threshold\" in kwargs:\n",
        "        threshold = kwargs[\"threshold\"]\n",
        "        \n",
        "    return similarity_measure, threshold\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Helper to apply the result of a feature-wise comparison between an incoming record and a \n",
        "candidate from the MPI to the accumulated 'match score' of the two. In a 'normal' case\n",
        "where we're not using log-odds, this is just a count of the number of feature comparisons\n",
        "that satisfy the fuzzy string threshold. In the log-odds case, this is an accumulation of\n",
        "the weighted probability score that the two records are a match.\n",
        "\"\"\"\n",
        "def _apply_score_contribution(feature_score, col, fuzzy_threshold, match_score, match_rule, **kwargs):\n",
        "    if \"log\" in match_rule:\n",
        "        col_odds = kwargs[\"log_odds\"][col]\n",
        "        match_score += (feature_score * col_odds)\n",
        "    else:\n",
        "        if feature_score >= fuzzy_threshold:\n",
        "            match_score += 1.0\n",
        "    return match_score\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Orchestrator function that provisions the RDD-mapping of the parallel candidate evaluation.\n",
        "Once we've parallel-processed the candidates, we apply RDD filtering to identify only those\n",
        "candidates who satisfy the provided matching rule. (be that \"all feature-wise comparisons are\n",
        "true\" or \"total probability score exceeds log-odds cutoff\").\n",
        "\"\"\"\n",
        "def spark_compare(data_block: pd.DataFrame, record: List, funcs: dict, col_to_idx: dict, matching_rule, **kwargs):\n",
        "    res = data_block.apply(lambda x: spark_compare_df_helper(x, record, funcs, col_to_idx, matching_rule, **kwargs), axis=1)\n",
        "    if \"log\" in matching_rule:\n",
        "        match_cutoff = kwargs[\"true_match_threshold\"]\n",
        "    else:\n",
        "        match_cutoff = len(funcs)\n",
        "    match_list = res.loc[res[1] >= match_cutoff]\n",
        "    match_list = list(match_list[0])\n",
        "    return match_list\n",
        "\n",
        "\n",
        "'''\n",
        "Main driver function that's applied in parallel to each record of the incoming\n",
        "evaluation set. The procedure is much the same as if the record were being\n",
        "processed in real time, except that a pandas dataframe (rather than a networked\n",
        "DB) is used to retrieve the candidate block for speed purposes.\n",
        "'''\n",
        "def parallel_eval(record, algo_config: List[dict], labeling_set: pd.DataFrame, testing_field=None, testing_vals=None):\n",
        "\n",
        "    # Flatten incoming resource and remove any lurking None's\n",
        "    flattened_record = flatten_patient_resource(record, FIELD_COLS_TO_IDX)\n",
        "    if flattened_record[2] is None:\n",
        "        flattened_record[2] = [\"\"]\n",
        "    if flattened_record[5] is None:\n",
        "        flattened_record[5] = [\"\"]\n",
        "\n",
        "    if testing_field:\n",
        "        matches = {str(x): [] for x in testing_vals}\n",
        "    else:\n",
        "        matches = []\n",
        "\n",
        "    for linkage_pass in algo_config:\n",
        "        blocking_fields = linkage_pass[\"blocks\"]\n",
        "        field_blocks = extract_blocking_values_from_record(record, blocking_fields)\n",
        "        if len(field_blocks) == 0:\n",
        "            continue\n",
        "        \n",
        "        # Use the extract of the MPI to quickly filter down a block of candidates\n",
        "        data_block = spark_block(field_blocks, labeling_set)\n",
        "        col_to_idx = {v: k for k, v in enumerate(formatted_cols)}\n",
        "\n",
        "        # Parallel process the candidates to find any matches\n",
        "        kwargs = linkage_pass.get(\"kwargs\", {})\n",
        "\n",
        "        if testing_field:\n",
        "            for tv in testing_vals:\n",
        "                vkwargs = copy.deepcopy(kwargs)\n",
        "                vkwargs[\"thresholds\"][testing_field] = tv\n",
        "                matching_records = spark_compare(\n",
        "                    data_block, flattened_record, linkage_pass[\"funcs\"], col_to_idx, linkage_pass[\"matching_rule\"], **vkwargs\n",
        "                )\n",
        "                matches[str(tv)] += matching_records\n",
        "        else:\n",
        "            matching_records = spark_compare(\n",
        "                data_block, flattened_record, linkage_pass[\"funcs\"], col_to_idx, linkage_pass[\"matching_rule\"], **kwargs\n",
        "            )\n",
        "            matches += matching_records\n",
        "\n",
        "    if testing_field:\n",
        "        return flattened_record[0], [matches[str(tv)] for tv in testing_vals]\n",
        "    else:\n",
        "        return flattened_record[0], matches\n",
        "\n",
        "\n",
        "'''\n",
        "Turn the patient_ids of identified \"found matches\" into the threaded multi-row-indices\n",
        "that the ground truth labeler can understand. This way, all indices are expressed in\n",
        "the same scheme for statistical comparison.\n",
        "'''\n",
        "def map_patient_ids_to_idxs(pids: List, data: pd.DataFrame):\n",
        "    record_idxs = []\n",
        "    for pid in pids:\n",
        "        row_idx = data[data['patient_id'] == pid].index.values\n",
        "        if len(row_idx) > 0:\n",
        "            record_idxs.append(row_idx[0])\n",
        "    return record_idxs\n",
        "\n",
        "\n",
        "'''\n",
        "Find existing patient records in a dataset that map to each incoming record in a block \n",
        "of FHIR data. Since the FHIR data itself is pulled from the MPI, we can freely use it\n",
        "for querying for blocks without risk of finding unrecognized data.\n",
        "'''\n",
        "def link_all_fhir_records_block_dataset(records, algo_config: List[dict], label_set: pd.DataFrame, testing_field=None, testing_vals=None):\n",
        "    if testing_field:\n",
        "        if not testing_vals or len(testing_vals) == 0:\n",
        "            print(\"Must supply list of threshold values to test\")\n",
        "            return\n",
        "        found_matches = { str(x): {} for x in testing_vals }\n",
        "    else:\n",
        "        found_matches = {}\n",
        "    start = time.time()\n",
        "    res = records.map(lambda x: parallel_eval(x, algo_config, label_set, testing_field, testing_vals))\n",
        "    res.cache()\n",
        "\n",
        "    if testing_field:\n",
        "        for x in res.collect():\n",
        "            ridx = map_patient_ids_to_idxs([x[0]], label_set)[0]\n",
        "            for tv in range(len(x[1])):\n",
        "                linked_rs_at_threshold = x[1][tv]\n",
        "                lidx = set(linked_rs_at_threshold)\n",
        "                lidx = map_patient_ids_to_idxs(lidx, label_set)\n",
        "                found_matches[str(testing_vals[tv])][ridx] = set(lidx)\n",
        "            \n",
        "        print(\"finished linking \", str(time.time() - start))\n",
        "        return found_matches\n",
        "\n",
        "    else:\n",
        "        for x in res.collect():\n",
        "            ridx = map_patient_ids_to_idxs([x[0]], label_set)[0]\n",
        "            lidx = set(x[1])\n",
        "            lidx = map_patient_ids_to_idxs(lidx, label_set)\n",
        "            found_matches[ridx] = set(lidx)\n",
        "\n",
        "        print(\"finished linking \", str(time.time() - start))\n",
        "        return found_matches\n",
        "\n",
        "'''\n",
        "Due to transforming patient_ids back into indices, multiple tuples get inserted for each\n",
        "match, i.e. we record the link (i,j) and the link (j,i), which would skew our stats.\n",
        "This function eliminates these redundancies and makes sure each link is counted once.\n",
        "'''\n",
        "def dedupe_match_double_counts(match_dict, is_fuzzy_test=False):\n",
        "    if is_fuzzy_test:\n",
        "        for tv in match_dict:\n",
        "            sub_dict = match_dict[tv]\n",
        "            for k in sub_dict:\n",
        "                if k > 0:\n",
        "                    lower_set = set(list(range(k)))\n",
        "                    sub_dict[k] = sub_dict[k].difference(lower_set)\n",
        "                if k in sub_dict[k]:\n",
        "                    sub_dict[k].remove(k)\n",
        "        return match_dict\n",
        "    \n",
        "    else:\n",
        "        for k in match_dict:\n",
        "            if k > 0:\n",
        "                lower_set = set(list(range(k)))\n",
        "                match_dict[k] = match_dict[k].difference(lower_set)\n",
        "            if k in match_dict[k]:\n",
        "                match_dict[k].remove(k)\n",
        "        return match_dict\n",
        "\n",
        "\n",
        "# Change the real None-type values back into their placeholders so we can mass-boolean filter\n",
        "labeling_set = labeling_set.replace({None: \"\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## `test_thresholds` Mode\n",
        "The following cell holds the code necessary to perform fuzzy matching threshold testing for a given patient field. When run in this mode, the statistical outputs of each value of the tested field are displayed so that a user can choose the threshold that best meets their needs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Helper function that scores a fuzzy matching threshold test on a subset of relevant\n",
        "performance statistics.\n",
        "\"\"\"\n",
        "def score_fuzzy_test(found_matches, true_matches, records_in_dataset, testing_vals):\n",
        "    scores = {}\n",
        "    for tv in testing_vals:\n",
        "        true_positives = 0.0\n",
        "        false_positives = 0.0\n",
        "        false_negatives = 0.0\n",
        "        matches_at_threshold = found_matches[str(tv)]\n",
        "\n",
        "        for root_record in true_matches:\n",
        "            if root_record in matches_at_threshold:\n",
        "                true_positives += len(\n",
        "                    true_matches[root_record].intersection(matches_at_threshold[root_record])\n",
        "                )\n",
        "                false_positives += len(\n",
        "                    matches_at_threshold[root_record].difference(true_matches[root_record])\n",
        "                )\n",
        "                false_negatives += len(\n",
        "                    true_matches[root_record].difference(matches_at_threshold[root_record])\n",
        "                )\n",
        "            else:\n",
        "                false_negatives += len(true_matches[root_record])\n",
        "        for record in set(set(matches_at_threshold.keys()).difference(true_matches.keys())):\n",
        "            false_positives += len(matches_at_threshold[record])\n",
        "\n",
        "        sensitivity = round(true_positives / (true_positives + false_negatives), 3)\n",
        "        ppv = round(true_positives / (true_positives + false_positives), 3)\n",
        "        f1 = round(\n",
        "            (2 * true_positives) / (2 * true_positives + false_negatives + false_positives),\n",
        "            3,\n",
        "        )\n",
        "        f_half_num = (1.0 + 0.5**2) * true_positives\n",
        "        f_half_denom_new = (0.5**2) * false_negatives + false_positives\n",
        "        f_half = round(f_half_num / (f_half_num + f_half_denom_new), 3)\n",
        "        scores[str(tv)] = {\n",
        "            \"tp\": true_positives,\n",
        "            \"fp\": false_positives,\n",
        "            \"fn\": false_negatives,\n",
        "            \"sens\": sensitivity,\n",
        "            \"ppv\": ppv,\n",
        "            \"f1\": f1,\n",
        "            \"f_half\": f_half\n",
        "        }\n",
        "    \n",
        "    return scores\n",
        "\n",
        "\n",
        "if NOTEBOOK_MODE == \"test_thresholds\":\n",
        "    new_algo = copy.deepcopy(DIBBS_BASIC)\n",
        "    col_thresholds = {\n",
        "        \"address\": 0.85,\n",
        "        \"birthdate\": 0.85,\n",
        "        \"city\": 0.85,\n",
        "        \"first_name\": 0.85,\n",
        "        \"last_name\": 0.85,\n",
        "        \"mrn\": 0.85,\n",
        "        \"sex\": 0.85,\n",
        "        \"state\": 0.85,\n",
        "        \"zip\": 0.85\n",
        "    }\n",
        "    new_algo[0][\"kwargs\"] = { \"thresholds\": col_thresholds }\n",
        "    new_algo[1][\"kwargs\"] = { \"thresholds\": col_thresholds }\n",
        "\n",
        "    found_matches_dibbs_basic = link_all_fhir_records_block_dataset(evaluation_set, new_algo, labeling_set, TESTING_FIELD, TESTING_VALS)\n",
        "    found_matches_dibbs_basic = dedupe_match_double_counts(found_matches_dibbs_basic, True)\n",
        "    eval_scores = score_fuzzy_test(found_matches_dibbs_basic, seer_labels, EVALUATION_SIZE, TESTING_VALS)\n",
        "    for t in eval_scores:\n",
        "        print(t, eval_scores[t])\n",
        "        print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## `train_weights` Mode\n",
        "The cells below contain code necessary to run the notebook in log-odds training mode, which allows a user to recompute the population weights for each field of patient data for later use with the DIBBs Enhanced algorithm. Weights training is made up of several steps:\n",
        "\n",
        "* recalculate the m- and u-probabilities, which measure the likelihoods that two records will have the same field value conditioned on whether or not the records match\n",
        "* recompute the log-odds, which is a ratio of the m- and u-probabilities calculated above\n",
        "* compute the distribution of feature scures for candidate pairs which do match and for a selection of candidate pairs which don't match\n",
        "* visualize these distributions to identify the cutoff score separating matches from non-matches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RECOMPUTE AND EXPORT LOG-ODDS\n",
        "# Estimates the m and u probabilities, computes their log-odds ratio,\n",
        "# then saves the output to a file for later loading.\n",
        "\n",
        "from random import randint\n",
        "from math import log\n",
        "\n",
        "\"\"\"\n",
        "For a given set of patient records, calculate the per-field\n",
        "m-probability. The m-probability for field X is defined as the\n",
        "probability that a pair of records A and B have the same value in\n",
        "X, given that A and B are a true matching pair. This function\n",
        "incorporates LaPlacian Smoothing to account for unseen data and\n",
        "to resolve future logarithms against 0.\n",
        "\"\"\"\n",
        "def calculate_m_probs(\n",
        "    data: pd.DataFrame,\n",
        "    true_matches: dict,\n",
        "    cols: Union[List[str], None] = None,\n",
        "):\n",
        "    if cols is None:\n",
        "        cols = data.columns\n",
        "    m_probs = {c: 1.0 for c in cols}\n",
        "    total_pairs = 1.0\n",
        "    for root_record, paired_records in true_matches.items():\n",
        "        total_pairs += len(paired_records)\n",
        "        for pr in paired_records:\n",
        "            for c in cols:\n",
        "                if data[c].iloc[root_record] == data[c].iloc[pr]:\n",
        "                    m_probs[c] += 1\n",
        "    for c in cols:\n",
        "        m_probs[c] /= total_pairs\n",
        "    return m_probs\n",
        "\n",
        "\"\"\"\n",
        "Function to estimate the u-probabilities of a set of data using a quick-check\n",
        "RNG heuristic to estimate negative pairs.\n",
        "\"\"\"\n",
        "def calculate_u_probs(\n",
        "    data: pd.DataFrame,\n",
        "    true_matches: dict,\n",
        "    n_samples: int,\n",
        "):\n",
        "\n",
        "    # Quick heuristic check to make sure we can generate enough\n",
        "    # negative samples to satisfy the parameter request\n",
        "    max_combos = (len(data.index) * (len(data.index) - 1)) / 2.0\n",
        "    # Based on bernoulli limits for deterministic runtimes, don't worry about the ln(2)\n",
        "    # This is how many neg pairs you can expect to generate in \"reasonable\" time\n",
        "    runtime_sample_neg_ceiling = np.log(2) * 0.10 * max_combos\n",
        "    if n_samples >= runtime_sample_neg_ceiling:\n",
        "        print(\"Too many samples requested for data size. Lower n_samples parameter.\")\n",
        "        return\n",
        "\n",
        "    u_probs = {c: 1.0 for c in data.columns}\n",
        "    neg_pairs = set()\n",
        "\n",
        "    # Use speed of RNGers to take a sample out of all possible non-match pairs\n",
        "    # without explicitly constructing the list\n",
        "    while len(neg_pairs) < n_samples:\n",
        "        idx1 = randint(0, len(data.index)-1)\n",
        "        idx2 = randint(0, len(data.index)-1)\n",
        "        root = min(idx1, idx2)\n",
        "        ref = max(idx1, idx2)\n",
        "        if root not in true_matches or ref not in true_matches[root]:\n",
        "            neg_pairs.add((root, ref))\n",
        "\n",
        "    neg_pairs = list(neg_pairs)\n",
        "\n",
        "    # Count up the number of candidate pairs that have a field that matches,\n",
        "    # then normalize per field\n",
        "    for root, ref in neg_pairs:\n",
        "        for c in data.columns:\n",
        "            if data[c].iloc[root] == data[c].iloc[ref]:\n",
        "                u_probs[c] += 1.0\n",
        "    for c in data.columns:\n",
        "            u_probs[c] = u_probs[c] / (n_samples + 1.0)\n",
        "\n",
        "    return u_probs\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Calculate the per-field log odds ratio score that two records will\n",
        "match in a given field. Measures the likelihood that two records\n",
        "match on a column due to being a true match as opposed to random\n",
        "chance.\n",
        "\"\"\"\n",
        "def calculate_log_odds(\n",
        "    m_probs: dict,\n",
        "    u_probs: dict,\n",
        "):\n",
        "    if m_probs.keys() != u_probs.keys():\n",
        "        raise ValueError(\n",
        "            \"m- and u- probability dictionaries must contain the same set of keys\"\n",
        "        )\n",
        "    log_odds = {}\n",
        "    for k in m_probs:\n",
        "        log_odds[k] = log(m_probs[k]) - log(u_probs[k])\n",
        "    return log_odds\n",
        "\n",
        "\n",
        "if NOTEBOOK_MODE == \"train_weights\":\n",
        "    m_probs = calculate_m_probs(labeling_set, seer_labels)\n",
        "    u_probs = calculate_u_probs(labeling_set, seer_labels, n_samples=NEG_SAMPLES)\n",
        "    log_odds = calculate_log_odds(m_probs, u_probs)\n",
        "    log_odds.pop(\"patient_id\")\n",
        "    log_odds.pop(\"person_id\")\n",
        "    print(log_odds)\n",
        "    mssparkutils.fs.put(LINKAGE_OUTPUTS_FILESYSTEM + \"updated_log_odds.json\", json.dumps(log_odds), True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# PROFILE LOG-ODDS WEIGHTS FOR CUTOFF DETERMINATION\n",
        "# Run computations on the log-odds cutoff scores for both matches and non-matches\n",
        "# for later graphical evaluation.\n",
        "\n",
        "\"\"\"\n",
        "Helper function that computes the match score between two records in the same\n",
        "data set, given a set of columns on which to perform fuzzy match evaluation.\n",
        "\"\"\"\n",
        "def profiling_df_helper(data, idx_i, idx_j, fuzzy_cols, log_odds, col_to_idx, cols_to_thresholds=None):\n",
        "\n",
        "    # Iteratively accumulate results of each feature-wise comparison\n",
        "    match_score = 0.0\n",
        "    ri = data[idx_i]\n",
        "    rj = data[idx_j]\n",
        "\n",
        "    for col in fuzzy_cols:\n",
        "        col_odds = log_odds[col]\n",
        "        cidx = col_to_idx[col]\n",
        "        similarity_measure=\"JaroWinkler\"\n",
        "        min_sim_threshold = 0.85\n",
        "        if cols_to_thresholds is not None:\n",
        "            if col in cols_to_thresholds:\n",
        "                min_sim_threshold = cols_to_thresholds[col]\n",
        "\n",
        "        # Given name is a list (possibly including middle name), so our logic says\n",
        "        # concatenate all the values together and then fuzzy compare\n",
        "        if col == \"first_name\":\n",
        "            feature_in_record = re.sub(r'\\[|\\]', \"\", ri[cidx])\n",
        "            feature_in_record = feature_in_record.split(\", \")\n",
        "            feature_in_record = \" \".join(feature_in_record)\n",
        "            feature_in_mpi = re.sub(r'\\[|\\]', \"\", rj[cidx])\n",
        "            feature_in_mpi = feature_in_mpi.split(\", \")\n",
        "            feature_in_mpi = \" \".join(feature_in_mpi)\n",
        "            feature_score = compare_strings(feature_in_mpi, feature_in_record, similarity_measure)\n",
        "\n",
        "        # Address is also a list, but rather than concatenate them all, we check if each\n",
        "        # line of an incoming address matches any line of an MPI address; this accounts for\n",
        "        # a patient's change of residence history\n",
        "        elif col == \"address\":\n",
        "            feature_in_record = re.sub(r'\\[|\\]', \"\", ri[cidx])\n",
        "            feature_in_record = feature_in_record.split(\", \")\n",
        "            feature_in_mpi = re.sub(r'\\[|\\]', \"\", rj[cidx])\n",
        "            feature_in_mpi = feature_in_mpi.split(\", \")\n",
        "            feature_score = 0.0\n",
        "            for r in feature_in_record:\n",
        "                for m in feature_in_mpi:\n",
        "                    feature_comp = compare_strings(r, m, similarity_measure)\n",
        "                    if feature_comp > feature_score:\n",
        "                        feature_score = feature_comp\n",
        "        \n",
        "        # Regular case: straight string comparison on the fields\n",
        "        else:\n",
        "            feature_in_record = ri[cidx]\n",
        "            feature_in_mpi = rj[cidx]\n",
        "            feature_score = compare_strings(feature_in_mpi, feature_in_record, similarity_measure)\n",
        "        \n",
        "        match_score += feature_score * col_odds\n",
        "\n",
        "    return match_score\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Function to generate net feature scores for a set of patient record data.\n",
        "These scores can later be used to build distributions of matches vs non-\n",
        "matches for graphical separation.\n",
        "\"\"\"\n",
        "def profile_log_odds_computation(\n",
        "    data: pd.DataFrame,\n",
        "    true_matches: dict,\n",
        "    log_odds: dict,\n",
        "    fuzzy_cols,\n",
        "    neg_samples: int = 50000,\n",
        "    cols_to_thresholds = None,\n",
        "):\n",
        "    neg_pairs = set()\n",
        "    while len(neg_pairs) < neg_samples:\n",
        "        idx1 = randint(0, len(data.index)-1)\n",
        "        idx2 = randint(0, len(data.index)-1)\n",
        "        root = min(idx1, idx2)\n",
        "        ref = max(idx1, idx2)\n",
        "        if root not in true_matches or ref not in true_matches[root]:\n",
        "            neg_pairs.add((root, ref))\n",
        "\n",
        "    neg_pairs = list(neg_pairs)\n",
        "\n",
        "    data_cols = list(data.columns)\n",
        "    col_to_idx = dict(zip(data_cols, range(len(data_cols))))\n",
        "    data = data.values.tolist()\n",
        "\n",
        "    true_match_scores = []\n",
        "    for root_record, paired_records in true_matches.items():\n",
        "        for pr in paired_records:\n",
        "            score = profiling_df_helper(data, root_record, pr, fuzzy_cols, log_odds, col_to_idx, cols_to_thresholds)\n",
        "            true_match_scores.append(score)\n",
        "\n",
        "    non_match_scores = []\n",
        "    for record_1, record_2 in neg_pairs:\n",
        "        score = profiling_df_helper(data, record_1, record_2, fuzzy_cols, log_odds, col_to_idx, cols_to_thresholds)\n",
        "        non_match_scores.append(score)\n",
        "    \n",
        "    return true_match_scores, non_match_scores\n",
        "\n",
        "\n",
        "if NOTEBOOK_MODE == \"train_weights\":\n",
        "    match_scores, non_match_scores = profile_log_odds_computation(labeling_set, seer_labels, log_odds, COLS_TO_PROFILE, NEG_SAMPLES, COLS_TO_THRESHOLDS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualizing Cutoff Scores\n",
        "The cell below creates a visualization of the distributions of match scores and non-match scores. Since matplotlib can't interactively zoom in Synapse, there are a selection of controls at the top of the cell that allow regeneration of the graph with different ranges to create the effect of zooming in anyway.\n",
        "\n",
        "IMPORTANT: Once a `train_weights` run is completed to this point, you can change the graph to zoom in or out **without** re-running the expensive linkage code above. The results are saved by the previous cell, so this cell's only responsibility is to show those results in a graph. Simply re-run this individual cell with different axis values to get a fast graphical update before moving on to changing the columns at the top of the notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# VISUALIZE LOG-ODDS GRAPH\n",
        "# Graphically displays elbow curves of the log-odds total match scores for both\n",
        "# true matches and true non-matches (as determined by SEER labels) so that the\n",
        "# separating hyperplane can be determined.\n",
        "\n",
        "# Number of bars to show in the histogram--start with 75\n",
        "N_BINS = 100\n",
        "# Range of the x axis--start with 0 to 25, and if you can't see the two \n",
        "# distribution peaks, increase the right boundary\n",
        "X_RANGE = [0, 25]\n",
        "# Density of tick marks along the axis--once you start zooming in, adjust\n",
        "# this value to get a more precise number of the separation plane\n",
        "AXIS_TICK_DENSITY = 20\n",
        "# Display limits for the axis--making these closer together will have the\n",
        "# effect of zooming the graph in because the chart will still fill the whole\n",
        "# figure space\n",
        "AXIS_LIMITS = [0, 25]\n",
        "YLIM = [0, 50]\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def show_profiling_graph(match_scores, non_match_scores):\n",
        "    fig, ax = plt.subplots()\n",
        "    fig.set_size_inches(12,6)\n",
        "    _, bins, _ = plt.hist(match_scores, bins=N_BINS, range=X_RANGE)\n",
        "    _ = plt.hist(non_match_scores, bins=bins, alpha=0.5)\n",
        "\n",
        "    # Adjust the density of tick marks here to find the best separation boundary\n",
        "    ax.xaxis.set_major_locator(plt.MaxNLocator(AXIS_TICK_DENSITY))\n",
        "\n",
        "    # Use this min and max of the x axis to effectively zoom in\n",
        "    ax.set_xlim(AXIS_LIMITS)\n",
        "    ax.set_ylim(YLIM)\n",
        "    plt.show()\n",
        "\n",
        "if NOTEBOOK_MODE == \"train_weights\":\n",
        "    show_profiling_graph(match_scores, non_match_scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## `compare_algorithms` Mode\n",
        "This final collection of cells contains code that executes the notebook in comaprative mode. We run three algorithms and collect statistics on each of them for comparative purposes. Along the way, each algorithm's results are saved into a linked container, so that they can be loaded during future runs if desired. The three algorithms run are:\n",
        "\n",
        "* a Python port of LAC's current blocking and matching criteria from their linking R-script--since we're testing the general principles of linkage, we included no post-processing heuristics or additional rules which might boost performance\n",
        "* the DIBBs Basic algorithm\n",
        "* the DIBBs Enhanced algorithm, which has the same blocks and passes as the DIBBs Basic, but incorporates statistical correction in the form of additional weights on each field match"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ALGORITHM EVALUATION: LAC EXISTING\n",
        "\n",
        "LAC_ALGO = [\n",
        "    {\n",
        "        \"funcs\": {\n",
        "            \"first_name\": \"feature_match_fuzzy_string\",\n",
        "            \"last_name\": \"feature_match_fuzzy_string\",\n",
        "            \"address\": \"feature_match_fuzzy_string\",\n",
        "            \"mrn\": \"feature_match_fuzzy_string\",\n",
        "        },\n",
        "        \"blocks\": [\n",
        "            {\"value\": \"first_name\", \"transformation\": \"first4\"},\n",
        "            {\"value\": \"last_name\", \"transformation\": \"first4\"},\n",
        "            {\"value\": \"birthdate\"},\n",
        "        ],\n",
        "        \"matching_rule\": \"eval_perfect_match\",\n",
        "        \"cluster_ratio\": 0.9,\n",
        "    },\n",
        "    {\n",
        "        \"funcs\": {\n",
        "            \"first_name\": \"feature_match_fuzzy_string\",\n",
        "            \"last_name\": \"feature_match_fuzzy_string\",\n",
        "            \"address\": \"feature_match_fuzzy_string\",\n",
        "            \"mrn\": \"feature_match_fuzzy_string\",\n",
        "        },\n",
        "        \"blocks\": [\n",
        "            {\"value\": \"first_name\", \"transformation\": \"first4\"},\n",
        "            {\"value\": \"last_name\", \"transformation\": \"first4\"},\n",
        "            {\"value\": \"address\", \"transformation\": \"first4\"},\n",
        "        ],\n",
        "        \"matching_rule\": \"eval_perfect_match\",\n",
        "        \"cluster_ratio\": 0.9,\n",
        "    },\n",
        "    {\n",
        "        \"funcs\": {\n",
        "            \"first_name\": \"feature_match_fuzzy_string\",\n",
        "            \"last_name\": \"feature_match_fuzzy_string\",\n",
        "            \"address\": \"feature_match_fuzzy_string\",\n",
        "            \"mrn\": \"feature_match_fuzzy_string\",\n",
        "        },\n",
        "        \"blocks\": [\n",
        "            {\"value\": \"birthdate\"},\n",
        "        ],\n",
        "        \"matching_rule\": \"eval_perfect_match\",\n",
        "        \"cluster_ratio\": 0.9,\n",
        "    },\n",
        "]\n",
        "\n",
        "if NOTEBOOK_MODE == \"compare_algorithms\":\n",
        "    if LOAD_PREVIOUS_RUNS:\n",
        "        found_matches_lac = load_linkage_results(spark, \"lac_algorithm_results\")\n",
        "    if not LOAD_PREVIOUS_RUNS or found_matches_lac is None:\n",
        "        found_matches_lac = link_all_fhir_records_block_dataset(evaluation_set, LAC_ALGO, labeling_set)\n",
        "        found_matches_lac = dedupe_match_double_counts(found_matches_lac)\n",
        "        write_linkage_results(\"lac_algorithm_results\", found_matches_lac)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ALGORITHM EVALUATION: DIBBs BASIC\n",
        "\n",
        "new_algo = copy.deepcopy(DIBBS_BASIC)\n",
        "col_thresholds = {\n",
        "    \"address\": 0.85,\n",
        "    \"birthdate\": 0.85,\n",
        "    \"city\": 0.85,\n",
        "    \"first_name\": 0.85,\n",
        "    \"last_name\": 0.85,\n",
        "    \"mrn\": 0.85,\n",
        "    \"sex\": 0.85,\n",
        "    \"state\": 0.85,\n",
        "    \"zip\": 0.85\n",
        "}\n",
        "if len(FINAL_COLS_TO_THRESHOLDS) > 0:\n",
        "    print(\"Using experimentally updated fuzzy thresholds\")\n",
        "    new_algo[0][\"kwargs\"] = { \"thresholds\": FINAL_COLS_TO_THRESHOLDS }\n",
        "    new_algo[1][\"kwargs\"] = { \"thresholds\": FINAL_COLS_TO_THRESHOLDS }\n",
        "else:\n",
        "    print(\"Using default uniform fuzzy threshold\")\n",
        "    new_algo[0][\"kwargs\"] = { \"thresholds\": col_thresholds }\n",
        "    new_algo[1][\"kwargs\"] = { \"thresholds\": col_thresholds }\n",
        "\n",
        "if NOTEBOOK_MODE == \"compare_algorithms\":\n",
        "    if LOAD_PREVIOUS_RUNS:\n",
        "        found_matches_dibbs_basic = load_linkage_results(spark, \"dibbs_basic_algorithm_results\")\n",
        "    if not LOAD_PREVIOUS_RUNS or found_matches_dibbs_basic is None:\n",
        "        found_matches_dibbs_basic = link_all_fhir_records_block_dataset(evaluation_set, new_algo, labeling_set)\n",
        "        found_matches_dibbs_basic = dedupe_match_double_counts(found_matches_dibbs_basic)\n",
        "        write_linkage_results(\"dibbs_basic_algorithm_results\", found_matches_dibbs_basic)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ALGORITHM EVALUATION: DIBBs ENHANCED\n",
        "new_algo = copy.deepcopy(DIBBS_ENHANCED)\n",
        "col_thresholds = {\n",
        "    \"address\": 0.85,\n",
        "    \"birthdate\": 0.85,\n",
        "    \"city\": 0.85,\n",
        "    \"first_name\": 0.85,\n",
        "    \"last_name\": 0.85,\n",
        "    \"mrn\": 0.85,\n",
        "    \"sex\": 0.85,\n",
        "    \"state\": 0.85,\n",
        "    \"zip\": 0.85\n",
        "}\n",
        "del new_algo[0][\"kwargs\"][\"threshold\"]\n",
        "del new_algo[1][\"kwargs\"][\"threshold\"]\n",
        "\n",
        "if len(FINAL_LOG_ODDS) > 0:\n",
        "    print(\"Using experimentally calculated log-odds weights\")\n",
        "    new_algo[0][\"kwargs\"][\"log_odds\"] = FINAL_LOG_ODDS\n",
        "    new_algo[1][\"kwargs\"][\"log_odds\"] = FINAL_LOG_ODDS\n",
        "else:\n",
        "    print(\"Using default synthetically trained log-odds weights\")\n",
        "\n",
        "if len(FINAL_COLS_TO_THRESHOLDS) > 0:\n",
        "    print(\"Using experimentally updated fuzzy thresholds\")\n",
        "    new_algo[0][\"kwargs\"][\"thresholds\"] = FINAL_COLS_TO_THRESHOLDS\n",
        "    new_algo[1][\"kwargs\"][\"thresholds\"] = FINAL_COLS_TO_THRESHOLDS\n",
        "else:\n",
        "    print(\"Using default uniform fuzzy threshold\")\n",
        "    new_algo[0][\"kwargs\"][\"thresholds\"] = col_thresholds\n",
        "    new_algo[1][\"kwargs\"][\"thresholds\"] = col_thresholds\n",
        "\n",
        "if FINAL_PASS_1_THRESHOLD is not None:\n",
        "    print(\"Using experimental cutoff threshold 1\")\n",
        "    new_algo[0][\"kwargs\"][\"true_match_threshold\"] = FINAL_PASS_1_THRESHOLD\n",
        "else:\n",
        "    print(\"Using default cutoff threshold 1\")\n",
        "if FINAL_PASS_2_THRESHOLD is not None:\n",
        "    print(\"Using experimental cutoff threshold 2\")\n",
        "    new_algo[1][\"kwargs\"][\"true_match_threshold\"] = FINAL_PASS_2_THRESHOLD\n",
        "else:\n",
        "    print(\"Using default cutoff threshold 2\")\n",
        "\n",
        "if NOTEBOOK_MODE == \"compare_algorithms\":\n",
        "    if LOAD_PREVIOUS_RUNS:\n",
        "        found_matches_dibbs_enhanced = load_linkage_results(spark, \"dibbs_enhanced_algorithm_results\")\n",
        "    if not LOAD_PREVIOUS_RUNS or found_matches_dibbs_enhanced is None:\n",
        "        found_matches_dibbs_enhanced = link_all_fhir_records_block_dataset(evaluation_set, new_algo, labeling_set)\n",
        "        found_matches_dibbs_enhanced = dedupe_match_double_counts(found_matches_dibbs_enhanced)\n",
        "        write_linkage_results(\"dibbs_enhanced_algorithm_results\", found_matches_dibbs_enhanced)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RUN THE NUMBERS AND GET THE STATS FUNCTIONS\n",
        "\n",
        "'''\n",
        "To ensure accurate statistics, the matches and the true matches dictionaries\n",
        "in the statistical evaluation function should have the following form:\n",
        "\n",
        "{\n",
        "    row_num_of_record_in_data: set(row_nums_of_linked_records)\n",
        "}\n",
        "\n",
        "Each row in the data should be represented as a key in both dictionaries.\n",
        "The value for each of these keys should be a set that contains all other\n",
        "row numbers for records in the data set that link to the key record.\n",
        "'''\n",
        "\n",
        "def score_linkage_vs_truth(found_matches, true_matches, records_in_dataset):\n",
        "\n",
        "    # Need division by 2 because ordering is irrelevant, matches are symmetric\n",
        "    total_possible_matches = (records_in_dataset * (records_in_dataset - 1)) / 2.0\n",
        "    true_positives = 0.0\n",
        "    false_positives = 0.0\n",
        "    false_negatives = 0.0\n",
        "\n",
        "    for root_record in true_matches:\n",
        "        if root_record in found_matches:\n",
        "            true_positives += len(\n",
        "                true_matches[root_record].intersection(found_matches[root_record])\n",
        "            )\n",
        "            false_positives += len(\n",
        "                found_matches[root_record].difference(true_matches[root_record])\n",
        "            )\n",
        "            false_negatives += len(\n",
        "                true_matches[root_record].difference(found_matches[root_record])\n",
        "            )\n",
        "        else:\n",
        "            false_negatives += len(true_matches[root_record])\n",
        "    for record in set(set(found_matches.keys()).difference(true_matches.keys())):\n",
        "        false_positives += len(found_matches[record])\n",
        "\n",
        "    true_negatives = (\n",
        "        total_possible_matches - true_positives - false_positives - false_negatives\n",
        "    )\n",
        "    npv = round((true_negatives / (true_negatives + false_negatives)), 3)\n",
        "    sensitivity = round(true_positives / (true_positives + false_negatives), 3)\n",
        "    specificity = round(true_negatives / (true_negatives + false_positives), 3)\n",
        "    ppv = round(true_positives / (true_positives + false_positives), 3)\n",
        "    f1 = round(\n",
        "        (2 * true_positives) / (2 * true_positives + false_negatives + false_positives),\n",
        "        3,\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        \"tp\": true_positives,\n",
        "        \"fp\": false_positives,\n",
        "        \"fn\": false_negatives,\n",
        "        \"sens\": sensitivity,\n",
        "        \"spec\": specificity,\n",
        "        \"ppv\": ppv,\n",
        "        \"npv\": npv,\n",
        "        \"f1\": f1\n",
        "    }\n",
        "\n",
        "if NOTEBOOK_MODE == \"compare_algorithms\":\n",
        "    display_str = \"\"\n",
        "    n_records = EVALUATION_SIZE\n",
        "\n",
        "    for lbl_type in [\"va\", \"uk-nhs\", \"nci-seer\"]:\n",
        "        if lbl_type == \"va\":\n",
        "            labels = va_labels\n",
        "        elif lbl_type == \"nci-seer\":\n",
        "            labels = seer_labels\n",
        "        else:\n",
        "            labels = uk_labels\n",
        "        \n",
        "        stats_dict_lac = score_linkage_vs_truth(found_matches_lac, labels, n_records)\n",
        "        stats_dict_dibbs_b = score_linkage_vs_truth(found_matches_dibbs_basic, labels, n_records)\n",
        "        stats_dict_dibbs_e = score_linkage_vs_truth(found_matches_dibbs_enhanced, labels, n_records)\n",
        "\n",
        "        display_str += \"DISPLAYING EVALUATION ON \" + lbl_type.upper() + \" LABELS:\\n\"\n",
        "        display_str += \"\\n\"\n",
        "\n",
        "        for algo in [\"lac\", \"basic\", \"enhanced\"]:\n",
        "            if algo == \"lac\":\n",
        "                display_str += \"LAC Existing Algorithm:\\n\"\n",
        "                scores = stats_dict_lac\n",
        "            elif algo == \"basic\":\n",
        "                display_str += \"DIBBs Basic Algorithm:\\n\"\n",
        "                scores = stats_dict_dibbs_b\n",
        "            else:\n",
        "                display_str += \"DIBBs Log-Odds Algorithm:\\n\"\n",
        "                scores = stats_dict_dibbs_e\n",
        "\n",
        "            display_str += \"True Positives: \" + str(scores[\"tp\"]) + \"\\n\"\n",
        "            display_str += \"False Positives: \" + str(scores[\"fp\"]) + \"\\n\"\n",
        "            display_str += \"False Negatives: \" + str(scores[\"fn\"]) + \"\\n\"\n",
        "            display_str += \"Sensitivity: \" + str(scores[\"sens\"]) + \"\\n\"\n",
        "            display_str += \"Specificity: \" + str(scores[\"spec\"]) + \"\\n\"\n",
        "            display_str += \"PPV: \" + str(scores[\"ppv\"]) + \"\\n\"\n",
        "            display_str += \"NPV: \" + str(scores[\"npv\"]) + \"\\n\"\n",
        "            display_str += \"F1: \" + str(scores[\"f1\"]) + \"\\n\"\n",
        "            display_str += \"\\n\"\n",
        "        \n",
        "        display_str += \"\\n\"\n",
        "\n",
        "    print(display_str)\n",
        "\n",
        "    mssparkutils.fs.put(LINKAGE_OUTPUTS_FILESYSTEM + \"results.txt\", display_str, True)"
      ]
    }
  ],
  "metadata": {
    "description": null,
    "kernel_info": {
      "name": "synapse_pyspark"
    },
    "kernelspec": {
      "display_name": "Synapse PySpark",
      "language": "Python",
      "name": "synapse_pyspark"
    },
    "language_info": {
      "name": "python"
    },
    "save_output": true,
    "synapse_widget": {
      "state": {},
      "version": "0.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
