{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### tabularizePatientTable\n",
        "This notebook extracts all data from the Patient table (`patient`) in the Master Patient Index and tabularizes the data into Lists of Lists of Lists (LoLoL)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "pip install psycopg2-binary azure-identity phdi==1.0.6 recordlinkage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Database-related imports\n",
        "import psycopg2\n",
        "from psycopg2.sql import Identifier, SQL\n",
        "from azure.identity import DefaultAzureCredential\n",
        "from phdi.linkage.postgres import DIBBsConnectorClient\n",
        "\n",
        "# Ground-truth labeling imports\n",
        "import time\n",
        "import pandas as pd\n",
        "import recordlinkage as rl\n",
        "from phdi.linkage import score_linkage_vs_truth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# GLOBAL VARIABLES FOR DATABASE ACCESS\n",
        "\n",
        "# Set your Key Vault information\n",
        "vault_name = \"$KEY_VAULT\"\n",
        "KEY_VAULT_URL = f\"https://{vault_name}.vault.azure.net\"\n",
        "vault_linked_service = \"$KEY_VAULT_LINKED_SERVICE\"\n",
        "\n",
        "# Set up db_client\n",
        "DB_NAME = \"DibbsMpiDB\"\n",
        "DB_USER = \"postgres\"\n",
        "DB_HOST = \"$MPI_DB_HOST\"\n",
        "DB_PORT = \"5432\"\n",
        "DB_TABLE_PATIENT = \"patient\"\n",
        "DB_TABLE_PERSON= \"person\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# GLOBAL VARIABLES FOR GROUND-TRUTH LABELING\n",
        "DATA_SIZE = None    # Optional variable; if none, use whole table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# MPI ACCESS AND TABULATION FUNCTIONS\n",
        "\n",
        "# Generate a query to extract all data from the patient table of the MPI.\n",
        "def generate_query(db_client):\n",
        "    select_query_stubs = []\n",
        "    query_data = []\n",
        "    for key in db_client.fields_to_jsonpaths:\n",
        "        query = f\"jsonb_path_query_array(patient_resource,%s) as {key}\"\n",
        "        select_query_stubs.append(query)\n",
        "        query_data.append(db_client.fields_to_jsonpaths[key])\n",
        "\n",
        "    select_query = \"SELECT \" + \", \".join(stub for stub in select_query_stubs)\n",
        "\n",
        "    query = select_query + \" FROM {patient_table};\"\n",
        "    query = SQL(query).format(patient_table=Identifier(db_client.patient_table))\n",
        "    return query, query_data\n",
        "\n",
        "\n",
        "# Format returned data as Lists of Lists of Lists (LoLoL)\n",
        "def format_data(data, db_client):\n",
        "    db_client._close_connections(db_conn=conn, db_cursor=cur)\n",
        "    data_cols = []\n",
        "    for key in sorted(list(db_client.fields_to_jsonpaths.keys())):\n",
        "        data_cols.append(key)\n",
        "    data.insert(0, data_cols)\n",
        "    return data\n",
        "\n",
        "# Access the MPI Database\n",
        "credential = DefaultAzureCredential()\n",
        "db_password =  TokenLibrary.getSecret(vault_name,\"mpi-db-password\",vault_linked_service)\n",
        "db_client = DIBBsConnectorClient(database = DB_NAME, user = DB_USER, password = db_password, host= DB_HOST, port = DB_PORT, patient_table= DB_TABLE_PATIENT, person_table=DB_TABLE_PERSON)\n",
        "\n",
        "# Create a connection and a cursor\n",
        "conn = db_client.get_connection()\n",
        "cur = conn.cursor()\n",
        "\n",
        "# Query for the data and format it\n",
        "query, query_data = generate_query(db_client)\n",
        "cur.execute(query, query_data)\n",
        "data = [list(row) for row in cur.fetchall()]\n",
        "formatted_data = format_data(data,db_client)\n",
        "\n",
        "# Apply any size caveats, if desired\n",
        "if DATA_SIZE is not None:\n",
        "    dataset = formatted_data[:min(DATA_SIZE+1, len(formatted_data))]\n",
        "else:\n",
        "    dataset = formatted_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# GROUND TRUTH LABELING: VIRGINIA FUNCTIONS\n",
        "#TODO: write a simple labeling function that accepts a LoLoL and outputs a dictionary\n",
        "# of \"true matches\" in this data. For the format of this dictionary, see the evaluation\n",
        "# cell below. Since the order of the data doesn't matter, you can just use the row\n",
        "# number of the data in the list as its index for computing purposes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# GROUND-TRUTH LABELING: RECORD LINKAGE TOOLKIT FUNCTIONS\n",
        "\n",
        "# Transform a recordlinkage toolkit multi-index into a set of candidate tuples\n",
        "def get_pred_match_dict_from_multi_idx(mltidx, n_rows):\n",
        "    candidate_tuples = mltidx.to_list()\n",
        "    pred_matches = {k: set() for k in range(n_rows)}\n",
        "    for pair in candidate_tuples:\n",
        "        reference_record = min(pair)\n",
        "        linked_record = max(pair)\n",
        "        pred_matches[reference_record].add(linked_record)\n",
        "    return pred_matches\n",
        "\n",
        "\n",
        "def predict_third_party_labels(data):\n",
        "    data = pd.DataFrame(data[1:], columns=data[0])\n",
        "    start = time.time()\n",
        "\n",
        "    # Create a full index on patient table so we don't miss any pairs\n",
        "    indexer = rl.Index()\n",
        "    indexer.full()\n",
        "    candidate_links = indexer.index(data)\n",
        "    # Note: using a multi-indexer treats the row number as the index, so\n",
        "    # results will automatically be in acceptable eval format\n",
        "\n",
        "    print(len(candidate_links), \"candidate pairs identified\")\n",
        "\n",
        "    # Apply feature comparisons on each supported field from the MPI\n",
        "    comp = rl.Compare()\n",
        "    comp.string(\n",
        "        \"first_name\", \"first_name\", method=\"jarowinkler\", threshold=0.85, label=\"first_name\"\n",
        "    )\n",
        "    comp.string(\n",
        "        \"last_name\", \"last_name\", method=\"jarowinkler\", threshold=0.85, label=\"last_name\"\n",
        "    )\n",
        "    comp.string(\"mrn\", \"mrn\", method=\"jarowinkler\", threshold=0.85, label=\"mrn\")\n",
        "    comp.string(\n",
        "        \"birthdate\", \"birthdate\", method=\"jarowinkler\", threshold=0.85, label=\"birthdate\"\n",
        "    )\n",
        "    comp.string(\"address\", \"address\", method=\"jarowinkler\", threshold=0.85, label=\"address\")\n",
        "    comp.string(\"city\", \"city\", method=\"jarowinkler\", threshold=0.85, label=\"city\")\n",
        "    comp.string(\"state\", \"state\", method=\"jarowinkler\", threshold=0.85, label=\"state\")\n",
        "    comp.string(\"zip\", \"zip\", method=\"jarowinkler\", threshold=0.85, label=\"zip\")\n",
        "    comp.string(\"sex\", \"sex\", method=\"jarowinkler\", threshold=0.85, label=\"sex\")\n",
        "    features = comp.compute(candidate_links, data)\n",
        "\n",
        "    # Create an EM Predictor and label the binary training vectors\n",
        "    clf = rl.ECMClassifier()\n",
        "    pred_links = clf.fit_predict(features)\n",
        "\n",
        "    end = time.time()\n",
        "    print(\"Computation took\", str(round(end - start, 2)), \"seconds\")\n",
        "\n",
        "    n_rows = DATA_SIZE if DATA_SIZE is not None else len(data)\n",
        "    matches = get_pred_match_dict_from_multi_idx(pred_links, n_rows)\n",
        "    return matches\n",
        "\n",
        "third_party_labels = predict_third_party_labels(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ALGORITHM EVALUATION: LAC EXISTING\n",
        "# TODO: Write a function that runs LAC's existing algorithm on the LoLoL\n",
        "# data extracted from the MPI and creates matches following acceptable\n",
        "# evaluation dictionary format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ALGORITHM EVALUATION: DIBBs BASIC\n",
        "# TODO: Write a function that runs the DIBBs basic algorithm on the LoLoL\n",
        "# data extracted from the MPI and outputs its matches in a dictionary that\n",
        "# conforms to the row number format below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ALGORITHM EVALUATION: DIBBs ENHANCED\n",
        "# TODO: As above but with the DIBBs enhanced algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RUN THE NUMBERS AND GET THE STATS FUNCTIONS\n",
        "\n",
        "'''\n",
        "To ensure accurate statistics, the matches and the true matches dictionaries\n",
        "in the statistical evaluation function should have the following form:\n",
        "\n",
        "{\n",
        "    row_num_of_record_in_data: set(row_nums_of_linked_records)\n",
        "}\n",
        "\n",
        "Each row in the data should be represented as a key in both dictionaries.\n",
        "The value for each of these keys should be a set that contains all other\n",
        "row numbers for records in the data set that link to the key record.\n",
        "'''\n",
        "def display_statistical_evaluation(\n",
        "    matches: dict, true_matches: dict, cluster_mode_used: bool = False\n",
        "):\n",
        "    sensitivitiy, specificity, ppv, f1 = score_linkage_vs_truth(\n",
        "        matches, true_matches, DATA_SIZE, cluster_mode_used\n",
        "    )\n",
        "    print(\"Sensitivity:\", sensitivitiy)\n",
        "    print(\"Specificity:\", specificity)\n",
        "    print(\"PPV:\", ppv)\n",
        "    print(\"F1:\", f1)\n",
        "\n",
        "# Call this function once for each combination of label, linkage_algo\n",
        "# display_statistical_evaluation(matches, true_matches)"
      ]
    }
  ],
  "metadata": {
    "description": null,
    "kernel_info": {
      "name": "synapse_pyspark"
    },
    "kernelspec": {
      "display_name": "Synapse PySpark",
      "language": "Python",
      "name": "synapse_pyspark"
    },
    "language_info": {
      "name": "python"
    },
    "save_output": true,
    "synapse_widget": {
      "state": {},
      "version": "0.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
