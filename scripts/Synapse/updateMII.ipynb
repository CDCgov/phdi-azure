{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### updateMII\n",
        "\n",
        "This notebook inserts and updates data from an uploaded parquet file (`mii_incoming_file_path`) into a Master Incident Index (MII) delta table (`mii_delta_table_path`). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "tags": [
          "parameters"
        ]
      },
      "outputs": [],
      "source": [
        "filename=\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from delta.tables import DeltaTable\n",
        "from pyspark.sql.functions import col\n",
        "from notebookutils import mssparkutils\n",
        "\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "\n",
        "# Set up file client\n",
        "storage_account = \"$STORAGE_ACCOUNT\"\n",
        "mii_incoming_file_path = f\"abfss://patient-data@{storage_account}.dfs.core.windows.net/{filename}\"\n",
        "mii_delta_table_path = f\"abfss://delta-tables@{storage_account}.dfs.core.windows.net/MII\"\n",
        "\n",
        "\n",
        "def update(mii_incoming_file_path,mii_delta_table_path):\n",
        "    mii_updates = spark.read.parquet(mii_incoming_file_path)\n",
        "\n",
        "    # Check if MII Delta table exists\n",
        "    if DeltaTable.isDeltaTable(spark, mii_delta_table_path):\n",
        "        # If the table exists, update records\n",
        "        mii_main = DeltaTable.forPath(spark, mii_delta_table_path)\n",
        "\n",
        "        mii_main.alias(\"mii_main\") \\\n",
        "        .merge(\n",
        "            mii_updates.alias(\"mii_updates\"),\n",
        "            \"mii_updates.person_id = mii_main.person_id\") \\\n",
        "        .whenMatchedUpdate(set ={\n",
        "            \"incident_id\": \"mii_updates.incident_id\",\n",
        "            \"specimen_collection_date\":\"mii_updates.collection_date\",\n",
        "            \"record_type\":\"mii_updates.record_type\",\n",
        "            \"episode_date\": \"mii_updates.episode_date\",\n",
        "            \"process_status\": \"mii_updates.process_status\",\n",
        "            \"resolution_status\": \"mii_updates.resolution_status\"}) \\\n",
        "        .whenNotMatchedInsert(values = { \"person_id\": col(\"mii_updates.person_id\"),\n",
        "        \"incident_id\": col(\"mii_updates.incident_id\"),\n",
        "        \"specimen_collection_date\": col(\"mii_updates.collection_date\"),\n",
        "        \"record_type\": col(\"mii_updates.record_type\"),\n",
        "        \"episode_date\": col(\"mii_updates.episode_date\"),\n",
        "        \"process_status\": col(\"mii_updates.process_status\"),\n",
        "        \"resolution_status\": col(\"mii_updates.resolution_status\")}) \\\n",
        "        .execute()\n",
        "    else:\n",
        "        # If Delta table doesn't exist, create it.\n",
        "        mii_updates.write.format(\"delta\").mode(\"append\").save(mii_delta_table_path)\n",
        "\n",
        "    \n",
        "\n",
        "    \n",
        "update(mii_incoming_file_path,mii_delta_table_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Move file that triggered the MII update event into the archive folder\n",
        "destination = f\"abfss://patient-data@{storage_account}.dfs.core.windows.net/archive/{filename}\"\n",
        "mssparkutils.fs.mv(src=mii_incoming_file_path,dest=destination,create_path=True)"
      ]
    }
  ],
  "metadata": {
    "description": null,
    "kernelspec": {
      "display_name": "Synapse PySpark",
      "name": "synapse_pyspark"
    },
    "language_info": {
      "name": "python"
    },
    "save_output": true,
    "synapse_widget": {
      "state": {},
      "version": "0.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
