{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "ECR_DELTA_TABLE_FILE_PATH = \"/delta-tables/ecr_datastore\"\r\n",
        "iris_tsv_column_aliases = {\r\n",
        "    \"incident_id\":\"Incident ID\",\r\n",
        "    \"last_name\":\" Last name\",\r\n",
        "    \"first_name\": \"First name\",\r\n",
        "    # Section action\r\n",
        "    # Section instance\r\n",
        "    \"rr_id\": \"RR ID\",\r\n",
        "    \"status\": \"Status\",\r\n",
        "    \"conditions\": \"Conditions\",\r\n",
        "    \"eicr_id\": \"eICR ID\",\r\n",
        "    \"eicr_version_number\":\"eICR Version Number\",\r\n",
        "    \"authoring_datetime\": \"Authoring date/time\",\r\n",
        "    \"provider_id\": \"Provider ID\",\r\n",
        "    \"facility_id_number\": \"Facility ID Number\",\r\n",
        "    \"facility_name\": \"Facility Name\",\r\n",
        "    \"facility_type\": \"Facility Type/Hospital unit\",\r\n",
        "    \"encounter_type\": \"Encounter Details: type\",\r\n",
        "    \"encounter_start_date\": \"Encounter Details: date (from)\",\r\n",
        "    \"encounter_end_date\": \"Encounter Details: date (to)\",\r\n",
        "    \"active_problem_1\": \"Active Problem 1\",\r\n",
        "    \"active_problem_date_1\": \"Active Problem Noted Date 1\",\r\n",
        "    \"active_problem_2\": \"Active Problem 2\",\r\n",
        "    \"active_problem_date_2\": \"Active Problem Noted Date 2\",\r\n",
        "    \"active_problem_3\": \"Active Problem 3\",\r\n",
        "    \"active_problem_date_3\": \"Active Problem Noted Date 3\",\r\n",
        "    \"active_problem_4\": \"Active Problem 4\",\r\n",
        "    \"active_problem_date_4\": \"Active Problem Noted Date 4\",\r\n",
        "    \"active_problem_5\": \"Active Problem 5\",\r\n",
        "    \"active_problem_date_5\": \"Active Problem Noted Date 5\",\r\n",
        "    \"reason_for_visit\": \"Reason for visit\",\r\n",
        "    # Comments\r\n",
        "    \"test_type_1\": \"Test Type 1\",\r\n",
        "    \"test_result_1\": \"Test Result 1\",\r\n",
        "    # \"test_result_interp_1\"\r\n",
        "    \"specimen_type_1\": \"Specimen Type 1\",\r\n",
        "    \"performing_lab_1\": \"Performing Lab 1\",\r\n",
        "    \"specimen_collection_date_1\": \"Specimen Collection Date 1\",\r\n",
        "    \"result_date_1\": \"Result Date 1\",\r\n",
        "    \"test_type_2\": \"Test Type 2\",\r\n",
        "    \"test_result_2\": \"Test Result 2\",\r\n",
        "    # \"test_result_interp_2\"\r\n",
        "    \"specimen_type_2\": \"Specimen Type 2\",\r\n",
        "    \"performing_lab_2\": \"Performing Lab 2\",\r\n",
        "    \"specimen_collection_date_2\": \"Specimen Collection Date 2\",\r\n",
        "    \"result_date_2\": \"Result Date 2\"\r\n",
        "    # \"Note\"\r\n",
        "    }\r\n",
        "\r\n",
        "\r\n",
        "from pyspark.sql import SparkSession\r\n",
        "from delta.tables import *\r\n",
        "from pyspark.sql.functions import *\r\n",
        "\r\n",
        "spark = SparkSession.builder.getOrCreate()\r\n",
        "\r\n",
        "# Read in data and rename columns for TSV export\r\n",
        "ecr = spark.read.format(\"delta\").load(ECR_DELTA_TABLE_FILE_PATH).select(\r\n",
        "    col(\"incident_id\").alias(iris_tsv_column_aliases[\"incident_id\"]),\r\n",
        "    col(\"iris_id\"),\r\n",
        "    col(\"patient_id\"),\r\n",
        "    col(\"person_id\"),\r\n",
        "    col(\"first_name\").alias(iris_tsv_column_aliases[\"first_name\"]),\r\n",
        "    col(\"last_name\").alias(iris_tsv_column_aliases[\"last_name\"]),\r\n",
        "    lit(\"[ListSectionInsert]\").alias(\"Section action\"),\r\n",
        "    lit(None).alias(\"Section instance\"),\r\n",
        "    col(\"rr_id\").alias(iris_tsv_column_aliases[\"rr_id\"]),\r\n",
        "    col(\"status\").alias(iris_tsv_column_aliases[\"status\"]),\r\n",
        "    col(\"conditions\").alias(iris_tsv_column_aliases[\"conditions\"]),\r\n",
        "    col(\"eicr_id\").alias(iris_tsv_column_aliases[\"eicr_id\"]),\r\n",
        "    col(\"eicr_version_number\").alias(iris_tsv_column_aliases[\"eicr_version_number\"]),\r\n",
        "    col(\"authoring_datetime\").alias(iris_tsv_column_aliases[\"authoring_datetime\"]),\r\n",
        "    col(\"provider_id\").alias(iris_tsv_column_aliases[\"provider_id\"]),\r\n",
        "    col(\"facility_id_number\").alias(iris_tsv_column_aliases[\"facility_id_number\"]),\r\n",
        "    col(\"facility_name\").alias(iris_tsv_column_aliases[\"facility_name\"]),\r\n",
        "    col(\"facility_type\").alias(iris_tsv_column_aliases[\"facility_type\"]),\r\n",
        "    col(\"encounter_type\").alias(iris_tsv_column_aliases[\"encounter_type\"]),\r\n",
        "    col(\"encounter_start_date\").alias(iris_tsv_column_aliases[\"encounter_start_date\"]),\r\n",
        "    col(\"encounter_end_date\").alias(iris_tsv_column_aliases[\"encounter_end_date\"]),\r\n",
        "    col(\"active_problem_1\").alias(iris_tsv_column_aliases[\"active_problem_1\"]),\r\n",
        "    col(\"active_problem_date_1\").alias(iris_tsv_column_aliases[\"active_problem_date_1\"]),\r\n",
        "    col(\"active_problem_2\").alias(iris_tsv_column_aliases[\"active_problem_2\"]),\r\n",
        "    col(\"active_problem_date_2\").alias(iris_tsv_column_aliases[\"active_problem_date_2\"]),\r\n",
        "    col(\"active_problem_3\").alias(iris_tsv_column_aliases[\"active_problem_3\"]),\r\n",
        "    col(\"active_problem_date_3\").alias(iris_tsv_column_aliases[\"active_problem_date_3\"]),\r\n",
        "    col(\"active_problem_4\").alias(iris_tsv_column_aliases[\"active_problem_4\"]),\r\n",
        "    col(\"active_problem_date_4\").alias(iris_tsv_column_aliases[\"active_problem_date_4\"]),\r\n",
        "    col(\"active_problem_5\").alias(iris_tsv_column_aliases[\"active_problem_5\"]),\r\n",
        "    col(\"active_problem_date_5\").alias(iris_tsv_column_aliases[\"active_problem_date_5\"]),\r\n",
        "    col(\"reason_for_visit\").alias(iris_tsv_column_aliases[\"reason_for_visit\"]),\r\n",
        "    lit(None).alias(\"Comments\"),\r\n",
        "    col(\"test_type_1\").alias(iris_tsv_column_aliases[\"test_type_1\"]),\r\n",
        "    col(\"test_result_1\").alias(iris_tsv_column_aliases[\"test_result_1\"]),\r\n",
        "    col(\"specimen_type_1\").alias(iris_tsv_column_aliases[\"specimen_type_1\"]),\r\n",
        "    col(\"performing_lab_1\").alias(iris_tsv_column_aliases[\"performing_lab_1\"]),\r\n",
        "    col(\"specimen_collection_date_1\").alias(iris_tsv_column_aliases[\"specimen_collection_date_1\"]),\r\n",
        "    col(\"result_date_1\").alias(iris_tsv_column_aliases[\"result_date_1\"]),\r\n",
        "    col(\"test_type_2\").alias(iris_tsv_column_aliases[\"test_type_2\"]),\r\n",
        "    col(\"test_result_2\").alias(iris_tsv_column_aliases[\"test_result_2\"]),\r\n",
        "    col(\"specimen_type_2\").alias(iris_tsv_column_aliases[\"specimen_type_2\"]),\r\n",
        "    col(\"performing_lab_2\").alias(iris_tsv_column_aliases[\"performing_lab_2\"]),\r\n",
        "    col(\"specimen_collection_date_2\").alias(iris_tsv_column_aliases[\"specimen_collection_date_2\"]),\r\n",
        "    # col(\"result_date_2\").alias(iris_tsv_column_aliases[\"result_date_2\"]),\r\n",
        "    lit(\"eCR data added to UDF through import utility\").alias(\"Note\"),\r\n",
        ")\r\n",
        "\r\n",
        "def flatten(row):\r\n",
        "    incident_id = row[0]\r\n",
        "    last_name = row[1]\r\n",
        "    first_name = row[2]\r\n",
        "    note = row[-1]\r\n",
        "    return iter([(incident_id,last_name,first_name,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None)] + [row])\r\n",
        "\r\n",
        "flattend_rdd=ecr.rdd.flatMap(flatten)\r\n",
        "\r\n",
        "df3 = spark.createDataFrame(flattend_rdd, ecr.columns)\r\n",
        "df3.show(6)\r\n",
        "\r\n",
        "# Separate ecrs with incident IDs and ones without using conditional .filter()\r\n",
        "\r\n",
        "# df3.write.option(\"header\",\"true\").option(\"sep\",\"/t\").csv(\"/test/test.tsv\")\r\n",
        "        "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    },
    "description": null,
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}