{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### updateECRDatastorePersonID\n",
        "This is the 1st step to update the ECR datastore after receiving new MPI data from LAC.\n",
        "\n",
        "This notebook joins the ECR datastore (`ecr`) and Patient table from the Master Patient Index (`patient`) on `patient_id` to update the ECR datastore's `person_id` with the most up-to-date `person_id` in the `patient` table. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "pip install psycopg2-binary azure-identity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from azure.identity import DefaultAzureCredential\n",
        "import psycopg2\n",
        "from delta.tables import *\n",
        "from pyspark.sql.functions import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "storage_account_name = \"$STORAGE_ACCOUNT\"\n",
        "ECR_DELTA_TABLE_FILE_PATH = f\"abfss://delta-tables@{storage_account_name}.dfs.core.windows.net/ecr-datastore\" \n",
        "\n",
        "# Set your Key Vault information and Key Vault linked service\n",
        "vault_name = \"$KEY_VAULT\"\n",
        "vault_linked_service = \"$KEY_VAULT_LINKED_SERVICE\"\n",
        "credential = DefaultAzureCredential()\n",
        "\n",
        "# Database connection parameters\n",
        "DB_NAME = \"DibbsMpiDB\"\n",
        "DB_USER = \"postgres\"\n",
        "DB_HOST = \"phdidevmpi9d194c64.postgres.database.azure.com\"\n",
        "DB_PORT = \"5432\"\n",
        "DB_TABLE = \"patient\"\n",
        "\n",
        "# Get the secret value (password) from the previous step\n",
        "db_password =  TokenLibrary.getSecret(vault_name,\"mpi-db-password\",vault_linked_service)\n",
        "\n",
        "# Connect to the database\n",
        "conn = psycopg2.connect(\n",
        "    dbname=DB_NAME,\n",
        "    user=DB_USER,\n",
        "    password=db_password,\n",
        "    host=DB_HOST,\n",
        "    port=DB_PORT\n",
        ")\n",
        "\n",
        "# Create a cursor\n",
        "cur = conn.cursor()\n",
        "\n",
        "# Execute the query to get the list of tables in the database\n",
        "cur.execute(f\"\"\"\n",
        "    SELECT patient_id,person_id\n",
        "    FROM {DB_TABLE};\n",
        "\"\"\")\n",
        "\n",
        "# Fetch the results\n",
        "data = cur.fetchall()\n",
        "\n",
        "# Close the cursor and connection\n",
        "cur.close()\n",
        "conn.close()\n",
        "\n",
        "\n",
        "# Prep the MPI data for merging with ECR data \n",
        "columns=['patient_id','person_id']\n",
        "patient = spark.createDataFrame(data = data, schema = columns)\n",
        "\n",
        "\n",
        "# Load ecr Delta table\n",
        "ecr = DeltaTable.forPath(spark,ECR_DELTA_TABLE_FILE_PATH)\n",
        "\n",
        "# Update ecr data with `person_id` from MPI by joining on `patient_id`\n",
        "ecr.alias(\"ecr\") \\\n",
        "  .merge(\n",
        "    patient.alias(\"mpi_patient\"),\n",
        "    \"ecr.patient_id = mpi_patient.patient_id\") \\\n",
        "  .whenMatchedUpdate(set = { \"person_id\": \"mpi_patient.person_id\", \"person_id_date_added\": date_format(current_timestamp(), 'yyyy-MM-dd')}) \\\n",
        "  .execute()\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "description": null,
    "kernel_info": {
      "name": "synapse_pyspark"
    },
    "kernelspec": {
      "display_name": "Synapse PySpark",
      "language": "Python",
      "name": "synapse_pyspark"
    },
    "language_info": {
      "name": "python"
    },
    "save_output": true,
    "synapse_widget": {
      "state": {},
      "version": "0.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}