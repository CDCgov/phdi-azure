{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### updateECRDatastorePersonID\n",
        "This is the 1st step to update the ECR datastore after receiving new MPI data from LAC.\n",
        "\n",
        "This notebook joins the ECR datastore (`ecr`) and Patient table from the Master Patient Index (`patient`) on `patient_id` to update the ECR datastore's `person_id` with the most up-to-date `person_id` in the `patient` table. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "pip install psycopg2-binary azure-keyvault"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from azure.identity import ManagedIdentityCredential\n",
        "from azure.core.credentials import AccessToken\n",
        "from azure.keyvault.secrets import SecretClient\n",
        "import psycopg2\n",
        "import time\n",
        "\n",
        "from delta.tables import *\n",
        "from pyspark.sql.functions import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "ECR_DELTA_TABLE_FILE_PATH = \"ecr-datastore\"\n",
        "\n",
        "\n",
        "# # Database connection parameters\n",
        "# DB_NAME = \"DibbsMpiDB\"\n",
        "# DB_USER = \"postgres\"\n",
        "# DB_HOST = \"phdidevmpi9d194c64.postgres.database.azure.com\"\n",
        "# DB_PORT = \"5432\"\n",
        "# DB_TABLE = \"patient\"\n",
        "\n",
        "# Set up authentication\n",
        "class spoof_token:\n",
        "    def get_token(*args, **kwargs):\n",
        "        return AccessToken(\n",
        "            token=mssparkutils.credentials.getToken(audience=\"vault\"),\n",
        "            expires_on=int(time.time())+60*10 # some random time in future... synapse doesn't document how to get the actual time\n",
        "        )\n",
        "\n",
        "credential = ManagedIdentityCredential()\n",
        "credential._credential = spoof_token() # monkey-patch the contents of the private `_credential`\n",
        "\n",
        "# Set your Key Vault information\n",
        "KEY_VAULT_URL = \"https://$KEY_VAULT.vault.azure.net\"\n",
        "DB_PASS_SECRET_NAME = \"mpi-db-password\"\n",
        "\n",
        "# Create a SecretClient to interact with the Key Vault\n",
        "secret_client = SecretClient(vault_url=KEY_VAULT_URL, credential=credential)\n",
        "\n",
        "# Retrieve the secret\n",
        "db_pass_secret = secret_client.get_secret(DB_PASS_SECRET_NAME)\n",
        "\n",
        "# Database connection parameters\n",
        "DB_NAME = \"DibbsMpiDB\"\n",
        "DB_USER = \"postgres\"\n",
        "DB_HOST = \"$MPI_DB_HOST\"\n",
        "DB_PORT = \"5432\"\n",
        "DB_TABLE = \"patient\"\n",
        "\n",
        "# Get the secret value (password) from the previous step\n",
        "db_password = db_pass_secret.value\n",
        "\n",
        "# Connect to the database\n",
        "conn = psycopg2.connect(\n",
        "    dbname=DB_NAME,\n",
        "    user=DB_USER,\n",
        "    password=db_password,\n",
        "    host=DB_HOST,\n",
        "    port=DB_PORT\n",
        ")\n",
        "\n",
        "# Create a cursor\n",
        "cur = conn.cursor()\n",
        "\n",
        "# Execute the query to get the list of tables in the database\n",
        "cur.execute(f\"\"\"\n",
        "    SELECT patient_id,person_id\n",
        "    FROM {DB_TABLE};\n",
        "\"\"\")\n",
        "\n",
        "# Fetch the results\n",
        "data = cur.fetchall()\n",
        "\n",
        "# Close the cursor and connection\n",
        "cur.close()\n",
        "conn.close()\n",
        "\n",
        "\n",
        "# Prep the MPI data for merging with ECR data \n",
        "columns=['patient_id','person_id']\n",
        "patient = spark.createDataFrame(data = data, schema = columns)\n",
        "\n",
        "\n",
        "# Load ecr Delta table\n",
        "ecr = DeltaTable.forPath(spark,ECR_DELTA_TABLE_FILE_PATH)\n",
        "\n",
        "# Update ecr data with `person_id` from MPI by joining on `patient_id`\n",
        "ecr.alias(\"ecr\") \\\n",
        "  .merge(\n",
        "    patient.alias(\"mpi_patient\"),\n",
        "    \"ecr.patient_id = mpi_patient.patient_id\") \\\n",
        "  .whenMatchedUpdate(set = { \"person_id\": \"mpi_patient.person_id\", \"person_id_date_added\": date_format(current_timestamp(), 'yyyy-MM-dd')}) \\\n",
        "  .execute()\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "description": null,
    "kernel_info": {
      "name": "synapse_pyspark"
    },
    "kernelspec": {
      "display_name": "Synapse PySpark",
      "language": "Python",
      "name": "synapse_pyspark"
    },
    "language_info": {
      "name": "python"
    },
    "save_output": true,
    "synapse_widget": {
      "state": {},
      "version": "0.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
