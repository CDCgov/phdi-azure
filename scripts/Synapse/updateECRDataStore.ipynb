{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# updateECRdatastore\n",
    "\n",
    "This notebook updates the ECR datastore delta table with new ECR records (`PARSED_ECR_PATH`); a new ECR datastore delta table is created if one does not already exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install azure-identity azure-keyvault-secrets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths\n",
    "STORAGE_ACCOUNT = \"$STORAGE_ACCOUNT\"\n",
    "BASE_DATASTORE_DIRECTORY = \"ecr-datastore\"\n",
    "DELTA_TABLES_FILESYSTEM = f\"abfss://delta-tables@{STORAGE_ACCOUNT}.dfs.core.windows.net/\"\n",
    "ECR_DATASTORE_PATH = DELTA_TABLES_FILESYSTEM + \"ecr-datastore\"\n",
    "ECR_DATASTORE_DAILY_EXTRACT_PATH = DELTA_TABLES_FILESYSTEM + \"ecr-datastore\"\n",
    "PARSED_ECR_PATH = DELTA_TABLES_FILESYSTEM + \"raw_data\"\n",
    "DAILY_EXTRACT_FORMATS = [\"parquet\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebookutils import mssparkutils\n",
    "\n",
    "# Set up for writing to blob storage\n",
    "delta_bucket_name = \"delta-tables\"\n",
    "linked_service_name = \"$BLOB_STORAGE_LINKED_SERVICE\" \n",
    "blob_sas_token = mssparkutils.credentials.getConnectionStringOrCreds(linked_service_name)\n",
    "wasb_path = 'wasbs://%s@%s.blob.core.windows.net/' % (delta_bucket_name, STORAGE_ACCOUNT)\n",
    "spark.conf.set('fs.azure.sas.%s.%s.blob.core.windows.net' % (delta_bucket_name, STORAGE_ACCOUNT), blob_sas_token)\n",
    "# Try mounting the remote storage directory at the mount point\n",
    "try:\n",
    "    mssparkutils.fs.mount(\n",
    "        wasb_path,\n",
    "        \"/\",\n",
    "        {\"LinkedService\": linked_service_name}\n",
    "    )\n",
    "except:\n",
    "    print(\"Already mounted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import (\n",
    "    StructType,\n",
    "    StructField,\n",
    "    StringType,\n",
    "    IntegerType,\n",
    "    FloatType,\n",
    "    BooleanType,\n",
    "    DateType,\n",
    "    TimestampType,\n",
    ")\n",
    "from delta.tables import *\n",
    "import json\n",
    "from typing import Tuple\n",
    "\n",
    "# Prepare Schema\n",
    "schema = {\n",
    "    \"patient_id\": [\"string\", False],\n",
    "    \"person_id\": [\"string\", False],\n",
    "    \"person_id_date_added\": [\"timestamp\", True],\n",
    "    \"iris_id\": [\"string\", True],\n",
    "    \"iris_id_date_added\": [\"timestamp\", True],\n",
    "    \"incident_id\": [\"string\", True],\n",
    "    \"incident_id_date_added\": [\"timestamp\", True],\n",
    "    \"last_name\": [\"string\", True],\n",
    "    \"first_name\": [\"string\", True],\n",
    "    \"birth_date\": [\"date\", True],\n",
    "    \"gender\": [\"string\", True],\n",
    "    \"race\": [\"string\", True],\n",
    "    \"ethnicity\": [\"string\", True],\n",
    "    \"rr_id\": [\"string\", True],\n",
    "    \"status\": [\"string\", True],\n",
    "    \"conditions\": [\"string\", True],\n",
    "    \"eicr_id\": [\"string\", False],\n",
    "    \"eicr_version_number\": [\"integer\", True],\n",
    "    \"authoring_datetime\": [\"timestamp\", True],\n",
    "    \"provider_id\": [\"string\", True],\n",
    "    \"facility_id_number\": [\"string\", True],\n",
    "    \"facility_name\": [\"string\", True],\n",
    "    \"facility_type\": [\"string\", True],\n",
    "    \"encounter_type\": [\"string\", True],\n",
    "    \"encounter_start_date\": [\"date\", True],\n",
    "    \"encounter_end_date\": [\"date\", True],\n",
    "    \"active_problem_1\": [\"string\", True],\n",
    "    \"active_problem_date_1\": [\"date\", True],\n",
    "    \"active_problem_2\": [\"string\", True],\n",
    "    \"active_problem_date_2\": [\"date\", True],\n",
    "    \"active_problem_3\": [\"string\", True],\n",
    "    \"active_problem_date_3\": [\"date\", True],\n",
    "    \"active_problem_4\": [\"string\", True],\n",
    "    \"active_problem_date_4\": [\"date\", True],\n",
    "    \"active_problem_5\": [\"string\", True],\n",
    "    \"active_problem_date_5\": [\"date\", True],\n",
    "    \"reason_for_visit\": [\"string\", True],\n",
    "    \"test_type_1\": [\"string\", True],\n",
    "    \"test_type_code_1\": [\"string\", True],\n",
    "    \"test_result_1\": [\"string\", True],\n",
    "    \"test_result_interp_1\": [\"string\", True],\n",
    "    \"specimen_type_1\": [\"string\", True],\n",
    "    \"performing_lab_1\": [\"string\", True],\n",
    "    \"specimen_collection_date_1\": [\"timestamp\", True],\n",
    "    \"result_date_1\": [\"timestamp\", True],\n",
    "    \"test_type_2\": [\"string\", True],\n",
    "    \"test_type_code_2\": [\"string\", True],\n",
    "    \"test_result_2\": [\"string\", True],\n",
    "    \"test_result_interp_2\": [\"string\", True],\n",
    "    \"specimen_type_2\": [\"string\", True],\n",
    "    \"performing_lab_2\": [\"string\", True],\n",
    "    \"specimen_collection_date_2\": [\"timestamp\", True],\n",
    "    \"result_date_2\": [\"timestamp\", True],\n",
    "    \"test_type_3\": [\"string\", True],\n",
    "    \"test_type_code_3\": [\"string\", True],\n",
    "    \"test_result_3\": [\"string\", True],\n",
    "    \"test_result_interp_3\": [\"string\", True],\n",
    "    \"specimen_type_3\": [\"string\", True],\n",
    "    \"performing_lab_3\": [\"string\", True],\n",
    "    \"specimen_collection_date_3\": [\"timestamp\", True],\n",
    "    \"result_date_3\": [\"timestamp\", True],\n",
    "    \"test_type_4\": [\"string\", True],\n",
    "    \"test_type_code_4\": [\"string\", True],\n",
    "    \"test_result_4\": [\"string\", True],\n",
    "    \"test_result_interp_4\": [\"string\", True],\n",
    "    \"specimen_type_4\": [\"string\", True],\n",
    "    \"performing_lab_4\": [\"string\", True],\n",
    "    \"specimen_collection_date_4\": [\"timestamp\", True],\n",
    "    \"result_date_4\": [\"timestamp\", True],\n",
    "    \"test_type_5\": [\"string\", True],\n",
    "    \"test_type_code_5\": [\"string\", True],\n",
    "    \"test_result_5\": [\"string\", True],\n",
    "    \"test_result_interp_5\": [\"string\", True],\n",
    "    \"specimen_type_5\": [\"string\", True],\n",
    "    \"performing_lab_5\": [\"string\", True],\n",
    "    \"specimen_collection_date_5\": [\"timestamp\", True],\n",
    "    \"result_date_5\": [\"timestamp\", True],\n",
    "    \"test_type_6\": [\"string\", True],\n",
    "    \"test_type_code_6\": [\"string\", True],\n",
    "    \"test_result_6\": [\"string\", True],\n",
    "    \"test_result_interp_6\": [\"string\", True],\n",
    "    \"specimen_type_6\": [\"string\", True],\n",
    "    \"performing_lab_6\": [\"string\", True],\n",
    "    \"specimen_collection_date_6\": [\"timestamp\", True],\n",
    "    \"result_date_6\": [\"timestamp\", True],\n",
    "    \"test_type_7\": [\"string\", True],\n",
    "    \"test_type_code_7\": [\"string\", True],\n",
    "    \"test_result_7\": [\"string\", True],\n",
    "    \"test_result_interp_7\": [\"string\", True],\n",
    "    \"specimen_type_7\": [\"string\", True],\n",
    "    \"performing_lab_7\": [\"string\", True],\n",
    "    \"specimen_collection_date_7\": [\"timestamp\", True],\n",
    "    \"result_date_7\": [\"timestamp\", True],\n",
    "    \"test_type_8\": [\"string\", True],\n",
    "    \"test_type_code_8\": [\"string\", True],\n",
    "    \"test_result_8\": [\"string\", True],\n",
    "    \"test_result_interp_8\": [\"string\", True],\n",
    "    \"specimen_type_8\": [\"string\", True],\n",
    "    \"performing_lab_8\": [\"string\", True],\n",
    "    \"specimen_collection_date_8\": [\"timestamp\", True],\n",
    "    \"result_date_8\": [\"timestamp\", True],\n",
    "    \"test_type_9\": [\"string\", True],\n",
    "    \"test_type_code_9\": [\"string\", True],\n",
    "    \"test_result_9\": [\"string\", True],\n",
    "    \"test_result_interp_9\": [\"string\", True],\n",
    "    \"specimen_type_9\": [\"string\", True],\n",
    "    \"performing_lab_9\": [\"string\", True],\n",
    "    \"specimen_collection_date_9\": [\"timestamp\", True],\n",
    "    \"result_date_9\": [\"timestamp\", True],\n",
    "    \"test_type_10\": [\"string\", True],\n",
    "    \"test_type_code_10\": [\"string\", True],\n",
    "    \"test_result_10\": [\"string\", True],\n",
    "    \"test_result_interp_10\": [\"string\", True],\n",
    "    \"specimen_type_10\": [\"string\", True],\n",
    "    \"performing_lab_10\": [\"string\", True],\n",
    "    \"specimen_collection_date_10\": [\"timestamp\", True],\n",
    "    \"result_date_10\": [\"timestamp\", True],\n",
    "    \"test_type_11\": [\"string\", True],\n",
    "    \"test_type_code_11\": [\"string\", True],\n",
    "    \"test_result_11\": [\"string\", True],\n",
    "    \"test_result_interp_11\": [\"string\", True],\n",
    "    \"specimen_type_11\": [\"string\", True],\n",
    "    \"performing_lab_11\": [\"string\", True],\n",
    "    \"specimen_collection_date_11\": [\"timestamp\", True],\n",
    "    \"result_date_11\": [\"timestamp\", True],\n",
    "    \"test_type_12\": [\"string\", True],\n",
    "    \"test_type_code_12\": [\"string\", True],\n",
    "    \"test_result_12\": [\"string\", True],\n",
    "    \"test_result_interp_12\": [\"string\", True],\n",
    "    \"specimen_type_12\": [\"string\", True],\n",
    "    \"performing_lab_12\": [\"string\", True],\n",
    "    \"specimen_collection_date_12\": [\"timestamp\", True],\n",
    "    \"result_date_12\": [\"timestamp\", True],\n",
    "    \"test_type_13\": [\"string\", True],\n",
    "    \"test_type_code_13\": [\"string\", True],\n",
    "    \"test_result_13\": [\"string\", True],\n",
    "    \"test_result_interp_13\": [\"string\", True],\n",
    "    \"specimen_type_13\": [\"string\", True],\n",
    "    \"performing_lab_13\": [\"string\", True],\n",
    "    \"specimen_collection_date_13\": [\"timestamp\", True],\n",
    "    \"result_date_13\": [\"timestamp\", True],\n",
    "    \"test_type_14\": [\"string\", True],\n",
    "    \"test_type_code_14\": [\"string\", True],\n",
    "    \"test_result_14\": [\"string\", True],\n",
    "    \"test_result_interp_14\": [\"string\", True],\n",
    "    \"specimen_type_14\": [\"string\", True],\n",
    "    \"performing_lab_14\": [\"string\", True],\n",
    "    \"specimen_collection_date_14\": [\"timestamp\", True],\n",
    "    \"result_date_14\": [\"timestamp\", True],\n",
    "    \"test_type_15\": [\"string\", True],\n",
    "    \"test_type_code_15\": [\"string\", True],\n",
    "    \"test_result_15\": [\"string\", True],\n",
    "    \"test_result_interp_15\": [\"string\", True],\n",
    "    \"specimen_type_15\": [\"string\", True],\n",
    "    \"performing_lab_15\": [\"string\", True],\n",
    "    \"specimen_collection_date_15\": [\"timestamp\", True],\n",
    "    \"result_date_15\": [\"timestamp\", True],\n",
    "    \"test_type_16\": [\"string\", True],\n",
    "    \"test_type_code_16\": [\"string\", True],\n",
    "    \"test_result_16\": [\"string\", True],\n",
    "    \"test_result_interp_16\": [\"string\", True],\n",
    "    \"specimen_type_16\": [\"string\", True],\n",
    "    \"performing_lab_16\": [\"string\", True],\n",
    "    \"specimen_collection_date_16\": [\"timestamp\", True],\n",
    "    \"result_date_16\": [\"timestamp\", True],\n",
    "    \"test_type_17\": [\"string\", True],\n",
    "    \"test_type_code_17\": [\"string\", True],\n",
    "    \"test_result_17\": [\"string\", True],\n",
    "    \"test_result_interp_17\": [\"string\", True],\n",
    "    \"specimen_type_17\": [\"string\", True],\n",
    "    \"performing_lab_17\": [\"string\", True],\n",
    "    \"specimen_collection_date_17\": [\"timestamp\", True],\n",
    "    \"result_date_17\": [\"timestamp\", True],\n",
    "    \"test_type_18\": [\"string\", True],\n",
    "    \"test_type_code_18\": [\"string\", True],\n",
    "    \"test_result_18\": [\"string\", True],\n",
    "    \"test_result_interp_18\": [\"string\", True],\n",
    "    \"specimen_type_18\": [\"string\", True],\n",
    "    \"performing_lab_18\": [\"string\", True],\n",
    "    \"specimen_collection_date_18\": [\"timestamp\", True],\n",
    "    \"result_date_18\": [\"timestamp\", True],\n",
    "    \"test_type_19\": [\"string\", True],\n",
    "    \"test_type_code_19\": [\"string\", True],\n",
    "    \"test_result_19\": [\"string\", True],\n",
    "    \"test_result_interp_19\": [\"string\", True],\n",
    "    \"specimen_type_19\": [\"string\", True],\n",
    "    \"performing_lab_19\": [\"string\", True],\n",
    "    \"specimen_collection_date_19\": [\"timestamp\", True],\n",
    "    \"result_date_19\": [\"timestamp\", True],\n",
    "    \"test_type_20\": [\"string\", True],\n",
    "    \"test_type_code_20\": [\"string\", True],\n",
    "    \"test_result_20\": [\"string\", True],\n",
    "    \"test_result_interp_20\": [\"string\", True],\n",
    "    \"specimen_type_20\": [\"string\", True],\n",
    "    \"performing_lab_20\": [\"string\", True],\n",
    "    \"specimen_collection_date_20\": [\"timestamp\", True],\n",
    "    \"result_date_20\": [\"timestamp\", True],\n",
    "    \"birth_sex\": [\"string\", True],\n",
    "    \"gender_identity\": [\"string\", True],\n",
    "    \"homelessness_status\": [\"string\", True],\n",
    "    \"disabilities\": [\"string\", True],\n",
    "    \"tribal_affiliation\": [\"string\", True],\n",
    "    \"tribal_enrollment_status\": [\"string\", True],\n",
    "    \"current_job_title\": [\"string\", True],\n",
    "    \"current_job_industry\": [\"string\", True],\n",
    "    \"usual_occupation\": [\"string\", True],\n",
    "    \"usual_industry\": [\"string\", True],\n",
    "    \"preferred_language\": [\"string\", True],\n",
    "    \"pregnancy_status\": [\"string\", True]\n",
    "  }\n",
    "\n",
    "def get_schemas(schema: dict) -> Tuple[StructType, dict]:\n",
    "    \"\"\"\n",
    "    Get a Spark StructType object from a JSON schema string.\n",
    "\n",
    "    :param schema: A dictionary defining the schema of the ECR datastore including \n",
    "        the data type of each field and whether null values are allowed. Should be of the form:\n",
    "        '{\"fieldname\": [<data type>, <nullable?(True/False)>]}'.\n",
    "    :return: A tuple containing a Spark StructType object representing the schema \n",
    "    and a dictionary defining field mappings for merge operations. \n",
    "    \"\"\"\n",
    "\n",
    "    schema_type_map = {\n",
    "        \"string\": StringType(),\n",
    "        \"integer\": IntegerType(),\n",
    "        \"float\": FloatType(),\n",
    "        \"boolean\": BooleanType(),\n",
    "        \"date\": DateType(),\n",
    "        \"timestamp\": TimestampType(),\n",
    "    }\n",
    "    spark_schema = StructType()\n",
    "    merge_schema = {}\n",
    "    for field in schema:\n",
    "        spark_schema.add(StructField(field, schema_type_map[schema[field][0]], schema[field][1]))\n",
    "        merge_schema[field] = \"new.\" + field\n",
    "    return spark_schema, merge_schema\n",
    "\n",
    "\n",
    "spark_schema, merge_schema = get_schemas(schema)\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = (\n",
    "    SparkSession.builder.master(\"local[*]\")\n",
    "    .appName(\"Update eCR Datastore\")\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")\n",
    "    .config(\n",
    "        \"spark.sql.catalog.spark_catalog\",\n",
    "        \"org.apache.spark.sql.delta.catalog.DeltaCatalog\",\n",
    "    )\n",
    "    .getOrCreate()\n",
    ")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read JSON files into a DataFrame with the specified schema\n",
    "new_ecr_records = spark.read.schema(spark_schema).json(PARSED_ECR_PATH,multiLine=True)\n",
    "\n",
    "# Check if Delta table exists\n",
    "if DeltaTable.isDeltaTable(spark, ECR_DATASTORE_PATH):\n",
    "    # If the table exists add new records.\n",
    "    ecr_datastore = DeltaTable.forPath(spark, ECR_DATASTORE_PATH)\n",
    "\n",
    "    ecr_datastore.alias(\"old\").merge(\n",
    "        new_ecr_records.alias(\"new\"), \"old.eicr_id = new.eicr_id\"\n",
    "    ).whenNotMatchedInsert(values=merge_schema).execute()\n",
    "else:\n",
    "    # If Delta table doesn't exist, create it.\n",
    "    new_ecr_records.write.format(\"delta\").mode(\"append\").save(ECR_DATASTORE_PATH)\n",
    "\n",
    "# Make a copy of the Delta table in CSV format for easy access.\n",
    "ecr_datastore = DeltaTable.forPath(spark, ECR_DATASTORE_PATH).toDF()\n",
    "\n",
    "# Set up storage client\n",
    "container_url = f\"https://{STORAGE_ACCOUNT}.blob.core.windows.net/\"\n",
    "\n",
    "for format in DAILY_EXTRACT_FORMATS:\n",
    "\n",
    "    # Write standard pyspark directories for each file format\n",
    "    # Force pyspark to coalesce the results into a single file\n",
    "    format_path = ECR_DATASTORE_DAILY_EXTRACT_PATH + \".\" + format\n",
    "    modified_datastore_directory = BASE_DATASTORE_DIRECTORY + \".\" + format + \"/\"\n",
    "    ecr_datastore.coalesce(1).write.format(format).mode('overwrite').save(format_path)\n",
    "\n",
    "    # Locate the file which actually has the data amidst the pyspark kruft\n",
    "    partial_file = \"\"\n",
    "    for f in mssparkutils.fs.ls(format_path):\n",
    "        file_in_namespace = f.path.split(\"/\")[-1]\n",
    "        if file_in_namespace.startswith(\"part-\") and file_in_namespace.endswith(\".\" + format):\n",
    "            partial_file = f.path\n",
    "\n",
    "    # Create a copy of just the data at the root level, formatted appropriately\n",
    "    mssparkutils.fs.cp(partial_file, DELTA_TABLES_FILESYSTEM + \"updated_ecr_datastore.\" + format)\n",
    "\n",
    "    # Now delete the pyspark junk folder by deleting all virtual filepaths\n",
    "    mssparkutils.fs.rm(format_path, recurse=True)"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "kernelspec": {
   "display_name": "Synapse PySpark",
   "language": "Python",
   "name": "synapse_pyspark"
  },
  "language_info": {
   "name": "python"
  },
  "save_output": true,
  "synapse_widget": {
   "state": {},
   "version": "0.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
