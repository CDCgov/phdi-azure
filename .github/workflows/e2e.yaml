name: End-to-end test

on:
  push:
  workflow_dispatch:
    inputs:
      environment:
        description: "Environment to deploy to"
        type: environment
        required: true
  workflow_run:
    workflows: [Deployment]
    types: [completed]

permissions:
  id-token: write
  contents: read
  packages: write
jobs:
  e2e:
    runs-on: ubuntu-latest
    environment: main
    steps:
      - name: Check Out Changes
        uses: actions/checkout@v3
      - name: Azure login
        uses: azure/login@v1
        with:
          client-id: ${{ secrets.CLIENT_ID }}
          tenant-id: ${{ secrets.TENANT_ID }}
          subscription-id: ${{ secrets.SUBSCRIPTION_ID }}
      - name: Azure defaults
        env:
          LOCATION: ${{ secrets.LOCATION }}
          RESOURCE_GROUP_NAME: ${{ secrets.RESOURCE_GROUP_NAME }}
        run: az config set defaults.location=$LOCATION defaults.group=$RESOURCE_GROUP_NAME
      - name: Set environment
        id: set-environment
        env:
          CLIENT_ID: ${{ secrets.CLIENT_ID }}
        run: |-
          echo "tf_env=$(
          if "${{ github.event.inputs.environment }}"; then
            echo ${{ github.event.inputs.environment }}
          else
            echo dev
          fi
          )" >> $GITHUB_OUTPUT
          echo "short_cid=${CLIENT_ID:0:8}" >> $GITHUB_OUTPUT
      - name: Upload sample data
        id: upload-sample-data
        env:
          TF_ENV: ${{ steps.set-environment.outputs.tf_env }}
          SHORT_CID: ${{ steps.set-environment.outputs.short_cid }}
        run: |
          TIMESTAMP=$(date "+%Y-%m-%dT%H:%M:%S")
          echo "timestamp=$TIMESTAMP" >> $GITHUB_OUTPUT
          az storage blob upload --account-name phdi${TF_ENV}phi${SHORT_CID} --container-name source-data --name vxu/VXU-V04-01_success_single_$TIMESTAMP.hl7 --file sample-data/VXU-V04-01_success_single.hl7
      - name: Check pipeline run
        env:
          TF_ENV: ${{ steps.set-environment.outputs.tf_env }}
          SHORT_CID: ${{ steps.set-environment.outputs.short_cid }}
          TIMESTAMP: ${{ steps.upload-sample-data.outputs.timestamp }}
        run: |
          az extension add --name datafactory --upgrade
          END_DATE=$(date --date="1 hour" "+%Y-%m-%dT%H:%M:%S")
          CHECK_COUNT=0

          check_pipeline_run_count() {
            az datafactory pipeline-run query-by-factory --factory-name "phdi-$TF_ENV-data-factory-$SHORT_CID" --filters operand="PipelineName" operator="Equals" values="phdi-$TF_ENV-ingestion" --filters operand="Status" operator="Equals" values="$1" --last-updated-after "$TIMESTAMP" --last-updated-before "$END_DATE" | jq 'map(select(.parameters.filename == "source-data/vxu/VXU-V04-01_success_single_$TIMESTAMP.hl7")) | length'
          }

          check_pipeline_success_count() {
            check_pipeline_run_count "Succeeded"
          }

          check_pipeline_failure_count() {
            check_pipeline_run_count "Failed"
          }

          while [[ "$(check_pipeline_success_count)" -lt 1 ]]; do
            if [[ "$CHECK_COUNT" -gt 60 || "$(check_pipeline_failure_count)" -gt 0 ]]; then
              echo "Pipeline run failed"
              exit 1
            fi
            echo "Waiting for pipeline to complete run..."
            sleep 10
            CHECK_COUNT=$((CHECK_COUNT+1))
          done
